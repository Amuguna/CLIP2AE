2022-06-20 19:05:03,087:INFO: Effective parameters:
2022-06-20 19:05:03,087:INFO:   <<< batch_size: 256
2022-06-20 19:05:03,087:INFO:   <<< batch_size_val: 16
2022-06-20 19:05:03,087:INFO:   <<< cache_dir: 
2022-06-20 19:05:03,087:INFO:   <<< coef_lr: 0.001
2022-06-20 19:05:03,087:INFO:   <<< cross_model: cross-base
2022-06-20 19:05:03,087:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:05:03,087:INFO:   <<< data_path: /home/key2317/CLIP4Clip/msvd_data
2022-06-20 19:05:03,087:INFO:   <<< datatype: msvd
2022-06-20 19:05:03,087:INFO:   <<< do_eval: False
2022-06-20 19:05:03,087:INFO:   <<< do_lower_case: False
2022-06-20 19:05:03,087:INFO:   <<< do_pretrain: False
2022-06-20 19:05:03,087:INFO:   <<< do_train: True
2022-06-20 19:05:03,087:INFO:   <<< epochs: 5
2022-06-20 19:05:03,087:INFO:   <<< eval_frame_order: 0
2022-06-20 19:05:03,087:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:05:03,087:INFO:   <<< feature_framerate: 1
2022-06-20 19:05:03,087:INFO:   <<< features_path: /home/key2317/CLIP4Clip/msvd_data/MSVD_Videos
2022-06-20 19:05:03,087:INFO:   <<< fp16: False
2022-06-20 19:05:03,087:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:05:03,087:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:05:03,087:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:05:03,087:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:05:03,087:INFO:   <<< init_model: None
2022-06-20 19:05:03,087:INFO:   <<< linear_patch: 2d
2022-06-20 19:05:03,087:INFO:   <<< local_rank: 0
2022-06-20 19:05:03,088:INFO:   <<< loose_type: True
2022-06-20 19:05:03,088:INFO:   <<< lr: 0.0001
2022-06-20 19:05:03,088:INFO:   <<< lr_decay: 0.9
2022-06-20 19:05:03,088:INFO:   <<< margin: 0.1
2022-06-20 19:05:03,088:INFO:   <<< max_frames: 12
2022-06-20 19:05:03,088:INFO:   <<< max_words: 32
2022-06-20 19:05:03,088:INFO:   <<< n_display: 50
2022-06-20 19:05:03,088:INFO:   <<< n_gpu: 1
2022-06-20 19:05:03,088:INFO:   <<< n_pair: 1
2022-06-20 19:05:03,088:INFO:   <<< negative_weighting: 1
2022-06-20 19:05:03,088:INFO:   <<< num_thread_reader: 2
2022-06-20 19:05:03,088:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:05:03,088:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:05:03,088:INFO:   <<< rank: 0
2022-06-20 19:05:03,088:INFO:   <<< resume_model: None
2022-06-20 19:05:03,088:INFO:   <<< sampled_use_mil: False
2022-06-20 19:05:03,088:INFO:   <<< seed: 42
2022-06-20 19:05:03,088:INFO:   <<< sim_header: meanP
2022-06-20 19:05:03,088:INFO:   <<< slice_framepos: 2
2022-06-20 19:05:03,088:INFO:   <<< task_type: retrieval
2022-06-20 19:05:03,088:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:05:03,088:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:05:03,088:INFO:   <<< train_frame_order: 0
2022-06-20 19:05:03,088:INFO:   <<< use_mil: False
2022-06-20 19:05:03,088:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:05:03,088:INFO:   <<< video_dim: 1024
2022-06-20 19:05:03,088:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:05:03,088:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:05:03,088:INFO:   <<< world_size: 1
2022-06-20 19:05:03,088:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:05:03,801:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:05:03,801:WARNING: Test retrieval by loose type.
2022-06-20 19:05:03,801:WARNING: 	 embed_dim: 512
2022-06-20 19:05:03,801:WARNING: 	 image_resolution: 224
2022-06-20 19:05:03,801:WARNING: 	 vision_layers: 12
2022-06-20 19:05:03,801:WARNING: 	 vision_width: 768
2022-06-20 19:05:03,801:WARNING: 	 vision_patch_size: 32
2022-06-20 19:05:03,801:WARNING: 	 context_length: 77
2022-06-20 19:05:03,801:WARNING: 	 vocab_size: 49408
2022-06-20 19:05:03,801:WARNING: 	 transformer_width: 512
2022-06-20 19:05:03,801:WARNING: 	 transformer_heads: 8
2022-06-20 19:05:03,802:WARNING: 	 transformer_layers: 12
2022-06-20 19:05:03,802:WARNING: 		 linear_patch: 2d
2022-06-20 19:05:03,802:WARNING: 	 cut_top_layer: 0
2022-06-20 19:12:12,710:INFO: Effective parameters:
2022-06-20 19:12:12,710:INFO:   <<< batch_size: 256
2022-06-20 19:12:12,710:INFO:   <<< batch_size_val: 16
2022-06-20 19:12:12,710:INFO:   <<< cache_dir: 
2022-06-20 19:12:12,711:INFO:   <<< coef_lr: 0.001
2022-06-20 19:12:12,711:INFO:   <<< cross_model: cross-base
2022-06-20 19:12:12,711:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:12:12,711:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:12:12,711:INFO:   <<< datatype: msvd
2022-06-20 19:12:12,711:INFO:   <<< do_eval: False
2022-06-20 19:12:12,711:INFO:   <<< do_lower_case: False
2022-06-20 19:12:12,711:INFO:   <<< do_pretrain: False
2022-06-20 19:12:12,711:INFO:   <<< do_train: True
2022-06-20 19:12:12,711:INFO:   <<< epochs: 5
2022-06-20 19:12:12,711:INFO:   <<< eval_frame_order: 0
2022-06-20 19:12:12,711:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:12:12,711:INFO:   <<< feature_framerate: 1
2022-06-20 19:12:12,711:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:12:12,711:INFO:   <<< fp16: False
2022-06-20 19:12:12,711:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:12:12,711:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:12:12,711:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:12:12,712:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:12:12,712:INFO:   <<< init_model: None
2022-06-20 19:12:12,712:INFO:   <<< linear_patch: 2d
2022-06-20 19:12:12,712:INFO:   <<< local_rank: 0
2022-06-20 19:12:12,712:INFO:   <<< loose_type: True
2022-06-20 19:12:12,712:INFO:   <<< lr: 0.0001
2022-06-20 19:12:12,712:INFO:   <<< lr_decay: 0.9
2022-06-20 19:12:12,712:INFO:   <<< margin: 0.1
2022-06-20 19:12:12,712:INFO:   <<< max_frames: 12
2022-06-20 19:12:12,712:INFO:   <<< max_words: 32
2022-06-20 19:12:12,712:INFO:   <<< n_display: 50
2022-06-20 19:12:12,712:INFO:   <<< n_gpu: 1
2022-06-20 19:12:12,712:INFO:   <<< n_pair: 1
2022-06-20 19:12:12,712:INFO:   <<< negative_weighting: 1
2022-06-20 19:12:12,712:INFO:   <<< num_thread_reader: 2
2022-06-20 19:12:12,712:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:12:12,712:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:12:12,712:INFO:   <<< rank: 0
2022-06-20 19:12:12,712:INFO:   <<< resume_model: None
2022-06-20 19:12:12,712:INFO:   <<< sampled_use_mil: False
2022-06-20 19:12:12,713:INFO:   <<< seed: 42
2022-06-20 19:12:12,713:INFO:   <<< sim_header: meanP
2022-06-20 19:12:12,713:INFO:   <<< slice_framepos: 2
2022-06-20 19:12:12,713:INFO:   <<< task_type: retrieval
2022-06-20 19:12:12,713:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:12:12,713:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:12:12,713:INFO:   <<< train_frame_order: 0
2022-06-20 19:12:12,713:INFO:   <<< use_mil: False
2022-06-20 19:12:12,713:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:12:12,713:INFO:   <<< video_dim: 1024
2022-06-20 19:12:12,713:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:12:12,713:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:12:12,713:INFO:   <<< world_size: 2
2022-06-20 19:12:12,713:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:14:08,232:INFO: Effective parameters:
2022-06-20 19:14:08,233:INFO:   <<< batch_size: 256
2022-06-20 19:14:08,233:INFO:   <<< batch_size_val: 16
2022-06-20 19:14:08,233:INFO:   <<< cache_dir: 
2022-06-20 19:14:08,233:INFO:   <<< coef_lr: 0.001
2022-06-20 19:14:08,233:INFO:   <<< cross_model: cross-base
2022-06-20 19:14:08,233:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:14:08,233:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:14:08,233:INFO:   <<< datatype: msvd
2022-06-20 19:14:08,233:INFO:   <<< do_eval: False
2022-06-20 19:14:08,233:INFO:   <<< do_lower_case: False
2022-06-20 19:14:08,233:INFO:   <<< do_pretrain: False
2022-06-20 19:14:08,233:INFO:   <<< do_train: True
2022-06-20 19:14:08,233:INFO:   <<< epochs: 5
2022-06-20 19:14:08,233:INFO:   <<< eval_frame_order: 0
2022-06-20 19:14:08,233:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:14:08,233:INFO:   <<< feature_framerate: 1
2022-06-20 19:14:08,233:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:14:08,233:INFO:   <<< fp16: False
2022-06-20 19:14:08,233:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:14:08,233:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:14:08,233:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:14:08,233:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:14:08,234:INFO:   <<< init_model: None
2022-06-20 19:14:08,234:INFO:   <<< linear_patch: 2d
2022-06-20 19:14:08,234:INFO:   <<< local_rank: 0
2022-06-20 19:14:08,234:INFO:   <<< loose_type: True
2022-06-20 19:14:08,234:INFO:   <<< lr: 0.0001
2022-06-20 19:14:08,234:INFO:   <<< lr_decay: 0.9
2022-06-20 19:14:08,234:INFO:   <<< margin: 0.1
2022-06-20 19:14:08,234:INFO:   <<< max_frames: 12
2022-06-20 19:14:08,234:INFO:   <<< max_words: 32
2022-06-20 19:14:08,234:INFO:   <<< n_display: 50
2022-06-20 19:14:08,234:INFO:   <<< n_gpu: 1
2022-06-20 19:14:08,234:INFO:   <<< n_pair: 1
2022-06-20 19:14:08,234:INFO:   <<< negative_weighting: 1
2022-06-20 19:14:08,234:INFO:   <<< num_thread_reader: 2
2022-06-20 19:14:08,234:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:14:08,234:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:14:08,234:INFO:   <<< rank: 0
2022-06-20 19:14:08,234:INFO:   <<< resume_model: None
2022-06-20 19:14:08,234:INFO:   <<< sampled_use_mil: False
2022-06-20 19:14:08,234:INFO:   <<< seed: 42
2022-06-20 19:14:08,234:INFO:   <<< sim_header: meanP
2022-06-20 19:14:08,234:INFO:   <<< slice_framepos: 2
2022-06-20 19:14:08,234:INFO:   <<< task_type: retrieval
2022-06-20 19:14:08,234:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:14:08,234:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:14:08,234:INFO:   <<< train_frame_order: 0
2022-06-20 19:14:08,234:INFO:   <<< use_mil: False
2022-06-20 19:14:08,234:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:14:08,234:INFO:   <<< video_dim: 1024
2022-06-20 19:14:08,235:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:14:08,235:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:14:08,235:INFO:   <<< world_size: 1
2022-06-20 19:14:08,235:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:14:08,954:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:14:08,955:WARNING: Test retrieval by loose type.
2022-06-20 19:14:08,955:WARNING: 	 embed_dim: 512
2022-06-20 19:14:08,955:WARNING: 	 image_resolution: 224
2022-06-20 19:14:08,955:WARNING: 	 vision_layers: 12
2022-06-20 19:14:08,955:WARNING: 	 vision_width: 768
2022-06-20 19:14:08,955:WARNING: 	 vision_patch_size: 32
2022-06-20 19:14:08,955:WARNING: 	 context_length: 77
2022-06-20 19:14:08,955:WARNING: 	 vocab_size: 49408
2022-06-20 19:14:08,956:WARNING: 	 transformer_width: 512
2022-06-20 19:14:08,956:WARNING: 	 transformer_heads: 8
2022-06-20 19:14:08,956:WARNING: 	 transformer_layers: 12
2022-06-20 19:14:08,956:WARNING: 		 linear_patch: 2d
2022-06-20 19:14:08,956:WARNING: 	 cut_top_layer: 0
2022-06-20 19:14:54,616:INFO: Effective parameters:
2022-06-20 19:14:54,616:INFO:   <<< batch_size: 256
2022-06-20 19:14:54,616:INFO:   <<< batch_size_val: 16
2022-06-20 19:14:54,616:INFO:   <<< cache_dir: 
2022-06-20 19:14:54,616:INFO:   <<< coef_lr: 0.001
2022-06-20 19:14:54,616:INFO:   <<< cross_model: cross-base
2022-06-20 19:14:54,616:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:14:54,616:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:14:54,616:INFO:   <<< datatype: msvd
2022-06-20 19:14:54,616:INFO:   <<< do_eval: False
2022-06-20 19:14:54,616:INFO:   <<< do_lower_case: False
2022-06-20 19:14:54,616:INFO:   <<< do_pretrain: False
2022-06-20 19:14:54,616:INFO:   <<< do_train: True
2022-06-20 19:14:54,616:INFO:   <<< epochs: 5
2022-06-20 19:14:54,617:INFO:   <<< eval_frame_order: 0
2022-06-20 19:14:54,617:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:14:54,617:INFO:   <<< feature_framerate: 1
2022-06-20 19:14:54,617:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:14:54,617:INFO:   <<< fp16: False
2022-06-20 19:14:54,617:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:14:54,617:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:14:54,617:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:14:54,617:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:14:54,617:INFO:   <<< init_model: None
2022-06-20 19:14:54,617:INFO:   <<< linear_patch: 2d
2022-06-20 19:14:54,617:INFO:   <<< local_rank: 0
2022-06-20 19:14:54,617:INFO:   <<< loose_type: True
2022-06-20 19:14:54,617:INFO:   <<< lr: 0.0001
2022-06-20 19:14:54,617:INFO:   <<< lr_decay: 0.9
2022-06-20 19:14:54,617:INFO:   <<< margin: 0.1
2022-06-20 19:14:54,617:INFO:   <<< max_frames: 12
2022-06-20 19:14:54,617:INFO:   <<< max_words: 32
2022-06-20 19:14:54,617:INFO:   <<< n_display: 50
2022-06-20 19:14:54,617:INFO:   <<< n_gpu: 1
2022-06-20 19:14:54,617:INFO:   <<< n_pair: 1
2022-06-20 19:14:54,617:INFO:   <<< negative_weighting: 1
2022-06-20 19:14:54,618:INFO:   <<< num_thread_reader: 2
2022-06-20 19:14:54,618:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:14:54,618:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:14:54,618:INFO:   <<< rank: 0
2022-06-20 19:14:54,618:INFO:   <<< resume_model: None
2022-06-20 19:14:54,618:INFO:   <<< sampled_use_mil: False
2022-06-20 19:14:54,618:INFO:   <<< seed: 42
2022-06-20 19:14:54,618:INFO:   <<< sim_header: meanP
2022-06-20 19:14:54,618:INFO:   <<< slice_framepos: 2
2022-06-20 19:14:54,618:INFO:   <<< task_type: retrieval
2022-06-20 19:14:54,618:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:14:54,618:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:14:54,618:INFO:   <<< train_frame_order: 0
2022-06-20 19:14:54,618:INFO:   <<< use_mil: False
2022-06-20 19:14:54,618:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:14:54,618:INFO:   <<< video_dim: 1024
2022-06-20 19:14:54,618:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:14:54,618:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:14:54,618:INFO:   <<< world_size: 1
2022-06-20 19:14:54,618:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:14:55,309:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:14:55,309:WARNING: Test retrieval by loose type.
2022-06-20 19:14:55,309:WARNING: 	 embed_dim: 512
2022-06-20 19:14:55,309:WARNING: 	 image_resolution: 224
2022-06-20 19:14:55,309:WARNING: 	 vision_layers: 12
2022-06-20 19:14:55,309:WARNING: 	 vision_width: 768
2022-06-20 19:14:55,310:WARNING: 	 vision_patch_size: 32
2022-06-20 19:14:55,310:WARNING: 	 context_length: 77
2022-06-20 19:14:55,310:WARNING: 	 vocab_size: 49408
2022-06-20 19:14:55,310:WARNING: 	 transformer_width: 512
2022-06-20 19:14:55,310:WARNING: 	 transformer_heads: 8
2022-06-20 19:14:55,310:WARNING: 	 transformer_layers: 12
2022-06-20 19:14:55,310:WARNING: 		 linear_patch: 2d
2022-06-20 19:14:55,310:WARNING: 	 cut_top_layer: 0
2022-06-20 19:16:00,451:INFO: Effective parameters:
2022-06-20 19:16:00,451:INFO:   <<< batch_size: 256
2022-06-20 19:16:00,451:INFO:   <<< batch_size_val: 16
2022-06-20 19:16:00,451:INFO:   <<< cache_dir: 
2022-06-20 19:16:00,451:INFO:   <<< coef_lr: 0.001
2022-06-20 19:16:00,451:INFO:   <<< cross_model: cross-base
2022-06-20 19:16:00,451:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:16:00,451:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:16:00,451:INFO:   <<< datatype: msvd
2022-06-20 19:16:00,451:INFO:   <<< do_eval: False
2022-06-20 19:16:00,451:INFO:   <<< do_lower_case: False
2022-06-20 19:16:00,451:INFO:   <<< do_pretrain: False
2022-06-20 19:16:00,451:INFO:   <<< do_train: True
2022-06-20 19:16:00,451:INFO:   <<< epochs: 5
2022-06-20 19:16:00,451:INFO:   <<< eval_frame_order: 0
2022-06-20 19:16:00,451:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:16:00,452:INFO:   <<< feature_framerate: 1
2022-06-20 19:16:00,452:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:16:00,452:INFO:   <<< fp16: False
2022-06-20 19:16:00,452:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:16:00,452:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:16:00,452:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:16:00,452:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:16:00,452:INFO:   <<< init_model: None
2022-06-20 19:16:00,452:INFO:   <<< linear_patch: 2d
2022-06-20 19:16:00,452:INFO:   <<< local_rank: 0
2022-06-20 19:16:00,452:INFO:   <<< loose_type: True
2022-06-20 19:16:00,452:INFO:   <<< lr: 0.0001
2022-06-20 19:16:00,452:INFO:   <<< lr_decay: 0.9
2022-06-20 19:16:00,452:INFO:   <<< margin: 0.1
2022-06-20 19:16:00,452:INFO:   <<< max_frames: 12
2022-06-20 19:16:00,452:INFO:   <<< max_words: 32
2022-06-20 19:16:00,452:INFO:   <<< n_display: 50
2022-06-20 19:16:00,452:INFO:   <<< n_gpu: 1
2022-06-20 19:16:00,452:INFO:   <<< n_pair: 1
2022-06-20 19:16:00,452:INFO:   <<< negative_weighting: 1
2022-06-20 19:16:00,452:INFO:   <<< num_thread_reader: 2
2022-06-20 19:16:00,452:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:16:00,452:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:16:00,452:INFO:   <<< rank: 0
2022-06-20 19:16:00,452:INFO:   <<< resume_model: None
2022-06-20 19:16:00,452:INFO:   <<< sampled_use_mil: False
2022-06-20 19:16:00,452:INFO:   <<< seed: 42
2022-06-20 19:16:00,453:INFO:   <<< sim_header: meanP
2022-06-20 19:16:00,453:INFO:   <<< slice_framepos: 2
2022-06-20 19:16:00,453:INFO:   <<< task_type: retrieval
2022-06-20 19:16:00,453:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:16:00,453:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:16:00,453:INFO:   <<< train_frame_order: 0
2022-06-20 19:16:00,453:INFO:   <<< use_mil: False
2022-06-20 19:16:00,453:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:16:00,453:INFO:   <<< video_dim: 1024
2022-06-20 19:16:00,453:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:16:00,453:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:16:00,453:INFO:   <<< world_size: 1
2022-06-20 19:16:00,453:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:16:01,250:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:16:01,251:WARNING: Test retrieval by loose type.
2022-06-20 19:16:01,251:WARNING: 	 embed_dim: 512
2022-06-20 19:16:01,251:WARNING: 	 image_resolution: 224
2022-06-20 19:16:01,251:WARNING: 	 vision_layers: 12
2022-06-20 19:16:01,251:WARNING: 	 vision_width: 768
2022-06-20 19:16:01,251:WARNING: 	 vision_patch_size: 32
2022-06-20 19:16:01,251:WARNING: 	 context_length: 77
2022-06-20 19:16:01,251:WARNING: 	 vocab_size: 49408
2022-06-20 19:16:01,251:WARNING: 	 transformer_width: 512
2022-06-20 19:16:01,251:WARNING: 	 transformer_heads: 8
2022-06-20 19:16:01,251:WARNING: 	 transformer_layers: 12
2022-06-20 19:16:01,251:WARNING: 		 linear_patch: 2d
2022-06-20 19:16:01,251:WARNING: 	 cut_top_layer: 0
2022-06-20 19:17:25,311:INFO: Effective parameters:
2022-06-20 19:17:25,311:INFO:   <<< batch_size: 256
2022-06-20 19:17:25,311:INFO:   <<< batch_size_val: 16
2022-06-20 19:17:25,311:INFO:   <<< cache_dir: 
2022-06-20 19:17:25,311:INFO:   <<< coef_lr: 0.001
2022-06-20 19:17:25,311:INFO:   <<< cross_model: cross-base
2022-06-20 19:17:25,311:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:17:25,311:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:17:25,311:INFO:   <<< datatype: msvd
2022-06-20 19:17:25,311:INFO:   <<< do_eval: False
2022-06-20 19:17:25,311:INFO:   <<< do_lower_case: False
2022-06-20 19:17:25,311:INFO:   <<< do_pretrain: False
2022-06-20 19:17:25,311:INFO:   <<< do_train: True
2022-06-20 19:17:25,311:INFO:   <<< epochs: 5
2022-06-20 19:17:25,311:INFO:   <<< eval_frame_order: 0
2022-06-20 19:17:25,311:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:17:25,311:INFO:   <<< feature_framerate: 1
2022-06-20 19:17:25,311:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:17:25,311:INFO:   <<< fp16: False
2022-06-20 19:17:25,311:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:17:25,311:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:17:25,312:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:17:25,312:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:17:25,312:INFO:   <<< init_model: None
2022-06-20 19:17:25,312:INFO:   <<< linear_patch: 2d
2022-06-20 19:17:25,312:INFO:   <<< local_rank: 0
2022-06-20 19:17:25,312:INFO:   <<< loose_type: True
2022-06-20 19:17:25,312:INFO:   <<< lr: 0.0001
2022-06-20 19:17:25,312:INFO:   <<< lr_decay: 0.9
2022-06-20 19:17:25,312:INFO:   <<< margin: 0.1
2022-06-20 19:17:25,312:INFO:   <<< max_frames: 12
2022-06-20 19:17:25,312:INFO:   <<< max_words: 32
2022-06-20 19:17:25,312:INFO:   <<< n_display: 50
2022-06-20 19:17:25,312:INFO:   <<< n_gpu: 1
2022-06-20 19:17:25,312:INFO:   <<< n_pair: 1
2022-06-20 19:17:25,312:INFO:   <<< negative_weighting: 1
2022-06-20 19:17:25,312:INFO:   <<< num_thread_reader: 2
2022-06-20 19:17:25,312:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:17:25,312:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:17:25,312:INFO:   <<< rank: 0
2022-06-20 19:17:25,312:INFO:   <<< resume_model: None
2022-06-20 19:17:25,312:INFO:   <<< sampled_use_mil: False
2022-06-20 19:17:25,312:INFO:   <<< seed: 42
2022-06-20 19:17:25,312:INFO:   <<< sim_header: meanP
2022-06-20 19:17:25,312:INFO:   <<< slice_framepos: 2
2022-06-20 19:17:25,312:INFO:   <<< task_type: retrieval
2022-06-20 19:17:25,312:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:17:25,312:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:17:25,312:INFO:   <<< train_frame_order: 0
2022-06-20 19:17:25,312:INFO:   <<< use_mil: False
2022-06-20 19:17:25,312:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:17:25,312:INFO:   <<< video_dim: 1024
2022-06-20 19:17:25,312:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:17:25,312:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:17:25,312:INFO:   <<< world_size: 1
2022-06-20 19:17:25,313:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:17:25,988:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:17:25,989:WARNING: Test retrieval by loose type.
2022-06-20 19:17:25,989:WARNING: 	 embed_dim: 512
2022-06-20 19:17:25,989:WARNING: 	 image_resolution: 224
2022-06-20 19:17:25,989:WARNING: 	 vision_layers: 12
2022-06-20 19:17:25,989:WARNING: 	 vision_width: 768
2022-06-20 19:17:25,989:WARNING: 	 vision_patch_size: 32
2022-06-20 19:17:25,989:WARNING: 	 context_length: 77
2022-06-20 19:17:25,989:WARNING: 	 vocab_size: 49408
2022-06-20 19:17:25,989:WARNING: 	 transformer_width: 512
2022-06-20 19:17:25,989:WARNING: 	 transformer_heads: 8
2022-06-20 19:17:25,989:WARNING: 	 transformer_layers: 12
2022-06-20 19:17:25,989:WARNING: 		 linear_patch: 2d
2022-06-20 19:17:25,989:WARNING: 	 cut_top_layer: 0
2022-06-20 19:18:14,740:INFO: Effective parameters:
2022-06-20 19:18:14,741:INFO:   <<< batch_size: 256
2022-06-20 19:18:14,741:INFO:   <<< batch_size_val: 16
2022-06-20 19:18:14,741:INFO:   <<< cache_dir: 
2022-06-20 19:18:14,741:INFO:   <<< coef_lr: 0.001
2022-06-20 19:18:14,741:INFO:   <<< cross_model: cross-base
2022-06-20 19:18:14,741:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:18:14,741:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:18:14,741:INFO:   <<< datatype: msvd
2022-06-20 19:18:14,741:INFO:   <<< do_eval: False
2022-06-20 19:18:14,741:INFO:   <<< do_lower_case: False
2022-06-20 19:18:14,741:INFO:   <<< do_pretrain: False
2022-06-20 19:18:14,741:INFO:   <<< do_train: True
2022-06-20 19:18:14,741:INFO:   <<< epochs: 5
2022-06-20 19:18:14,741:INFO:   <<< eval_frame_order: 0
2022-06-20 19:18:14,741:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:18:14,741:INFO:   <<< feature_framerate: 1
2022-06-20 19:18:14,741:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:18:14,741:INFO:   <<< fp16: False
2022-06-20 19:18:14,741:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:18:14,741:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:18:14,741:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:18:14,741:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:18:14,741:INFO:   <<< init_model: None
2022-06-20 19:18:14,741:INFO:   <<< linear_patch: 2d
2022-06-20 19:18:14,741:INFO:   <<< local_rank: 0
2022-06-20 19:18:14,741:INFO:   <<< loose_type: True
2022-06-20 19:18:14,741:INFO:   <<< lr: 0.0001
2022-06-20 19:18:14,741:INFO:   <<< lr_decay: 0.9
2022-06-20 19:18:14,742:INFO:   <<< margin: 0.1
2022-06-20 19:18:14,742:INFO:   <<< max_frames: 12
2022-06-20 19:18:14,742:INFO:   <<< max_words: 32
2022-06-20 19:18:14,742:INFO:   <<< n_display: 50
2022-06-20 19:18:14,742:INFO:   <<< n_gpu: 1
2022-06-20 19:18:14,742:INFO:   <<< n_pair: 1
2022-06-20 19:18:14,742:INFO:   <<< negative_weighting: 1
2022-06-20 19:18:14,742:INFO:   <<< num_thread_reader: 2
2022-06-20 19:18:14,742:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:18:14,742:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:18:14,742:INFO:   <<< rank: 0
2022-06-20 19:18:14,742:INFO:   <<< resume_model: None
2022-06-20 19:18:14,742:INFO:   <<< sampled_use_mil: False
2022-06-20 19:18:14,742:INFO:   <<< seed: 42
2022-06-20 19:18:14,742:INFO:   <<< sim_header: meanP
2022-06-20 19:18:14,742:INFO:   <<< slice_framepos: 2
2022-06-20 19:18:14,742:INFO:   <<< task_type: retrieval
2022-06-20 19:18:14,742:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:18:14,742:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:18:14,742:INFO:   <<< train_frame_order: 0
2022-06-20 19:18:14,742:INFO:   <<< use_mil: False
2022-06-20 19:18:14,742:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:18:14,742:INFO:   <<< video_dim: 1024
2022-06-20 19:18:14,742:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:18:14,742:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:18:14,742:INFO:   <<< world_size: 1
2022-06-20 19:18:14,742:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:18:15,456:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:18:15,456:WARNING: Test retrieval by loose type.
2022-06-20 19:18:15,457:WARNING: 	 embed_dim: 512
2022-06-20 19:18:15,457:WARNING: 	 image_resolution: 224
2022-06-20 19:18:15,457:WARNING: 	 vision_layers: 12
2022-06-20 19:18:15,457:WARNING: 	 vision_width: 768
2022-06-20 19:18:15,457:WARNING: 	 vision_patch_size: 32
2022-06-20 19:18:15,457:WARNING: 	 context_length: 77
2022-06-20 19:18:15,457:WARNING: 	 vocab_size: 49408
2022-06-20 19:18:15,457:WARNING: 	 transformer_width: 512
2022-06-20 19:18:15,457:WARNING: 	 transformer_heads: 8
2022-06-20 19:18:15,457:WARNING: 	 transformer_layers: 12
2022-06-20 19:18:15,457:WARNING: 		 linear_patch: 2d
2022-06-20 19:18:15,457:WARNING: 	 cut_top_layer: 0
2022-06-20 19:24:02,598:INFO: Effective parameters:
2022-06-20 19:24:02,599:INFO:   <<< batch_size: 256
2022-06-20 19:24:02,599:INFO:   <<< batch_size_val: 16
2022-06-20 19:24:02,599:INFO:   <<< cache_dir: 
2022-06-20 19:24:02,599:INFO:   <<< coef_lr: 0.001
2022-06-20 19:24:02,599:INFO:   <<< cross_model: cross-base
2022-06-20 19:24:02,599:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:24:02,599:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:24:02,599:INFO:   <<< datatype: msvd
2022-06-20 19:24:02,599:INFO:   <<< do_eval: False
2022-06-20 19:24:02,599:INFO:   <<< do_lower_case: False
2022-06-20 19:24:02,599:INFO:   <<< do_pretrain: False
2022-06-20 19:24:02,599:INFO:   <<< do_train: True
2022-06-20 19:24:02,599:INFO:   <<< epochs: 5
2022-06-20 19:24:02,599:INFO:   <<< eval_frame_order: 0
2022-06-20 19:24:02,599:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:24:02,599:INFO:   <<< feature_framerate: 1
2022-06-20 19:24:02,599:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:24:02,599:INFO:   <<< fp16: False
2022-06-20 19:24:02,599:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:24:02,599:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:24:02,599:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:24:02,599:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:24:02,599:INFO:   <<< init_model: None
2022-06-20 19:24:02,599:INFO:   <<< linear_patch: 2d
2022-06-20 19:24:02,599:INFO:   <<< local_rank: 0
2022-06-20 19:24:02,599:INFO:   <<< loose_type: True
2022-06-20 19:24:02,599:INFO:   <<< lr: 0.0001
2022-06-20 19:24:02,599:INFO:   <<< lr_decay: 0.9
2022-06-20 19:24:02,599:INFO:   <<< margin: 0.1
2022-06-20 19:24:02,599:INFO:   <<< max_frames: 12
2022-06-20 19:24:02,599:INFO:   <<< max_words: 32
2022-06-20 19:24:02,600:INFO:   <<< n_display: 50
2022-06-20 19:24:02,600:INFO:   <<< n_gpu: 1
2022-06-20 19:24:02,600:INFO:   <<< n_pair: 1
2022-06-20 19:24:02,600:INFO:   <<< negative_weighting: 1
2022-06-20 19:24:02,600:INFO:   <<< num_thread_reader: 2
2022-06-20 19:24:02,600:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:24:02,600:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:24:02,600:INFO:   <<< rank: 0
2022-06-20 19:24:02,600:INFO:   <<< resume_model: None
2022-06-20 19:24:02,600:INFO:   <<< sampled_use_mil: False
2022-06-20 19:24:02,600:INFO:   <<< seed: 42
2022-06-20 19:24:02,600:INFO:   <<< sim_header: meanP
2022-06-20 19:24:02,600:INFO:   <<< slice_framepos: 2
2022-06-20 19:24:02,600:INFO:   <<< task_type: retrieval
2022-06-20 19:24:02,600:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:24:02,600:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:24:02,600:INFO:   <<< train_frame_order: 0
2022-06-20 19:24:02,600:INFO:   <<< use_mil: False
2022-06-20 19:24:02,600:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:24:02,600:INFO:   <<< video_dim: 1024
2022-06-20 19:24:02,600:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:24:02,600:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:24:02,600:INFO:   <<< world_size: 1
2022-06-20 19:24:02,600:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:24:03,357:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:24:03,357:WARNING: Test retrieval by loose type.
2022-06-20 19:24:03,357:WARNING: 	 embed_dim: 512
2022-06-20 19:24:03,357:WARNING: 	 image_resolution: 224
2022-06-20 19:24:03,357:WARNING: 	 vision_layers: 12
2022-06-20 19:24:03,358:WARNING: 	 vision_width: 768
2022-06-20 19:24:03,358:WARNING: 	 vision_patch_size: 32
2022-06-20 19:24:03,358:WARNING: 	 context_length: 77
2022-06-20 19:24:03,358:WARNING: 	 vocab_size: 49408
2022-06-20 19:24:03,358:WARNING: 	 transformer_width: 512
2022-06-20 19:24:03,358:WARNING: 	 transformer_heads: 8
2022-06-20 19:24:03,358:WARNING: 	 transformer_layers: 12
2022-06-20 19:24:03,358:WARNING: 		 linear_patch: 2d
2022-06-20 19:24:03,358:WARNING: 	 cut_top_layer: 0
2022-06-20 19:25:54,535:INFO: Effective parameters:
2022-06-20 19:25:54,535:INFO:   <<< batch_size: 256
2022-06-20 19:25:54,535:INFO:   <<< batch_size_val: 16
2022-06-20 19:25:54,535:INFO:   <<< cache_dir: 
2022-06-20 19:25:54,535:INFO:   <<< coef_lr: 0.001
2022-06-20 19:25:54,535:INFO:   <<< cross_model: cross-base
2022-06-20 19:25:54,535:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:25:54,535:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:25:54,535:INFO:   <<< datatype: msvd
2022-06-20 19:25:54,536:INFO:   <<< do_eval: False
2022-06-20 19:25:54,536:INFO:   <<< do_lower_case: False
2022-06-20 19:25:54,536:INFO:   <<< do_pretrain: False
2022-06-20 19:25:54,536:INFO:   <<< do_train: True
2022-06-20 19:25:54,536:INFO:   <<< epochs: 5
2022-06-20 19:25:54,536:INFO:   <<< eval_frame_order: 0
2022-06-20 19:25:54,536:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:25:54,536:INFO:   <<< feature_framerate: 1
2022-06-20 19:25:54,536:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:25:54,536:INFO:   <<< fp16: False
2022-06-20 19:25:54,536:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:25:54,536:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:25:54,536:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:25:54,536:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:25:54,536:INFO:   <<< init_model: None
2022-06-20 19:25:54,536:INFO:   <<< linear_patch: 3d
2022-06-20 19:25:54,536:INFO:   <<< local_rank: 0
2022-06-20 19:25:54,536:INFO:   <<< loose_type: True
2022-06-20 19:25:54,536:INFO:   <<< lr: 0.0001
2022-06-20 19:25:54,536:INFO:   <<< lr_decay: 0.9
2022-06-20 19:25:54,536:INFO:   <<< margin: 0.1
2022-06-20 19:25:54,536:INFO:   <<< max_frames: 12
2022-06-20 19:25:54,536:INFO:   <<< max_words: 32
2022-06-20 19:25:54,536:INFO:   <<< n_display: 50
2022-06-20 19:25:54,536:INFO:   <<< n_gpu: 1
2022-06-20 19:25:54,536:INFO:   <<< n_pair: 1
2022-06-20 19:25:54,537:INFO:   <<< negative_weighting: 1
2022-06-20 19:25:54,537:INFO:   <<< num_thread_reader: 2
2022-06-20 19:25:54,537:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:25:54,537:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:25:54,537:INFO:   <<< rank: 0
2022-06-20 19:25:54,537:INFO:   <<< resume_model: None
2022-06-20 19:25:54,537:INFO:   <<< sampled_use_mil: False
2022-06-20 19:25:54,537:INFO:   <<< seed: 42
2022-06-20 19:25:54,537:INFO:   <<< sim_header: meanP
2022-06-20 19:25:54,537:INFO:   <<< slice_framepos: 2
2022-06-20 19:25:54,537:INFO:   <<< task_type: retrieval
2022-06-20 19:25:54,537:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:25:54,537:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:25:54,537:INFO:   <<< train_frame_order: 0
2022-06-20 19:25:54,537:INFO:   <<< use_mil: False
2022-06-20 19:25:54,537:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:25:54,537:INFO:   <<< video_dim: 1024
2022-06-20 19:25:54,537:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:25:54,537:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:25:54,537:INFO:   <<< world_size: 1
2022-06-20 19:25:54,537:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:25:55,141:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:25:55,142:WARNING: Test retrieval by loose type.
2022-06-20 19:25:55,142:WARNING: 	 embed_dim: 512
2022-06-20 19:25:55,142:WARNING: 	 image_resolution: 224
2022-06-20 19:25:55,142:WARNING: 	 vision_layers: 12
2022-06-20 19:25:55,142:WARNING: 	 vision_width: 768
2022-06-20 19:25:55,142:WARNING: 	 vision_patch_size: 32
2022-06-20 19:25:55,142:WARNING: 	 context_length: 77
2022-06-20 19:25:55,142:WARNING: 	 vocab_size: 49408
2022-06-20 19:25:55,142:WARNING: 	 transformer_width: 512
2022-06-20 19:25:55,143:WARNING: 	 transformer_heads: 8
2022-06-20 19:25:55,143:WARNING: 	 transformer_layers: 12
2022-06-20 19:25:55,143:WARNING: 		 linear_patch: 3d
2022-06-20 19:25:55,143:WARNING: 	 cut_top_layer: 0
2022-06-20 19:27:25,799:INFO: Effective parameters:
2022-06-20 19:27:25,799:INFO:   <<< batch_size: 256
2022-06-20 19:27:25,799:INFO:   <<< batch_size_val: 16
2022-06-20 19:27:25,799:INFO:   <<< cache_dir: 
2022-06-20 19:27:25,799:INFO:   <<< coef_lr: 0.001
2022-06-20 19:27:25,799:INFO:   <<< cross_model: cross-base
2022-06-20 19:27:25,800:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:27:25,800:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:27:25,800:INFO:   <<< datatype: msvd
2022-06-20 19:27:25,800:INFO:   <<< do_eval: False
2022-06-20 19:27:25,800:INFO:   <<< do_lower_case: False
2022-06-20 19:27:25,800:INFO:   <<< do_pretrain: False
2022-06-20 19:27:25,800:INFO:   <<< do_train: True
2022-06-20 19:27:25,800:INFO:   <<< epochs: 5
2022-06-20 19:27:25,800:INFO:   <<< eval_frame_order: 0
2022-06-20 19:27:25,800:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:27:25,800:INFO:   <<< feature_framerate: 1
2022-06-20 19:27:25,800:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:27:25,800:INFO:   <<< fp16: False
2022-06-20 19:27:25,800:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:27:25,800:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:27:25,800:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:27:25,800:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:27:25,800:INFO:   <<< init_model: None
2022-06-20 19:27:25,800:INFO:   <<< linear_patch: 3d
2022-06-20 19:27:25,800:INFO:   <<< local_rank: 0
2022-06-20 19:27:25,800:INFO:   <<< loose_type: True
2022-06-20 19:27:25,800:INFO:   <<< lr: 0.0001
2022-06-20 19:27:25,800:INFO:   <<< lr_decay: 0.9
2022-06-20 19:27:25,800:INFO:   <<< margin: 0.1
2022-06-20 19:27:25,800:INFO:   <<< max_frames: 12
2022-06-20 19:27:25,800:INFO:   <<< max_words: 32
2022-06-20 19:27:25,800:INFO:   <<< n_display: 50
2022-06-20 19:27:25,800:INFO:   <<< n_gpu: 1
2022-06-20 19:27:25,800:INFO:   <<< n_pair: 1
2022-06-20 19:27:25,800:INFO:   <<< negative_weighting: 1
2022-06-20 19:27:25,800:INFO:   <<< num_thread_reader: 2
2022-06-20 19:27:25,800:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:27:25,800:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:27:25,800:INFO:   <<< rank: 0
2022-06-20 19:27:25,800:INFO:   <<< resume_model: None
2022-06-20 19:27:25,800:INFO:   <<< sampled_use_mil: False
2022-06-20 19:27:25,801:INFO:   <<< seed: 42
2022-06-20 19:27:25,801:INFO:   <<< sim_header: meanP
2022-06-20 19:27:25,801:INFO:   <<< slice_framepos: 2
2022-06-20 19:27:25,801:INFO:   <<< task_type: retrieval
2022-06-20 19:27:25,801:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:27:25,801:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:27:25,801:INFO:   <<< train_frame_order: 0
2022-06-20 19:27:25,801:INFO:   <<< use_mil: False
2022-06-20 19:27:25,801:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:27:25,801:INFO:   <<< video_dim: 1024
2022-06-20 19:27:25,801:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:27:25,801:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:27:25,801:INFO:   <<< world_size: 1
2022-06-20 19:27:25,801:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:27:26,519:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:27:26,519:WARNING: Test retrieval by loose type.
2022-06-20 19:27:26,519:WARNING: 	 embed_dim: 512
2022-06-20 19:27:26,519:WARNING: 	 image_resolution: 224
2022-06-20 19:27:26,520:WARNING: 	 vision_layers: 12
2022-06-20 19:27:26,520:WARNING: 	 vision_width: 768
2022-06-20 19:27:26,520:WARNING: 	 vision_patch_size: 32
2022-06-20 19:27:26,520:WARNING: 	 context_length: 77
2022-06-20 19:27:26,520:WARNING: 	 vocab_size: 49408
2022-06-20 19:27:26,520:WARNING: 	 transformer_width: 512
2022-06-20 19:27:26,520:WARNING: 	 transformer_heads: 8
2022-06-20 19:27:26,520:WARNING: 	 transformer_layers: 12
2022-06-20 19:27:26,520:WARNING: 		 linear_patch: 3d
2022-06-20 19:27:26,520:WARNING: 	 cut_top_layer: 0
2022-06-20 19:28:31,306:INFO: Effective parameters:
2022-06-20 19:28:31,307:INFO:   <<< batch_size: 256
2022-06-20 19:28:31,307:INFO:   <<< batch_size_val: 16
2022-06-20 19:28:31,307:INFO:   <<< cache_dir: 
2022-06-20 19:28:31,307:INFO:   <<< coef_lr: 0.001
2022-06-20 19:28:31,307:INFO:   <<< cross_model: cross-base
2022-06-20 19:28:31,307:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:28:31,307:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:28:31,307:INFO:   <<< datatype: msvd
2022-06-20 19:28:31,307:INFO:   <<< do_eval: False
2022-06-20 19:28:31,307:INFO:   <<< do_lower_case: False
2022-06-20 19:28:31,307:INFO:   <<< do_pretrain: False
2022-06-20 19:28:31,307:INFO:   <<< do_train: True
2022-06-20 19:28:31,307:INFO:   <<< epochs: 5
2022-06-20 19:28:31,307:INFO:   <<< eval_frame_order: 0
2022-06-20 19:28:31,307:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:28:31,307:INFO:   <<< feature_framerate: 1
2022-06-20 19:28:31,308:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:28:31,308:INFO:   <<< fp16: False
2022-06-20 19:28:31,308:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:28:31,308:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:28:31,308:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:28:31,308:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:28:31,308:INFO:   <<< init_model: None
2022-06-20 19:28:31,308:INFO:   <<< linear_patch: 3d
2022-06-20 19:28:31,308:INFO:   <<< local_rank: 0
2022-06-20 19:28:31,308:INFO:   <<< loose_type: True
2022-06-20 19:28:31,308:INFO:   <<< lr: 0.0001
2022-06-20 19:28:31,308:INFO:   <<< lr_decay: 0.9
2022-06-20 19:28:31,308:INFO:   <<< margin: 0.1
2022-06-20 19:28:31,308:INFO:   <<< max_frames: 12
2022-06-20 19:28:31,308:INFO:   <<< max_words: 32
2022-06-20 19:28:31,308:INFO:   <<< n_display: 50
2022-06-20 19:28:31,308:INFO:   <<< n_gpu: 1
2022-06-20 19:28:31,308:INFO:   <<< n_pair: 1
2022-06-20 19:28:31,308:INFO:   <<< negative_weighting: 1
2022-06-20 19:28:31,309:INFO:   <<< num_thread_reader: 2
2022-06-20 19:28:31,309:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:28:31,309:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:28:31,309:INFO:   <<< rank: 0
2022-06-20 19:28:31,309:INFO:   <<< resume_model: None
2022-06-20 19:28:31,309:INFO:   <<< sampled_use_mil: False
2022-06-20 19:28:31,309:INFO:   <<< seed: 42
2022-06-20 19:28:31,309:INFO:   <<< sim_header: meanP
2022-06-20 19:28:31,309:INFO:   <<< slice_framepos: 2
2022-06-20 19:28:31,309:INFO:   <<< task_type: retrieval
2022-06-20 19:28:31,309:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:28:31,309:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:28:31,309:INFO:   <<< train_frame_order: 0
2022-06-20 19:28:31,309:INFO:   <<< use_mil: False
2022-06-20 19:28:31,309:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:28:31,309:INFO:   <<< video_dim: 1024
2022-06-20 19:28:31,309:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:28:31,309:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:28:31,310:INFO:   <<< world_size: 1
2022-06-20 19:28:31,310:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:28:32,067:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:28:32,068:WARNING: Test retrieval by loose type.
2022-06-20 19:28:32,068:WARNING: 	 embed_dim: 512
2022-06-20 19:28:32,068:WARNING: 	 image_resolution: 224
2022-06-20 19:28:32,068:WARNING: 	 vision_layers: 12
2022-06-20 19:28:32,068:WARNING: 	 vision_width: 768
2022-06-20 19:28:32,068:WARNING: 	 vision_patch_size: 32
2022-06-20 19:28:32,068:WARNING: 	 context_length: 77
2022-06-20 19:28:32,068:WARNING: 	 vocab_size: 49408
2022-06-20 19:28:32,068:WARNING: 	 transformer_width: 512
2022-06-20 19:28:32,068:WARNING: 	 transformer_heads: 8
2022-06-20 19:28:32,068:WARNING: 	 transformer_layers: 12
2022-06-20 19:28:32,068:WARNING: 		 linear_patch: 3d
2022-06-20 19:28:32,068:WARNING: 	 cut_top_layer: 0
2022-06-20 19:29:34,862:INFO: Effective parameters:
2022-06-20 19:29:34,862:INFO:   <<< batch_size: 256
2022-06-20 19:29:34,862:INFO:   <<< batch_size_val: 16
2022-06-20 19:29:34,862:INFO:   <<< cache_dir: 
2022-06-20 19:29:34,862:INFO:   <<< coef_lr: 0.001
2022-06-20 19:29:34,862:INFO:   <<< cross_model: cross-base
2022-06-20 19:29:34,862:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:29:34,862:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:29:34,862:INFO:   <<< datatype: msvd
2022-06-20 19:29:34,862:INFO:   <<< do_eval: False
2022-06-20 19:29:34,862:INFO:   <<< do_lower_case: False
2022-06-20 19:29:34,862:INFO:   <<< do_pretrain: False
2022-06-20 19:29:34,862:INFO:   <<< do_train: True
2022-06-20 19:29:34,862:INFO:   <<< epochs: 5
2022-06-20 19:29:34,862:INFO:   <<< eval_frame_order: 0
2022-06-20 19:29:34,862:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:29:34,863:INFO:   <<< feature_framerate: 1
2022-06-20 19:29:34,863:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:29:34,863:INFO:   <<< fp16: False
2022-06-20 19:29:34,863:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:29:34,863:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:29:34,863:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:29:34,863:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:29:34,863:INFO:   <<< init_model: None
2022-06-20 19:29:34,863:INFO:   <<< linear_patch: 3d
2022-06-20 19:29:34,863:INFO:   <<< local_rank: 0
2022-06-20 19:29:34,863:INFO:   <<< loose_type: True
2022-06-20 19:29:34,863:INFO:   <<< lr: 0.0001
2022-06-20 19:29:34,863:INFO:   <<< lr_decay: 0.9
2022-06-20 19:29:34,863:INFO:   <<< margin: 0.1
2022-06-20 19:29:34,863:INFO:   <<< max_frames: 12
2022-06-20 19:29:34,863:INFO:   <<< max_words: 32
2022-06-20 19:29:34,863:INFO:   <<< n_display: 50
2022-06-20 19:29:34,863:INFO:   <<< n_gpu: 1
2022-06-20 19:29:34,863:INFO:   <<< n_pair: 1
2022-06-20 19:29:34,863:INFO:   <<< negative_weighting: 1
2022-06-20 19:29:34,863:INFO:   <<< num_thread_reader: 2
2022-06-20 19:29:34,863:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:29:34,863:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:29:34,863:INFO:   <<< rank: 0
2022-06-20 19:29:34,863:INFO:   <<< resume_model: None
2022-06-20 19:29:34,863:INFO:   <<< sampled_use_mil: False
2022-06-20 19:29:34,863:INFO:   <<< seed: 42
2022-06-20 19:29:34,863:INFO:   <<< sim_header: meanP
2022-06-20 19:29:34,863:INFO:   <<< slice_framepos: 2
2022-06-20 19:29:34,863:INFO:   <<< task_type: retrieval
2022-06-20 19:29:34,864:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:29:34,864:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:29:34,864:INFO:   <<< train_frame_order: 0
2022-06-20 19:29:34,864:INFO:   <<< use_mil: False
2022-06-20 19:29:34,864:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:29:34,864:INFO:   <<< video_dim: 1024
2022-06-20 19:29:34,864:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:29:34,864:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:29:34,864:INFO:   <<< world_size: 1
2022-06-20 19:29:34,864:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:29:35,370:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:29:35,370:WARNING: Test retrieval by loose type.
2022-06-20 19:29:35,371:WARNING: 	 embed_dim: 512
2022-06-20 19:29:35,371:WARNING: 	 image_resolution: 224
2022-06-20 19:29:35,371:WARNING: 	 vision_layers: 12
2022-06-20 19:29:35,371:WARNING: 	 vision_width: 768
2022-06-20 19:29:35,371:WARNING: 	 vision_patch_size: 32
2022-06-20 19:29:35,371:WARNING: 	 context_length: 77
2022-06-20 19:29:35,371:WARNING: 	 vocab_size: 49408
2022-06-20 19:29:35,371:WARNING: 	 transformer_width: 512
2022-06-20 19:29:35,371:WARNING: 	 transformer_heads: 8
2022-06-20 19:29:35,371:WARNING: 	 transformer_layers: 12
2022-06-20 19:29:35,371:WARNING: 		 linear_patch: 3d
2022-06-20 19:29:35,371:WARNING: 	 cut_top_layer: 0
2022-06-20 19:30:34,040:INFO: Effective parameters:
2022-06-20 19:30:34,041:INFO:   <<< batch_size: 256
2022-06-20 19:30:34,041:INFO:   <<< batch_size_val: 16
2022-06-20 19:30:34,041:INFO:   <<< cache_dir: 
2022-06-20 19:30:34,041:INFO:   <<< coef_lr: 0.001
2022-06-20 19:30:34,041:INFO:   <<< cross_model: cross-base
2022-06-20 19:30:34,041:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:30:34,041:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:30:34,041:INFO:   <<< datatype: msvd
2022-06-20 19:30:34,041:INFO:   <<< do_eval: False
2022-06-20 19:30:34,041:INFO:   <<< do_lower_case: False
2022-06-20 19:30:34,041:INFO:   <<< do_pretrain: False
2022-06-20 19:30:34,041:INFO:   <<< do_train: True
2022-06-20 19:30:34,041:INFO:   <<< epochs: 5
2022-06-20 19:30:34,041:INFO:   <<< eval_frame_order: 0
2022-06-20 19:30:34,041:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:30:34,041:INFO:   <<< feature_framerate: 1
2022-06-20 19:30:34,041:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:30:34,041:INFO:   <<< fp16: False
2022-06-20 19:30:34,041:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:30:34,041:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:30:34,041:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:30:34,041:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:30:34,041:INFO:   <<< init_model: None
2022-06-20 19:30:34,041:INFO:   <<< linear_patch: 3d
2022-06-20 19:30:34,041:INFO:   <<< local_rank: 0
2022-06-20 19:30:34,041:INFO:   <<< loose_type: True
2022-06-20 19:30:34,041:INFO:   <<< lr: 0.0001
2022-06-20 19:30:34,041:INFO:   <<< lr_decay: 0.9
2022-06-20 19:30:34,041:INFO:   <<< margin: 0.1
2022-06-20 19:30:34,041:INFO:   <<< max_frames: 12
2022-06-20 19:30:34,041:INFO:   <<< max_words: 32
2022-06-20 19:30:34,042:INFO:   <<< n_display: 50
2022-06-20 19:30:34,042:INFO:   <<< n_gpu: 1
2022-06-20 19:30:34,042:INFO:   <<< n_pair: 1
2022-06-20 19:30:34,042:INFO:   <<< negative_weighting: 1
2022-06-20 19:30:34,042:INFO:   <<< num_thread_reader: 2
2022-06-20 19:30:34,042:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:30:34,042:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:30:34,042:INFO:   <<< rank: 0
2022-06-20 19:30:34,042:INFO:   <<< resume_model: None
2022-06-20 19:30:34,042:INFO:   <<< sampled_use_mil: False
2022-06-20 19:30:34,042:INFO:   <<< seed: 42
2022-06-20 19:30:34,042:INFO:   <<< sim_header: meanP
2022-06-20 19:30:34,042:INFO:   <<< slice_framepos: 2
2022-06-20 19:30:34,042:INFO:   <<< task_type: retrieval
2022-06-20 19:30:34,042:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:30:34,042:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:30:34,042:INFO:   <<< train_frame_order: 0
2022-06-20 19:30:34,042:INFO:   <<< use_mil: False
2022-06-20 19:30:34,042:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:30:34,042:INFO:   <<< video_dim: 1024
2022-06-20 19:30:34,042:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:30:34,042:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:30:34,042:INFO:   <<< world_size: 1
2022-06-20 19:30:34,042:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:30:34,915:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:30:34,915:WARNING: Test retrieval by loose type.
2022-06-20 19:30:34,916:WARNING: 	 embed_dim: 512
2022-06-20 19:30:34,916:WARNING: 	 image_resolution: 224
2022-06-20 19:30:34,916:WARNING: 	 vision_layers: 12
2022-06-20 19:30:34,916:WARNING: 	 vision_width: 768
2022-06-20 19:30:34,916:WARNING: 	 vision_patch_size: 32
2022-06-20 19:30:34,916:WARNING: 	 context_length: 77
2022-06-20 19:30:34,916:WARNING: 	 vocab_size: 49408
2022-06-20 19:30:34,916:WARNING: 	 transformer_width: 512
2022-06-20 19:30:34,916:WARNING: 	 transformer_heads: 8
2022-06-20 19:30:34,916:WARNING: 	 transformer_layers: 12
2022-06-20 19:30:34,916:WARNING: 		 linear_patch: 3d
2022-06-20 19:30:34,916:WARNING: 	 cut_top_layer: 0
2022-06-20 19:31:57,929:INFO: Effective parameters:
2022-06-20 19:31:57,929:INFO:   <<< batch_size: 256
2022-06-20 19:31:57,929:INFO:   <<< batch_size_val: 16
2022-06-20 19:31:57,929:INFO:   <<< cache_dir: 
2022-06-20 19:31:57,929:INFO:   <<< coef_lr: 0.001
2022-06-20 19:31:57,929:INFO:   <<< cross_model: cross-base
2022-06-20 19:31:57,929:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:31:57,929:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:31:57,929:INFO:   <<< datatype: msvd
2022-06-20 19:31:57,929:INFO:   <<< do_eval: False
2022-06-20 19:31:57,929:INFO:   <<< do_lower_case: False
2022-06-20 19:31:57,929:INFO:   <<< do_pretrain: False
2022-06-20 19:31:57,929:INFO:   <<< do_train: True
2022-06-20 19:31:57,929:INFO:   <<< epochs: 5
2022-06-20 19:31:57,929:INFO:   <<< eval_frame_order: 0
2022-06-20 19:31:57,929:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:31:57,930:INFO:   <<< feature_framerate: 1
2022-06-20 19:31:57,930:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:31:57,930:INFO:   <<< fp16: False
2022-06-20 19:31:57,930:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:31:57,930:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:31:57,930:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:31:57,930:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:31:57,930:INFO:   <<< init_model: None
2022-06-20 19:31:57,930:INFO:   <<< linear_patch: 3d
2022-06-20 19:31:57,930:INFO:   <<< local_rank: 0
2022-06-20 19:31:57,930:INFO:   <<< loose_type: True
2022-06-20 19:31:57,930:INFO:   <<< lr: 0.0001
2022-06-20 19:31:57,930:INFO:   <<< lr_decay: 0.9
2022-06-20 19:31:57,930:INFO:   <<< margin: 0.1
2022-06-20 19:31:57,930:INFO:   <<< max_frames: 12
2022-06-20 19:31:57,930:INFO:   <<< max_words: 32
2022-06-20 19:31:57,930:INFO:   <<< n_display: 50
2022-06-20 19:31:57,930:INFO:   <<< n_gpu: 1
2022-06-20 19:31:57,930:INFO:   <<< n_pair: 1
2022-06-20 19:31:57,930:INFO:   <<< negative_weighting: 1
2022-06-20 19:31:57,930:INFO:   <<< num_thread_reader: 2
2022-06-20 19:31:57,930:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:31:57,930:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:31:57,930:INFO:   <<< rank: 0
2022-06-20 19:31:57,930:INFO:   <<< resume_model: None
2022-06-20 19:31:57,930:INFO:   <<< sampled_use_mil: False
2022-06-20 19:31:57,930:INFO:   <<< seed: 42
2022-06-20 19:31:57,930:INFO:   <<< sim_header: meanP
2022-06-20 19:31:57,930:INFO:   <<< slice_framepos: 2
2022-06-20 19:31:57,930:INFO:   <<< task_type: retrieval
2022-06-20 19:31:57,930:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:31:57,930:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:31:57,930:INFO:   <<< train_frame_order: 0
2022-06-20 19:31:57,930:INFO:   <<< use_mil: False
2022-06-20 19:31:57,930:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:31:57,931:INFO:   <<< video_dim: 1024
2022-06-20 19:31:57,931:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:31:57,931:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:31:57,931:INFO:   <<< world_size: 1
2022-06-20 19:31:57,931:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:31:58,635:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:31:58,635:WARNING: Test retrieval by loose type.
2022-06-20 19:31:58,636:WARNING: 	 embed_dim: 512
2022-06-20 19:31:58,636:WARNING: 	 image_resolution: 224
2022-06-20 19:31:58,636:WARNING: 	 vision_layers: 12
2022-06-20 19:31:58,636:WARNING: 	 vision_width: 768
2022-06-20 19:31:58,636:WARNING: 	 vision_patch_size: 32
2022-06-20 19:31:58,636:WARNING: 	 context_length: 77
2022-06-20 19:31:58,636:WARNING: 	 vocab_size: 49408
2022-06-20 19:31:58,636:WARNING: 	 transformer_width: 512
2022-06-20 19:31:58,636:WARNING: 	 transformer_heads: 8
2022-06-20 19:31:58,636:WARNING: 	 transformer_layers: 12
2022-06-20 19:31:58,636:WARNING: 		 linear_patch: 3d
2022-06-20 19:31:58,636:WARNING: 	 cut_top_layer: 0
2022-06-20 19:34:38,912:INFO: Effective parameters:
2022-06-20 19:34:38,913:INFO:   <<< batch_size: 256
2022-06-20 19:34:38,913:INFO:   <<< batch_size_val: 16
2022-06-20 19:34:38,913:INFO:   <<< cache_dir: 
2022-06-20 19:34:38,913:INFO:   <<< coef_lr: 0.001
2022-06-20 19:34:38,913:INFO:   <<< cross_model: cross-base
2022-06-20 19:34:38,913:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:34:38,913:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:34:38,913:INFO:   <<< datatype: msvd
2022-06-20 19:34:38,913:INFO:   <<< do_eval: False
2022-06-20 19:34:38,913:INFO:   <<< do_lower_case: False
2022-06-20 19:34:38,913:INFO:   <<< do_pretrain: False
2022-06-20 19:34:38,913:INFO:   <<< do_train: True
2022-06-20 19:34:38,913:INFO:   <<< epochs: 5
2022-06-20 19:34:38,913:INFO:   <<< eval_frame_order: 0
2022-06-20 19:34:38,913:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:34:38,913:INFO:   <<< feature_framerate: 1
2022-06-20 19:34:38,913:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:34:38,913:INFO:   <<< fp16: False
2022-06-20 19:34:38,913:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:34:38,913:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:34:38,913:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:34:38,913:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:34:38,913:INFO:   <<< init_model: None
2022-06-20 19:34:38,913:INFO:   <<< linear_patch: 3d
2022-06-20 19:34:38,913:INFO:   <<< local_rank: 0
2022-06-20 19:34:38,913:INFO:   <<< loose_type: True
2022-06-20 19:34:38,913:INFO:   <<< lr: 0.0001
2022-06-20 19:34:38,913:INFO:   <<< lr_decay: 0.9
2022-06-20 19:34:38,913:INFO:   <<< margin: 0.1
2022-06-20 19:34:38,913:INFO:   <<< max_frames: 12
2022-06-20 19:34:38,913:INFO:   <<< max_words: 32
2022-06-20 19:34:38,913:INFO:   <<< n_display: 50
2022-06-20 19:34:38,914:INFO:   <<< n_gpu: 1
2022-06-20 19:34:38,914:INFO:   <<< n_pair: 1
2022-06-20 19:34:38,914:INFO:   <<< negative_weighting: 1
2022-06-20 19:34:38,914:INFO:   <<< num_thread_reader: 2
2022-06-20 19:34:38,914:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:34:38,914:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:34:38,914:INFO:   <<< rank: 0
2022-06-20 19:34:38,914:INFO:   <<< resume_model: None
2022-06-20 19:34:38,914:INFO:   <<< sampled_use_mil: False
2022-06-20 19:34:38,914:INFO:   <<< seed: 42
2022-06-20 19:34:38,914:INFO:   <<< sim_header: meanP
2022-06-20 19:34:38,914:INFO:   <<< slice_framepos: 2
2022-06-20 19:34:38,914:INFO:   <<< task_type: retrieval
2022-06-20 19:34:38,914:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:34:38,914:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:34:38,914:INFO:   <<< train_frame_order: 0
2022-06-20 19:34:38,914:INFO:   <<< use_mil: False
2022-06-20 19:34:38,914:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:34:38,914:INFO:   <<< video_dim: 1024
2022-06-20 19:34:38,914:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:34:38,914:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:34:38,914:INFO:   <<< world_size: 1
2022-06-20 19:34:38,914:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:34:39,671:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:34:39,671:WARNING: Test retrieval by loose type.
2022-06-20 19:34:39,672:WARNING: 	 embed_dim: 512
2022-06-20 19:34:39,672:WARNING: 	 image_resolution: 224
2022-06-20 19:34:39,672:WARNING: 	 vision_layers: 12
2022-06-20 19:34:39,672:WARNING: 	 vision_width: 768
2022-06-20 19:34:39,672:WARNING: 	 vision_patch_size: 32
2022-06-20 19:34:39,672:WARNING: 	 context_length: 77
2022-06-20 19:34:39,672:WARNING: 	 vocab_size: 49408
2022-06-20 19:34:39,672:WARNING: 	 transformer_width: 512
2022-06-20 19:34:39,672:WARNING: 	 transformer_heads: 8
2022-06-20 19:34:39,672:WARNING: 	 transformer_layers: 12
2022-06-20 19:34:39,672:WARNING: 		 linear_patch: 3d
2022-06-20 19:34:39,672:WARNING: 	 cut_top_layer: 0
2022-06-20 19:36:42,698:INFO: Effective parameters:
2022-06-20 19:36:42,698:INFO:   <<< batch_size: 256
2022-06-20 19:36:42,698:INFO:   <<< batch_size_val: 16
2022-06-20 19:36:42,698:INFO:   <<< cache_dir: 
2022-06-20 19:36:42,698:INFO:   <<< coef_lr: 0.001
2022-06-20 19:36:42,698:INFO:   <<< cross_model: cross-base
2022-06-20 19:36:42,698:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 19:36:42,698:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 19:36:42,699:INFO:   <<< datatype: msvd
2022-06-20 19:36:42,699:INFO:   <<< do_eval: False
2022-06-20 19:36:42,699:INFO:   <<< do_lower_case: False
2022-06-20 19:36:42,699:INFO:   <<< do_pretrain: False
2022-06-20 19:36:42,699:INFO:   <<< do_train: True
2022-06-20 19:36:42,699:INFO:   <<< epochs: 5
2022-06-20 19:36:42,699:INFO:   <<< eval_frame_order: 0
2022-06-20 19:36:42,699:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 19:36:42,699:INFO:   <<< feature_framerate: 1
2022-06-20 19:36:42,699:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 19:36:42,699:INFO:   <<< fp16: False
2022-06-20 19:36:42,699:INFO:   <<< fp16_opt_level: O1
2022-06-20 19:36:42,699:INFO:   <<< freeze_layer_num: 0
2022-06-20 19:36:42,699:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 19:36:42,699:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 19:36:42,699:INFO:   <<< init_model: None
2022-06-20 19:36:42,700:INFO:   <<< linear_patch: 3d
2022-06-20 19:36:42,700:INFO:   <<< local_rank: 0
2022-06-20 19:36:42,700:INFO:   <<< loose_type: True
2022-06-20 19:36:42,700:INFO:   <<< lr: 0.0001
2022-06-20 19:36:42,700:INFO:   <<< lr_decay: 0.9
2022-06-20 19:36:42,700:INFO:   <<< margin: 0.1
2022-06-20 19:36:42,700:INFO:   <<< max_frames: 12
2022-06-20 19:36:42,700:INFO:   <<< max_words: 32
2022-06-20 19:36:42,700:INFO:   <<< n_display: 50
2022-06-20 19:36:42,700:INFO:   <<< n_gpu: 1
2022-06-20 19:36:42,700:INFO:   <<< n_pair: 1
2022-06-20 19:36:42,700:INFO:   <<< negative_weighting: 1
2022-06-20 19:36:42,700:INFO:   <<< num_thread_reader: 2
2022-06-20 19:36:42,700:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 19:36:42,700:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 19:36:42,700:INFO:   <<< rank: 0
2022-06-20 19:36:42,701:INFO:   <<< resume_model: None
2022-06-20 19:36:42,701:INFO:   <<< sampled_use_mil: False
2022-06-20 19:36:42,701:INFO:   <<< seed: 42
2022-06-20 19:36:42,701:INFO:   <<< sim_header: meanP
2022-06-20 19:36:42,701:INFO:   <<< slice_framepos: 2
2022-06-20 19:36:42,701:INFO:   <<< task_type: retrieval
2022-06-20 19:36:42,701:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 19:36:42,701:INFO:   <<< train_csv: data/.train.csv
2022-06-20 19:36:42,701:INFO:   <<< train_frame_order: 0
2022-06-20 19:36:42,701:INFO:   <<< use_mil: False
2022-06-20 19:36:42,701:INFO:   <<< val_csv: data/.val.csv
2022-06-20 19:36:42,701:INFO:   <<< video_dim: 1024
2022-06-20 19:36:42,701:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 19:36:42,701:INFO:   <<< warmup_proportion: 0.1
2022-06-20 19:36:42,701:INFO:   <<< world_size: 1
2022-06-20 19:36:42,702:INFO: device: cuda:0 n_gpu: 1
2022-06-20 19:36:43,404:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 19:36:43,405:WARNING: Test retrieval by loose type.
2022-06-20 19:36:43,405:WARNING: 	 embed_dim: 512
2022-06-20 19:36:43,405:WARNING: 	 image_resolution: 224
2022-06-20 19:36:43,405:WARNING: 	 vision_layers: 12
2022-06-20 19:36:43,405:WARNING: 	 vision_width: 768
2022-06-20 19:36:43,405:WARNING: 	 vision_patch_size: 32
2022-06-20 19:36:43,405:WARNING: 	 context_length: 77
2022-06-20 19:36:43,405:WARNING: 	 vocab_size: 49408
2022-06-20 19:36:43,405:WARNING: 	 transformer_width: 512
2022-06-20 19:36:43,405:WARNING: 	 transformer_heads: 8
2022-06-20 19:36:43,405:WARNING: 	 transformer_layers: 12
2022-06-20 19:36:43,405:WARNING: 		 linear_patch: 3d
2022-06-20 19:36:43,405:WARNING: 	 cut_top_layer: 0
2022-06-20 20:58:24,319:INFO: Effective parameters:
2022-06-20 20:58:24,320:INFO:   <<< batch_size: 256
2022-06-20 20:58:24,320:INFO:   <<< batch_size_val: 16
2022-06-20 20:58:24,320:INFO:   <<< cache_dir: 
2022-06-20 20:58:24,320:INFO:   <<< coef_lr: 0.001
2022-06-20 20:58:24,320:INFO:   <<< cross_model: cross-base
2022-06-20 20:58:24,320:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 20:58:24,320:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 20:58:24,321:INFO:   <<< datatype: msvd
2022-06-20 20:58:24,321:INFO:   <<< do_eval: False
2022-06-20 20:58:24,321:INFO:   <<< do_lower_case: False
2022-06-20 20:58:24,321:INFO:   <<< do_pretrain: False
2022-06-20 20:58:24,321:INFO:   <<< do_train: True
2022-06-20 20:58:24,321:INFO:   <<< epochs: 5
2022-06-20 20:58:24,321:INFO:   <<< eval_frame_order: 0
2022-06-20 20:58:24,321:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 20:58:24,321:INFO:   <<< feature_framerate: 1
2022-06-20 20:58:24,321:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 20:58:24,322:INFO:   <<< fp16: False
2022-06-20 20:58:24,322:INFO:   <<< fp16_opt_level: O1
2022-06-20 20:58:24,322:INFO:   <<< freeze_layer_num: 0
2022-06-20 20:58:24,322:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 20:58:24,322:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 20:58:24,322:INFO:   <<< init_model: None
2022-06-20 20:58:24,322:INFO:   <<< linear_patch: 3d
2022-06-20 20:58:24,322:INFO:   <<< local_rank: 0
2022-06-20 20:58:24,322:INFO:   <<< loose_type: True
2022-06-20 20:58:24,323:INFO:   <<< lr: 0.0001
2022-06-20 20:58:24,323:INFO:   <<< lr_decay: 0.9
2022-06-20 20:58:24,323:INFO:   <<< margin: 0.1
2022-06-20 20:58:24,323:INFO:   <<< max_frames: 12
2022-06-20 20:58:24,323:INFO:   <<< max_words: 32
2022-06-20 20:58:24,323:INFO:   <<< n_display: 50
2022-06-20 20:58:24,323:INFO:   <<< n_gpu: 1
2022-06-20 20:58:24,323:INFO:   <<< n_pair: 1
2022-06-20 20:58:24,323:INFO:   <<< negative_weighting: 1
2022-06-20 20:58:24,324:INFO:   <<< num_thread_reader: 2
2022-06-20 20:58:24,324:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 20:58:24,324:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 20:58:24,324:INFO:   <<< rank: 0
2022-06-20 20:58:24,324:INFO:   <<< resume_model: None
2022-06-20 20:58:24,324:INFO:   <<< sampled_use_mil: False
2022-06-20 20:58:24,324:INFO:   <<< seed: 42
2022-06-20 20:58:24,324:INFO:   <<< sim_header: meanP
2022-06-20 20:58:24,324:INFO:   <<< slice_framepos: 2
2022-06-20 20:58:24,324:INFO:   <<< task_type: retrieval
2022-06-20 20:58:24,325:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 20:58:24,325:INFO:   <<< train_csv: data/.train.csv
2022-06-20 20:58:24,325:INFO:   <<< train_frame_order: 0
2022-06-20 20:58:24,325:INFO:   <<< use_mil: False
2022-06-20 20:58:24,325:INFO:   <<< val_csv: data/.val.csv
2022-06-20 20:58:24,325:INFO:   <<< video_dim: 1024
2022-06-20 20:58:24,325:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 20:58:24,325:INFO:   <<< warmup_proportion: 0.1
2022-06-20 20:58:24,325:INFO:   <<< world_size: 1
2022-06-20 20:58:24,326:INFO: device: cuda:0 n_gpu: 1
2022-06-20 20:58:25,078:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 20:58:25,078:WARNING: Test retrieval by loose type.
2022-06-20 20:58:25,079:WARNING: 	 embed_dim: 512
2022-06-20 20:58:25,079:WARNING: 	 image_resolution: 224
2022-06-20 20:58:25,079:WARNING: 	 vision_layers: 12
2022-06-20 20:58:25,079:WARNING: 	 vision_width: 768
2022-06-20 20:58:25,079:WARNING: 	 vision_patch_size: 32
2022-06-20 20:58:25,079:WARNING: 	 context_length: 77
2022-06-20 20:58:25,079:WARNING: 	 vocab_size: 49408
2022-06-20 20:58:25,079:WARNING: 	 transformer_width: 512
2022-06-20 20:58:25,079:WARNING: 	 transformer_heads: 8
2022-06-20 20:58:25,079:WARNING: 	 transformer_layers: 12
2022-06-20 20:58:25,079:WARNING: 		 linear_patch: 3d
2022-06-20 20:58:25,079:WARNING: 	 cut_top_layer: 0
2022-06-20 21:51:36,377:INFO: Effective parameters:
2022-06-20 21:51:36,377:INFO:   <<< batch_size: 256
2022-06-20 21:51:36,377:INFO:   <<< batch_size_val: 16
2022-06-20 21:51:36,377:INFO:   <<< cache_dir: 
2022-06-20 21:51:36,377:INFO:   <<< coef_lr: 0.001
2022-06-20 21:51:36,377:INFO:   <<< cross_model: cross-base
2022-06-20 21:51:36,377:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 21:51:36,377:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 21:51:36,378:INFO:   <<< datatype: msvd
2022-06-20 21:51:36,378:INFO:   <<< do_eval: False
2022-06-20 21:51:36,378:INFO:   <<< do_lower_case: False
2022-06-20 21:51:36,378:INFO:   <<< do_pretrain: False
2022-06-20 21:51:36,378:INFO:   <<< do_train: True
2022-06-20 21:51:36,378:INFO:   <<< epochs: 5
2022-06-20 21:51:36,378:INFO:   <<< eval_frame_order: 0
2022-06-20 21:51:36,378:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 21:51:36,378:INFO:   <<< feature_framerate: 1
2022-06-20 21:51:36,378:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 21:51:36,378:INFO:   <<< fp16: False
2022-06-20 21:51:36,378:INFO:   <<< fp16_opt_level: O1
2022-06-20 21:51:36,378:INFO:   <<< freeze_layer_num: 0
2022-06-20 21:51:36,378:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 21:51:36,378:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 21:51:36,378:INFO:   <<< init_model: None
2022-06-20 21:51:36,378:INFO:   <<< linear_patch: 3d
2022-06-20 21:51:36,378:INFO:   <<< local_rank: 0
2022-06-20 21:51:36,378:INFO:   <<< loose_type: True
2022-06-20 21:51:36,378:INFO:   <<< lr: 0.0001
2022-06-20 21:51:36,378:INFO:   <<< lr_decay: 0.9
2022-06-20 21:51:36,378:INFO:   <<< margin: 0.1
2022-06-20 21:51:36,378:INFO:   <<< max_frames: 12
2022-06-20 21:51:36,378:INFO:   <<< max_words: 32
2022-06-20 21:51:36,378:INFO:   <<< n_display: 50
2022-06-20 21:51:36,378:INFO:   <<< n_gpu: 1
2022-06-20 21:51:36,378:INFO:   <<< n_pair: 1
2022-06-20 21:51:36,378:INFO:   <<< negative_weighting: 1
2022-06-20 21:51:36,378:INFO:   <<< num_thread_reader: 2
2022-06-20 21:51:36,378:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 21:51:36,378:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 21:51:36,378:INFO:   <<< rank: 0
2022-06-20 21:51:36,378:INFO:   <<< resume_model: None
2022-06-20 21:51:36,378:INFO:   <<< sampled_use_mil: False
2022-06-20 21:51:36,378:INFO:   <<< seed: 42
2022-06-20 21:51:36,379:INFO:   <<< sim_header: meanP
2022-06-20 21:51:36,379:INFO:   <<< slice_framepos: 2
2022-06-20 21:51:36,379:INFO:   <<< task_type: retrieval
2022-06-20 21:51:36,379:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 21:51:36,379:INFO:   <<< train_csv: data/.train.csv
2022-06-20 21:51:36,379:INFO:   <<< train_frame_order: 0
2022-06-20 21:51:36,379:INFO:   <<< use_mil: False
2022-06-20 21:51:36,379:INFO:   <<< val_csv: data/.val.csv
2022-06-20 21:51:36,379:INFO:   <<< video_dim: 1024
2022-06-20 21:51:36,379:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 21:51:36,379:INFO:   <<< warmup_proportion: 0.1
2022-06-20 21:51:36,379:INFO:   <<< world_size: 1
2022-06-20 21:51:36,379:INFO: device: cuda:0 n_gpu: 1
2022-06-20 21:51:37,060:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 21:51:37,060:WARNING: Test retrieval by loose type.
2022-06-20 21:51:37,060:WARNING: 	 embed_dim: 512
2022-06-20 21:51:37,060:WARNING: 	 image_resolution: 224
2022-06-20 21:51:37,060:WARNING: 	 vision_layers: 12
2022-06-20 21:51:37,060:WARNING: 	 vision_width: 768
2022-06-20 21:51:37,061:WARNING: 	 vision_patch_size: 32
2022-06-20 21:51:37,061:WARNING: 	 context_length: 77
2022-06-20 21:51:37,061:WARNING: 	 vocab_size: 49408
2022-06-20 21:51:37,061:WARNING: 	 transformer_width: 512
2022-06-20 21:51:37,061:WARNING: 	 transformer_heads: 8
2022-06-20 21:51:37,061:WARNING: 	 transformer_layers: 12
2022-06-20 21:51:37,061:WARNING: 		 linear_patch: 3d
2022-06-20 21:51:37,061:WARNING: 	 cut_top_layer: 0
2022-06-20 22:02:34,359:INFO: Effective parameters:
2022-06-20 22:02:34,359:INFO:   <<< batch_size: 256
2022-06-20 22:02:34,360:INFO:   <<< batch_size_val: 16
2022-06-20 22:02:34,360:INFO:   <<< cache_dir: 
2022-06-20 22:02:34,360:INFO:   <<< coef_lr: 0.001
2022-06-20 22:02:34,360:INFO:   <<< cross_model: cross-base
2022-06-20 22:02:34,360:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 22:02:34,360:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 22:02:34,360:INFO:   <<< datatype: msvd
2022-06-20 22:02:34,360:INFO:   <<< do_eval: False
2022-06-20 22:02:34,360:INFO:   <<< do_lower_case: False
2022-06-20 22:02:34,360:INFO:   <<< do_pretrain: False
2022-06-20 22:02:34,360:INFO:   <<< do_train: True
2022-06-20 22:02:34,360:INFO:   <<< epochs: 5
2022-06-20 22:02:34,360:INFO:   <<< eval_frame_order: 0
2022-06-20 22:02:34,360:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 22:02:34,360:INFO:   <<< feature_framerate: 1
2022-06-20 22:02:34,360:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 22:02:34,360:INFO:   <<< fp16: False
2022-06-20 22:02:34,360:INFO:   <<< fp16_opt_level: O1
2022-06-20 22:02:34,360:INFO:   <<< freeze_layer_num: 0
2022-06-20 22:02:34,360:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 22:02:34,360:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 22:02:34,360:INFO:   <<< init_model: None
2022-06-20 22:02:34,361:INFO:   <<< linear_patch: 3d
2022-06-20 22:02:34,361:INFO:   <<< local_rank: 0
2022-06-20 22:02:34,361:INFO:   <<< loose_type: True
2022-06-20 22:02:34,361:INFO:   <<< lr: 0.0001
2022-06-20 22:02:34,361:INFO:   <<< lr_decay: 0.9
2022-06-20 22:02:34,361:INFO:   <<< margin: 0.1
2022-06-20 22:02:34,361:INFO:   <<< max_frames: 12
2022-06-20 22:02:34,361:INFO:   <<< max_words: 32
2022-06-20 22:02:34,361:INFO:   <<< n_display: 50
2022-06-20 22:02:34,361:INFO:   <<< n_gpu: 1
2022-06-20 22:02:34,361:INFO:   <<< n_pair: 1
2022-06-20 22:02:34,361:INFO:   <<< negative_weighting: 1
2022-06-20 22:02:34,361:INFO:   <<< num_thread_reader: 2
2022-06-20 22:02:34,361:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 22:02:34,361:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 22:02:34,361:INFO:   <<< rank: 0
2022-06-20 22:02:34,361:INFO:   <<< resume_model: None
2022-06-20 22:02:34,361:INFO:   <<< sampled_use_mil: False
2022-06-20 22:02:34,361:INFO:   <<< seed: 42
2022-06-20 22:02:34,361:INFO:   <<< sim_header: meanP
2022-06-20 22:02:34,361:INFO:   <<< slice_framepos: 2
2022-06-20 22:02:34,361:INFO:   <<< task_type: retrieval
2022-06-20 22:02:34,361:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 22:02:34,361:INFO:   <<< train_csv: data/.train.csv
2022-06-20 22:02:34,362:INFO:   <<< train_frame_order: 0
2022-06-20 22:02:34,362:INFO:   <<< use_mil: False
2022-06-20 22:02:34,362:INFO:   <<< val_csv: data/.val.csv
2022-06-20 22:02:34,362:INFO:   <<< video_dim: 1024
2022-06-20 22:02:34,362:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 22:02:34,362:INFO:   <<< warmup_proportion: 0.1
2022-06-20 22:02:34,362:INFO:   <<< world_size: 1
2022-06-20 22:02:34,362:INFO: device: cuda:0 n_gpu: 1
2022-06-20 22:02:35,266:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 22:02:35,266:WARNING: Test retrieval by loose type.
2022-06-20 22:02:35,267:WARNING: 	 embed_dim: 512
2022-06-20 22:02:35,267:WARNING: 	 image_resolution: 224
2022-06-20 22:02:35,267:WARNING: 	 vision_layers: 12
2022-06-20 22:02:35,267:WARNING: 	 vision_width: 768
2022-06-20 22:02:35,267:WARNING: 	 vision_patch_size: 32
2022-06-20 22:02:35,267:WARNING: 	 context_length: 77
2022-06-20 22:02:35,267:WARNING: 	 vocab_size: 49408
2022-06-20 22:02:35,267:WARNING: 	 transformer_width: 512
2022-06-20 22:02:35,267:WARNING: 	 transformer_heads: 8
2022-06-20 22:02:35,267:WARNING: 	 transformer_layers: 12
2022-06-20 22:02:35,267:WARNING: 		 linear_patch: 3d
2022-06-20 22:02:35,267:WARNING: 	 cut_top_layer: 0
2022-06-20 23:16:28,919:INFO: Effective parameters:
2022-06-20 23:16:28,919:INFO:   <<< batch_size: 256
2022-06-20 23:16:28,919:INFO:   <<< batch_size_val: 16
2022-06-20 23:16:28,919:INFO:   <<< cache_dir: 
2022-06-20 23:16:28,919:INFO:   <<< coef_lr: 0.001
2022-06-20 23:16:28,919:INFO:   <<< cross_model: cross-base
2022-06-20 23:16:28,919:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 23:16:28,919:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 23:16:28,919:INFO:   <<< datatype: msvd
2022-06-20 23:16:28,919:INFO:   <<< do_eval: False
2022-06-20 23:16:28,920:INFO:   <<< do_lower_case: False
2022-06-20 23:16:28,920:INFO:   <<< do_pretrain: False
2022-06-20 23:16:28,920:INFO:   <<< do_train: True
2022-06-20 23:16:28,920:INFO:   <<< epochs: 5
2022-06-20 23:16:28,920:INFO:   <<< eval_frame_order: 0
2022-06-20 23:16:28,920:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 23:16:28,920:INFO:   <<< feature_framerate: 1
2022-06-20 23:16:28,920:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 23:16:28,920:INFO:   <<< fp16: False
2022-06-20 23:16:28,920:INFO:   <<< fp16_opt_level: O1
2022-06-20 23:16:28,920:INFO:   <<< freeze_layer_num: 0
2022-06-20 23:16:28,920:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 23:16:28,920:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 23:16:28,920:INFO:   <<< init_model: None
2022-06-20 23:16:28,920:INFO:   <<< linear_patch: 3d
2022-06-20 23:16:28,920:INFO:   <<< local_rank: 0
2022-06-20 23:16:28,920:INFO:   <<< loose_type: True
2022-06-20 23:16:28,920:INFO:   <<< lr: 0.0001
2022-06-20 23:16:28,920:INFO:   <<< lr_decay: 0.9
2022-06-20 23:16:28,920:INFO:   <<< margin: 0.1
2022-06-20 23:16:28,920:INFO:   <<< max_frames: 12
2022-06-20 23:16:28,920:INFO:   <<< max_words: 32
2022-06-20 23:16:28,920:INFO:   <<< n_display: 50
2022-06-20 23:16:28,920:INFO:   <<< n_gpu: 1
2022-06-20 23:16:28,920:INFO:   <<< n_pair: 1
2022-06-20 23:16:28,920:INFO:   <<< negative_weighting: 1
2022-06-20 23:16:28,920:INFO:   <<< num_thread_reader: 2
2022-06-20 23:16:28,920:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 23:16:28,920:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 23:16:28,920:INFO:   <<< rank: 0
2022-06-20 23:16:28,920:INFO:   <<< resume_model: None
2022-06-20 23:16:28,920:INFO:   <<< sampled_use_mil: False
2022-06-20 23:16:28,920:INFO:   <<< seed: 42
2022-06-20 23:16:28,920:INFO:   <<< sim_header: meanP
2022-06-20 23:16:28,920:INFO:   <<< slice_framepos: 2
2022-06-20 23:16:28,920:INFO:   <<< task_type: retrieval
2022-06-20 23:16:28,920:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 23:16:28,921:INFO:   <<< train_csv: data/.train.csv
2022-06-20 23:16:28,921:INFO:   <<< train_frame_order: 0
2022-06-20 23:16:28,921:INFO:   <<< use_mil: False
2022-06-20 23:16:28,921:INFO:   <<< val_csv: data/.val.csv
2022-06-20 23:16:28,921:INFO:   <<< video_dim: 1024
2022-06-20 23:16:28,921:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 23:16:28,921:INFO:   <<< warmup_proportion: 0.1
2022-06-20 23:16:28,921:INFO:   <<< world_size: 1
2022-06-20 23:16:28,921:INFO: device: cuda:0 n_gpu: 1
2022-06-20 23:16:29,878:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 23:16:29,878:WARNING: Test retrieval by loose type.
2022-06-20 23:16:29,879:WARNING: 	 embed_dim: 512
2022-06-20 23:16:29,879:WARNING: 	 image_resolution: 224
2022-06-20 23:16:29,879:WARNING: 	 vision_layers: 12
2022-06-20 23:16:29,879:WARNING: 	 vision_width: 768
2022-06-20 23:16:29,879:WARNING: 	 vision_patch_size: 32
2022-06-20 23:16:29,879:WARNING: 	 context_length: 77
2022-06-20 23:16:29,879:WARNING: 	 vocab_size: 49408
2022-06-20 23:16:29,879:WARNING: 	 transformer_width: 512
2022-06-20 23:16:29,879:WARNING: 	 transformer_heads: 8
2022-06-20 23:16:29,879:WARNING: 	 transformer_layers: 12
2022-06-20 23:16:29,879:WARNING: 		 linear_patch: 3d
2022-06-20 23:16:29,879:WARNING: 	 cut_top_layer: 0
2022-06-20 23:17:14,281:INFO: Effective parameters:
2022-06-20 23:17:14,281:INFO:   <<< batch_size: 256
2022-06-20 23:17:14,281:INFO:   <<< batch_size_val: 16
2022-06-20 23:17:14,282:INFO:   <<< cache_dir: 
2022-06-20 23:17:14,282:INFO:   <<< coef_lr: 0.001
2022-06-20 23:17:14,282:INFO:   <<< cross_model: cross-base
2022-06-20 23:17:14,282:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 23:17:14,282:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 23:17:14,282:INFO:   <<< datatype: msvd
2022-06-20 23:17:14,282:INFO:   <<< do_eval: False
2022-06-20 23:17:14,282:INFO:   <<< do_lower_case: False
2022-06-20 23:17:14,282:INFO:   <<< do_pretrain: False
2022-06-20 23:17:14,282:INFO:   <<< do_train: True
2022-06-20 23:17:14,282:INFO:   <<< epochs: 5
2022-06-20 23:17:14,282:INFO:   <<< eval_frame_order: 0
2022-06-20 23:17:14,282:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 23:17:14,282:INFO:   <<< feature_framerate: 1
2022-06-20 23:17:14,282:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 23:17:14,282:INFO:   <<< fp16: False
2022-06-20 23:17:14,282:INFO:   <<< fp16_opt_level: O1
2022-06-20 23:17:14,282:INFO:   <<< freeze_layer_num: 0
2022-06-20 23:17:14,282:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 23:17:14,282:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 23:17:14,282:INFO:   <<< init_model: None
2022-06-20 23:17:14,282:INFO:   <<< linear_patch: 3d
2022-06-20 23:17:14,282:INFO:   <<< local_rank: 0
2022-06-20 23:17:14,282:INFO:   <<< loose_type: True
2022-06-20 23:17:14,282:INFO:   <<< lr: 0.0001
2022-06-20 23:17:14,282:INFO:   <<< lr_decay: 0.9
2022-06-20 23:17:14,282:INFO:   <<< margin: 0.1
2022-06-20 23:17:14,282:INFO:   <<< max_frames: 12
2022-06-20 23:17:14,282:INFO:   <<< max_words: 32
2022-06-20 23:17:14,282:INFO:   <<< n_display: 50
2022-06-20 23:17:14,282:INFO:   <<< n_gpu: 1
2022-06-20 23:17:14,282:INFO:   <<< n_pair: 1
2022-06-20 23:17:14,282:INFO:   <<< negative_weighting: 1
2022-06-20 23:17:14,282:INFO:   <<< num_thread_reader: 2
2022-06-20 23:17:14,282:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 23:17:14,283:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 23:17:14,283:INFO:   <<< rank: 0
2022-06-20 23:17:14,283:INFO:   <<< resume_model: None
2022-06-20 23:17:14,283:INFO:   <<< sampled_use_mil: False
2022-06-20 23:17:14,283:INFO:   <<< seed: 42
2022-06-20 23:17:14,283:INFO:   <<< sim_header: meanP
2022-06-20 23:17:14,283:INFO:   <<< slice_framepos: 2
2022-06-20 23:17:14,283:INFO:   <<< task_type: retrieval
2022-06-20 23:17:14,283:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 23:17:14,283:INFO:   <<< train_csv: data/.train.csv
2022-06-20 23:17:14,283:INFO:   <<< train_frame_order: 0
2022-06-20 23:17:14,283:INFO:   <<< use_mil: False
2022-06-20 23:17:14,283:INFO:   <<< val_csv: data/.val.csv
2022-06-20 23:17:14,283:INFO:   <<< video_dim: 1024
2022-06-20 23:17:14,283:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 23:17:14,283:INFO:   <<< warmup_proportion: 0.1
2022-06-20 23:17:14,283:INFO:   <<< world_size: 1
2022-06-20 23:17:14,283:INFO: device: cuda:0 n_gpu: 1
2022-06-20 23:17:15,063:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 23:17:15,063:WARNING: Test retrieval by loose type.
2022-06-20 23:17:15,063:WARNING: 	 embed_dim: 512
2022-06-20 23:17:15,063:WARNING: 	 image_resolution: 224
2022-06-20 23:17:15,063:WARNING: 	 vision_layers: 12
2022-06-20 23:17:15,063:WARNING: 	 vision_width: 768
2022-06-20 23:17:15,063:WARNING: 	 vision_patch_size: 32
2022-06-20 23:17:15,063:WARNING: 	 context_length: 77
2022-06-20 23:17:15,064:WARNING: 	 vocab_size: 49408
2022-06-20 23:17:15,064:WARNING: 	 transformer_width: 512
2022-06-20 23:17:15,064:WARNING: 	 transformer_heads: 8
2022-06-20 23:17:15,064:WARNING: 	 transformer_layers: 12
2022-06-20 23:17:15,064:WARNING: 		 linear_patch: 3d
2022-06-20 23:17:15,064:WARNING: 	 cut_top_layer: 0
2022-06-20 23:17:22,304:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-20 23:17:36,652:INFO: ***** Running test *****
2022-06-20 23:17:36,652:INFO:   Num examples = 27763
2022-06-20 23:17:36,652:INFO:   Batch size = 16
2022-06-20 23:17:36,652:INFO:   Num steps = 1736
2022-06-20 23:17:36,652:INFO: ***** Running val *****
2022-06-20 23:17:36,652:INFO:   Num examples = 4290
2022-06-20 23:20:55,356:INFO: Effective parameters:
2022-06-20 23:20:55,356:INFO:   <<< batch_size: 256
2022-06-20 23:20:55,356:INFO:   <<< batch_size_val: 16
2022-06-20 23:20:55,356:INFO:   <<< cache_dir: 
2022-06-20 23:20:55,357:INFO:   <<< coef_lr: 0.001
2022-06-20 23:20:55,357:INFO:   <<< cross_model: cross-base
2022-06-20 23:20:55,357:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 23:20:55,357:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 23:20:55,357:INFO:   <<< datatype: msvd
2022-06-20 23:20:55,357:INFO:   <<< do_eval: False
2022-06-20 23:20:55,357:INFO:   <<< do_lower_case: False
2022-06-20 23:20:55,357:INFO:   <<< do_pretrain: False
2022-06-20 23:20:55,357:INFO:   <<< do_train: True
2022-06-20 23:20:55,357:INFO:   <<< epochs: 5
2022-06-20 23:20:55,357:INFO:   <<< eval_frame_order: 0
2022-06-20 23:20:55,357:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 23:20:55,357:INFO:   <<< feature_framerate: 1
2022-06-20 23:20:55,357:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 23:20:55,357:INFO:   <<< fp16: False
2022-06-20 23:20:55,357:INFO:   <<< fp16_opt_level: O1
2022-06-20 23:20:55,357:INFO:   <<< freeze_layer_num: 0
2022-06-20 23:20:55,357:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 23:20:55,357:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 23:20:55,357:INFO:   <<< init_model: None
2022-06-20 23:20:55,357:INFO:   <<< linear_patch: 3d
2022-06-20 23:20:55,357:INFO:   <<< local_rank: 0
2022-06-20 23:20:55,357:INFO:   <<< loose_type: True
2022-06-20 23:20:55,357:INFO:   <<< lr: 0.0001
2022-06-20 23:20:55,357:INFO:   <<< lr_decay: 0.9
2022-06-20 23:20:55,357:INFO:   <<< margin: 0.1
2022-06-20 23:20:55,357:INFO:   <<< max_frames: 12
2022-06-20 23:20:55,357:INFO:   <<< max_words: 32
2022-06-20 23:20:55,357:INFO:   <<< n_display: 50
2022-06-20 23:20:55,357:INFO:   <<< n_gpu: 1
2022-06-20 23:20:55,357:INFO:   <<< n_pair: 1
2022-06-20 23:20:55,357:INFO:   <<< negative_weighting: 1
2022-06-20 23:20:55,357:INFO:   <<< num_thread_reader: 2
2022-06-20 23:20:55,357:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 23:20:55,357:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 23:20:55,357:INFO:   <<< rank: 0
2022-06-20 23:20:55,358:INFO:   <<< resume_model: None
2022-06-20 23:20:55,358:INFO:   <<< sampled_use_mil: False
2022-06-20 23:20:55,358:INFO:   <<< seed: 42
2022-06-20 23:20:55,358:INFO:   <<< sim_header: meanP
2022-06-20 23:20:55,358:INFO:   <<< slice_framepos: 2
2022-06-20 23:20:55,358:INFO:   <<< task_type: retrieval
2022-06-20 23:20:55,358:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 23:20:55,358:INFO:   <<< train_csv: data/.train.csv
2022-06-20 23:20:55,358:INFO:   <<< train_frame_order: 0
2022-06-20 23:20:55,358:INFO:   <<< use_mil: False
2022-06-20 23:20:55,358:INFO:   <<< val_csv: data/.val.csv
2022-06-20 23:20:55,358:INFO:   <<< video_dim: 1024
2022-06-20 23:20:55,358:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 23:20:55,358:INFO:   <<< warmup_proportion: 0.1
2022-06-20 23:20:55,358:INFO:   <<< world_size: 1
2022-06-20 23:20:55,358:INFO: device: cuda:0 n_gpu: 1
2022-06-20 23:20:56,060:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 23:20:56,060:WARNING: Test retrieval by loose type.
2022-06-20 23:20:56,061:WARNING: 	 embed_dim: 512
2022-06-20 23:20:56,061:WARNING: 	 image_resolution: 224
2022-06-20 23:20:56,061:WARNING: 	 vision_layers: 12
2022-06-20 23:20:56,061:WARNING: 	 vision_width: 768
2022-06-20 23:20:56,061:WARNING: 	 vision_patch_size: 32
2022-06-20 23:20:56,061:WARNING: 	 context_length: 77
2022-06-20 23:20:56,061:WARNING: 	 vocab_size: 49408
2022-06-20 23:20:56,061:WARNING: 	 transformer_width: 512
2022-06-20 23:20:56,061:WARNING: 	 transformer_heads: 8
2022-06-20 23:20:56,061:WARNING: 	 transformer_layers: 12
2022-06-20 23:20:56,061:WARNING: 		 linear_patch: 3d
2022-06-20 23:20:56,061:WARNING: 	 cut_top_layer: 0
2022-06-20 23:21:03,268:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-20 23:21:14,878:INFO: ***** Running test *****
2022-06-20 23:21:14,878:INFO:   Num examples = 27763
2022-06-20 23:21:14,879:INFO:   Batch size = 16
2022-06-20 23:21:14,879:INFO:   Num steps = 1736
2022-06-20 23:21:14,879:INFO: ***** Running val *****
2022-06-20 23:21:14,879:INFO:   Num examples = 4290
2022-06-20 23:21:15,860:INFO: ***** Running training *****
2022-06-20 23:21:15,860:INFO:   Num examples = 48774
2022-06-20 23:21:15,860:INFO:   Batch size = 256
2022-06-20 23:21:15,860:INFO:   Num steps = 950
2022-06-20 23:26:42,577:INFO: Effective parameters:
2022-06-20 23:26:42,577:INFO:   <<< batch_size: 256
2022-06-20 23:26:42,577:INFO:   <<< batch_size_val: 16
2022-06-20 23:26:42,577:INFO:   <<< cache_dir: 
2022-06-20 23:26:42,577:INFO:   <<< coef_lr: 0.001
2022-06-20 23:26:42,577:INFO:   <<< cross_model: cross-base
2022-06-20 23:26:42,577:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 23:26:42,577:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 23:26:42,577:INFO:   <<< datatype: msvd
2022-06-20 23:26:42,577:INFO:   <<< do_eval: False
2022-06-20 23:26:42,577:INFO:   <<< do_lower_case: False
2022-06-20 23:26:42,577:INFO:   <<< do_pretrain: False
2022-06-20 23:26:42,577:INFO:   <<< do_train: True
2022-06-20 23:26:42,577:INFO:   <<< epochs: 5
2022-06-20 23:26:42,577:INFO:   <<< eval_frame_order: 0
2022-06-20 23:26:42,578:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 23:26:42,578:INFO:   <<< feature_framerate: 1
2022-06-20 23:26:42,578:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 23:26:42,578:INFO:   <<< fp16: False
2022-06-20 23:26:42,578:INFO:   <<< fp16_opt_level: O1
2022-06-20 23:26:42,578:INFO:   <<< freeze_layer_num: 0
2022-06-20 23:26:42,578:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 23:26:42,578:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 23:26:42,578:INFO:   <<< init_model: None
2022-06-20 23:26:42,578:INFO:   <<< linear_patch: 3d
2022-06-20 23:26:42,578:INFO:   <<< local_rank: 0
2022-06-20 23:26:42,578:INFO:   <<< loose_type: True
2022-06-20 23:26:42,578:INFO:   <<< lr: 0.0001
2022-06-20 23:26:42,578:INFO:   <<< lr_decay: 0.9
2022-06-20 23:26:42,578:INFO:   <<< margin: 0.1
2022-06-20 23:26:42,578:INFO:   <<< max_frames: 12
2022-06-20 23:26:42,578:INFO:   <<< max_words: 32
2022-06-20 23:26:42,578:INFO:   <<< n_display: 50
2022-06-20 23:26:42,578:INFO:   <<< n_gpu: 1
2022-06-20 23:26:42,578:INFO:   <<< n_pair: 1
2022-06-20 23:26:42,578:INFO:   <<< negative_weighting: 1
2022-06-20 23:26:42,578:INFO:   <<< num_thread_reader: 2
2022-06-20 23:26:42,578:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 23:26:42,578:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 23:26:42,578:INFO:   <<< rank: 0
2022-06-20 23:26:42,578:INFO:   <<< resume_model: None
2022-06-20 23:26:42,578:INFO:   <<< sampled_use_mil: False
2022-06-20 23:26:42,578:INFO:   <<< seed: 42
2022-06-20 23:26:42,578:INFO:   <<< sim_header: meanP
2022-06-20 23:26:42,578:INFO:   <<< slice_framepos: 2
2022-06-20 23:26:42,578:INFO:   <<< task_type: retrieval
2022-06-20 23:26:42,578:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 23:26:42,578:INFO:   <<< train_csv: data/.train.csv
2022-06-20 23:26:42,578:INFO:   <<< train_frame_order: 0
2022-06-20 23:26:42,579:INFO:   <<< use_mil: False
2022-06-20 23:26:42,579:INFO:   <<< val_csv: data/.val.csv
2022-06-20 23:26:42,579:INFO:   <<< video_dim: 1024
2022-06-20 23:26:42,579:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 23:26:42,579:INFO:   <<< warmup_proportion: 0.1
2022-06-20 23:26:42,579:INFO:   <<< world_size: 1
2022-06-20 23:26:42,579:INFO: device: cuda:0 n_gpu: 1
2022-06-20 23:26:43,283:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 23:26:43,283:WARNING: Test retrieval by loose type.
2022-06-20 23:26:43,283:WARNING: 	 embed_dim: 512
2022-06-20 23:26:43,283:WARNING: 	 image_resolution: 224
2022-06-20 23:26:43,283:WARNING: 	 vision_layers: 12
2022-06-20 23:26:43,283:WARNING: 	 vision_width: 768
2022-06-20 23:26:43,284:WARNING: 	 vision_patch_size: 32
2022-06-20 23:26:43,284:WARNING: 	 context_length: 77
2022-06-20 23:26:43,284:WARNING: 	 vocab_size: 49408
2022-06-20 23:26:43,284:WARNING: 	 transformer_width: 512
2022-06-20 23:26:43,284:WARNING: 	 transformer_heads: 8
2022-06-20 23:26:43,284:WARNING: 	 transformer_layers: 12
2022-06-20 23:26:43,284:WARNING: 		 linear_patch: 3d
2022-06-20 23:26:43,284:WARNING: 	 cut_top_layer: 0
2022-06-20 23:26:49,806:INFO: Effective parameters:
2022-06-20 23:26:49,806:INFO:   <<< batch_size: 256
2022-06-20 23:26:49,807:INFO:   <<< batch_size_val: 16
2022-06-20 23:26:49,807:INFO:   <<< cache_dir: 
2022-06-20 23:26:49,807:INFO:   <<< coef_lr: 0.001
2022-06-20 23:26:49,807:INFO:   <<< cross_model: cross-base
2022-06-20 23:26:49,807:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 23:26:49,807:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 23:26:49,807:INFO:   <<< datatype: msvd
2022-06-20 23:26:49,807:INFO:   <<< do_eval: False
2022-06-20 23:26:49,807:INFO:   <<< do_lower_case: False
2022-06-20 23:26:49,807:INFO:   <<< do_pretrain: False
2022-06-20 23:26:49,807:INFO:   <<< do_train: True
2022-06-20 23:26:49,807:INFO:   <<< epochs: 5
2022-06-20 23:26:49,807:INFO:   <<< eval_frame_order: 0
2022-06-20 23:26:49,807:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 23:26:49,807:INFO:   <<< feature_framerate: 1
2022-06-20 23:26:49,807:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 23:26:49,807:INFO:   <<< fp16: False
2022-06-20 23:26:49,807:INFO:   <<< fp16_opt_level: O1
2022-06-20 23:26:49,807:INFO:   <<< freeze_layer_num: 0
2022-06-20 23:26:49,807:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 23:26:49,807:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 23:26:49,807:INFO:   <<< init_model: None
2022-06-20 23:26:49,807:INFO:   <<< linear_patch: 3d
2022-06-20 23:26:49,807:INFO:   <<< local_rank: 0
2022-06-20 23:26:49,807:INFO:   <<< loose_type: True
2022-06-20 23:26:49,807:INFO:   <<< lr: 0.0001
2022-06-20 23:26:49,807:INFO:   <<< lr_decay: 0.9
2022-06-20 23:26:49,807:INFO:   <<< margin: 0.1
2022-06-20 23:26:49,807:INFO:   <<< max_frames: 12
2022-06-20 23:26:49,807:INFO:   <<< max_words: 32
2022-06-20 23:26:49,807:INFO:   <<< n_display: 50
2022-06-20 23:26:49,807:INFO:   <<< n_gpu: 1
2022-06-20 23:26:49,807:INFO:   <<< n_pair: 1
2022-06-20 23:26:49,807:INFO:   <<< negative_weighting: 1
2022-06-20 23:26:49,807:INFO:   <<< num_thread_reader: 2
2022-06-20 23:26:49,808:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 23:26:49,808:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 23:26:49,808:INFO:   <<< rank: 0
2022-06-20 23:26:49,808:INFO:   <<< resume_model: None
2022-06-20 23:26:49,808:INFO:   <<< sampled_use_mil: False
2022-06-20 23:26:49,808:INFO:   <<< seed: 42
2022-06-20 23:26:49,808:INFO:   <<< sim_header: meanP
2022-06-20 23:26:49,808:INFO:   <<< slice_framepos: 2
2022-06-20 23:26:49,808:INFO:   <<< task_type: retrieval
2022-06-20 23:26:49,808:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 23:26:49,808:INFO:   <<< train_csv: data/.train.csv
2022-06-20 23:26:49,808:INFO:   <<< train_frame_order: 0
2022-06-20 23:26:49,808:INFO:   <<< use_mil: False
2022-06-20 23:26:49,808:INFO:   <<< val_csv: data/.val.csv
2022-06-20 23:26:49,808:INFO:   <<< video_dim: 1024
2022-06-20 23:26:49,808:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 23:26:49,808:INFO:   <<< warmup_proportion: 0.1
2022-06-20 23:26:49,808:INFO:   <<< world_size: 1
2022-06-20 23:26:49,808:INFO: device: cuda:0 n_gpu: 1
2022-06-20 23:26:50,526:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 23:26:50,527:WARNING: Test retrieval by loose type.
2022-06-20 23:26:50,527:WARNING: 	 embed_dim: 512
2022-06-20 23:26:50,527:WARNING: 	 image_resolution: 224
2022-06-20 23:26:50,527:WARNING: 	 vision_layers: 12
2022-06-20 23:26:50,527:WARNING: 	 vision_width: 768
2022-06-20 23:26:50,527:WARNING: 	 vision_patch_size: 32
2022-06-20 23:26:50,527:WARNING: 	 context_length: 77
2022-06-20 23:26:50,527:WARNING: 	 vocab_size: 49408
2022-06-20 23:26:50,527:WARNING: 	 transformer_width: 512
2022-06-20 23:26:50,527:WARNING: 	 transformer_heads: 8
2022-06-20 23:26:50,528:WARNING: 	 transformer_layers: 12
2022-06-20 23:26:50,528:WARNING: 		 linear_patch: 3d
2022-06-20 23:26:50,528:WARNING: 	 cut_top_layer: 0
2022-06-20 23:26:57,760:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-20 23:27:08,266:INFO: ***** Running test *****
2022-06-20 23:27:08,266:INFO:   Num examples = 27763
2022-06-20 23:27:08,266:INFO:   Batch size = 16
2022-06-20 23:27:08,266:INFO:   Num steps = 1736
2022-06-20 23:27:08,266:INFO: ***** Running val *****
2022-06-20 23:27:08,266:INFO:   Num examples = 4290
2022-06-20 23:27:09,333:INFO: ***** Running training *****
2022-06-20 23:27:09,333:INFO:   Num examples = 48774
2022-06-20 23:27:09,333:INFO:   Batch size = 256
2022-06-20 23:27:09,333:INFO:   Num steps = 950
2022-06-20 23:31:11,990:INFO: Effective parameters:
2022-06-20 23:31:11,990:INFO:   <<< batch_size: 128
2022-06-20 23:31:11,990:INFO:   <<< batch_size_val: 16
2022-06-20 23:31:11,990:INFO:   <<< cache_dir: 
2022-06-20 23:31:11,990:INFO:   <<< coef_lr: 0.001
2022-06-20 23:31:11,990:INFO:   <<< cross_model: cross-base
2022-06-20 23:31:11,991:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 23:31:11,991:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 23:31:11,991:INFO:   <<< datatype: msvd
2022-06-20 23:31:11,991:INFO:   <<< do_eval: False
2022-06-20 23:31:11,991:INFO:   <<< do_lower_case: False
2022-06-20 23:31:11,991:INFO:   <<< do_pretrain: False
2022-06-20 23:31:11,991:INFO:   <<< do_train: True
2022-06-20 23:31:11,991:INFO:   <<< epochs: 5
2022-06-20 23:31:11,991:INFO:   <<< eval_frame_order: 0
2022-06-20 23:31:11,991:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 23:31:11,991:INFO:   <<< feature_framerate: 1
2022-06-20 23:31:11,991:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 23:31:11,991:INFO:   <<< fp16: False
2022-06-20 23:31:11,991:INFO:   <<< fp16_opt_level: O1
2022-06-20 23:31:11,991:INFO:   <<< freeze_layer_num: 0
2022-06-20 23:31:11,991:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 23:31:11,991:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 23:31:11,991:INFO:   <<< init_model: None
2022-06-20 23:31:11,991:INFO:   <<< linear_patch: 3d
2022-06-20 23:31:11,991:INFO:   <<< local_rank: 0
2022-06-20 23:31:11,991:INFO:   <<< loose_type: True
2022-06-20 23:31:11,991:INFO:   <<< lr: 0.0001
2022-06-20 23:31:11,991:INFO:   <<< lr_decay: 0.9
2022-06-20 23:31:11,991:INFO:   <<< margin: 0.1
2022-06-20 23:31:11,991:INFO:   <<< max_frames: 12
2022-06-20 23:31:11,991:INFO:   <<< max_words: 32
2022-06-20 23:31:11,991:INFO:   <<< n_display: 50
2022-06-20 23:31:11,991:INFO:   <<< n_gpu: 1
2022-06-20 23:31:11,991:INFO:   <<< n_pair: 1
2022-06-20 23:31:11,991:INFO:   <<< negative_weighting: 1
2022-06-20 23:31:11,991:INFO:   <<< num_thread_reader: 2
2022-06-20 23:31:11,991:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 23:31:11,991:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 23:31:11,991:INFO:   <<< rank: 0
2022-06-20 23:31:11,992:INFO:   <<< resume_model: None
2022-06-20 23:31:11,992:INFO:   <<< sampled_use_mil: False
2022-06-20 23:31:11,992:INFO:   <<< seed: 42
2022-06-20 23:31:11,992:INFO:   <<< sim_header: meanP
2022-06-20 23:31:11,992:INFO:   <<< slice_framepos: 2
2022-06-20 23:31:11,992:INFO:   <<< task_type: retrieval
2022-06-20 23:31:11,992:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 23:31:11,992:INFO:   <<< train_csv: data/.train.csv
2022-06-20 23:31:11,992:INFO:   <<< train_frame_order: 0
2022-06-20 23:31:11,992:INFO:   <<< use_mil: False
2022-06-20 23:31:11,992:INFO:   <<< val_csv: data/.val.csv
2022-06-20 23:31:11,992:INFO:   <<< video_dim: 1024
2022-06-20 23:31:11,992:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 23:31:11,992:INFO:   <<< warmup_proportion: 0.1
2022-06-20 23:31:11,992:INFO:   <<< world_size: 1
2022-06-20 23:31:11,992:INFO: device: cuda:0 n_gpu: 1
2022-06-20 23:31:12,760:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 23:31:12,760:WARNING: Test retrieval by loose type.
2022-06-20 23:31:12,761:WARNING: 	 embed_dim: 512
2022-06-20 23:31:12,761:WARNING: 	 image_resolution: 224
2022-06-20 23:31:12,761:WARNING: 	 vision_layers: 12
2022-06-20 23:31:12,761:WARNING: 	 vision_width: 768
2022-06-20 23:31:12,761:WARNING: 	 vision_patch_size: 32
2022-06-20 23:31:12,761:WARNING: 	 context_length: 77
2022-06-20 23:31:12,761:WARNING: 	 vocab_size: 49408
2022-06-20 23:31:12,761:WARNING: 	 transformer_width: 512
2022-06-20 23:31:12,761:WARNING: 	 transformer_heads: 8
2022-06-20 23:31:12,761:WARNING: 	 transformer_layers: 12
2022-06-20 23:31:12,761:WARNING: 		 linear_patch: 3d
2022-06-20 23:31:12,761:WARNING: 	 cut_top_layer: 0
2022-06-20 23:31:19,894:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-20 23:31:31,823:INFO: ***** Running test *****
2022-06-20 23:31:31,823:INFO:   Num examples = 27763
2022-06-20 23:31:31,823:INFO:   Batch size = 16
2022-06-20 23:31:31,823:INFO:   Num steps = 1736
2022-06-20 23:31:31,823:INFO: ***** Running val *****
2022-06-20 23:31:31,823:INFO:   Num examples = 4290
2022-06-20 23:31:34,268:INFO: ***** Running training *****
2022-06-20 23:31:34,269:INFO:   Num examples = 48774
2022-06-20 23:31:34,269:INFO:   Batch size = 128
2022-06-20 23:31:34,269:INFO:   Num steps = 1905
2022-06-20 23:36:19,662:INFO: Effective parameters:
2022-06-20 23:36:19,662:INFO:   <<< batch_size: 64
2022-06-20 23:36:19,662:INFO:   <<< batch_size_val: 16
2022-06-20 23:36:19,662:INFO:   <<< cache_dir: 
2022-06-20 23:36:19,663:INFO:   <<< coef_lr: 0.001
2022-06-20 23:36:19,663:INFO:   <<< cross_model: cross-base
2022-06-20 23:36:19,663:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 23:36:19,663:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 23:36:19,663:INFO:   <<< datatype: msvd
2022-06-20 23:36:19,663:INFO:   <<< do_eval: False
2022-06-20 23:36:19,663:INFO:   <<< do_lower_case: False
2022-06-20 23:36:19,663:INFO:   <<< do_pretrain: False
2022-06-20 23:36:19,663:INFO:   <<< do_train: True
2022-06-20 23:36:19,663:INFO:   <<< epochs: 5
2022-06-20 23:36:19,663:INFO:   <<< eval_frame_order: 0
2022-06-20 23:36:19,663:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 23:36:19,663:INFO:   <<< feature_framerate: 1
2022-06-20 23:36:19,663:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 23:36:19,663:INFO:   <<< fp16: False
2022-06-20 23:36:19,664:INFO:   <<< fp16_opt_level: O1
2022-06-20 23:36:19,664:INFO:   <<< freeze_layer_num: 0
2022-06-20 23:36:19,664:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 23:36:19,664:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 23:36:19,664:INFO:   <<< init_model: None
2022-06-20 23:36:19,664:INFO:   <<< linear_patch: 3d
2022-06-20 23:36:19,664:INFO:   <<< local_rank: 0
2022-06-20 23:36:19,664:INFO:   <<< loose_type: True
2022-06-20 23:36:19,664:INFO:   <<< lr: 0.0001
2022-06-20 23:36:19,664:INFO:   <<< lr_decay: 0.9
2022-06-20 23:36:19,664:INFO:   <<< margin: 0.1
2022-06-20 23:36:19,664:INFO:   <<< max_frames: 12
2022-06-20 23:36:19,664:INFO:   <<< max_words: 32
2022-06-20 23:36:19,664:INFO:   <<< n_display: 50
2022-06-20 23:36:19,664:INFO:   <<< n_gpu: 1
2022-06-20 23:36:19,664:INFO:   <<< n_pair: 1
2022-06-20 23:36:19,665:INFO:   <<< negative_weighting: 1
2022-06-20 23:36:19,665:INFO:   <<< num_thread_reader: 2
2022-06-20 23:36:19,665:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 23:36:19,665:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 23:36:19,665:INFO:   <<< rank: 0
2022-06-20 23:36:19,665:INFO:   <<< resume_model: None
2022-06-20 23:36:19,665:INFO:   <<< sampled_use_mil: False
2022-06-20 23:36:19,665:INFO:   <<< seed: 42
2022-06-20 23:36:19,665:INFO:   <<< sim_header: meanP
2022-06-20 23:36:19,665:INFO:   <<< slice_framepos: 2
2022-06-20 23:36:19,665:INFO:   <<< task_type: retrieval
2022-06-20 23:36:19,665:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 23:36:19,665:INFO:   <<< train_csv: data/.train.csv
2022-06-20 23:36:19,665:INFO:   <<< train_frame_order: 0
2022-06-20 23:36:19,665:INFO:   <<< use_mil: False
2022-06-20 23:36:19,666:INFO:   <<< val_csv: data/.val.csv
2022-06-20 23:36:19,666:INFO:   <<< video_dim: 1024
2022-06-20 23:36:19,666:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 23:36:19,666:INFO:   <<< warmup_proportion: 0.1
2022-06-20 23:36:19,666:INFO:   <<< world_size: 1
2022-06-20 23:36:19,666:INFO: device: cuda:0 n_gpu: 1
2022-06-20 23:36:20,409:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 23:36:20,409:WARNING: Test retrieval by loose type.
2022-06-20 23:36:20,410:WARNING: 	 embed_dim: 512
2022-06-20 23:36:20,410:WARNING: 	 image_resolution: 224
2022-06-20 23:36:20,410:WARNING: 	 vision_layers: 12
2022-06-20 23:36:20,410:WARNING: 	 vision_width: 768
2022-06-20 23:36:20,410:WARNING: 	 vision_patch_size: 32
2022-06-20 23:36:20,410:WARNING: 	 context_length: 77
2022-06-20 23:36:20,410:WARNING: 	 vocab_size: 49408
2022-06-20 23:36:20,410:WARNING: 	 transformer_width: 512
2022-06-20 23:36:20,410:WARNING: 	 transformer_heads: 8
2022-06-20 23:36:20,410:WARNING: 	 transformer_layers: 12
2022-06-20 23:36:20,410:WARNING: 		 linear_patch: 3d
2022-06-20 23:36:20,410:WARNING: 	 cut_top_layer: 0
2022-06-20 23:36:27,709:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-20 23:36:38,368:INFO: ***** Running test *****
2022-06-20 23:36:38,368:INFO:   Num examples = 27763
2022-06-20 23:36:38,368:INFO:   Batch size = 16
2022-06-20 23:36:38,368:INFO:   Num steps = 1736
2022-06-20 23:36:38,368:INFO: ***** Running val *****
2022-06-20 23:36:38,368:INFO:   Num examples = 4290
2022-06-20 23:36:39,247:INFO: ***** Running training *****
2022-06-20 23:36:39,247:INFO:   Num examples = 48774
2022-06-20 23:36:39,247:INFO:   Batch size = 64
2022-06-20 23:36:39,247:INFO:   Num steps = 3810
2022-06-20 23:41:11,174:INFO: Effective parameters:
2022-06-20 23:41:11,174:INFO:   <<< batch_size: 64
2022-06-20 23:41:11,174:INFO:   <<< batch_size_val: 16
2022-06-20 23:41:11,174:INFO:   <<< cache_dir: 
2022-06-20 23:41:11,174:INFO:   <<< coef_lr: 0.001
2022-06-20 23:41:11,174:INFO:   <<< cross_model: cross-base
2022-06-20 23:41:11,175:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 23:41:11,175:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 23:41:11,175:INFO:   <<< datatype: msvd
2022-06-20 23:41:11,175:INFO:   <<< do_eval: False
2022-06-20 23:41:11,175:INFO:   <<< do_lower_case: False
2022-06-20 23:41:11,175:INFO:   <<< do_pretrain: False
2022-06-20 23:41:11,175:INFO:   <<< do_train: True
2022-06-20 23:41:11,175:INFO:   <<< epochs: 5
2022-06-20 23:41:11,175:INFO:   <<< eval_frame_order: 0
2022-06-20 23:41:11,175:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 23:41:11,175:INFO:   <<< feature_framerate: 1
2022-06-20 23:41:11,175:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 23:41:11,175:INFO:   <<< fp16: False
2022-06-20 23:41:11,175:INFO:   <<< fp16_opt_level: O1
2022-06-20 23:41:11,175:INFO:   <<< freeze_layer_num: 0
2022-06-20 23:41:11,176:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 23:41:11,176:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 23:41:11,176:INFO:   <<< init_model: None
2022-06-20 23:41:11,176:INFO:   <<< linear_patch: 3d
2022-06-20 23:41:11,176:INFO:   <<< local_rank: 0
2022-06-20 23:41:11,176:INFO:   <<< loose_type: True
2022-06-20 23:41:11,176:INFO:   <<< lr: 0.0001
2022-06-20 23:41:11,176:INFO:   <<< lr_decay: 0.9
2022-06-20 23:41:11,176:INFO:   <<< margin: 0.1
2022-06-20 23:41:11,176:INFO:   <<< max_frames: 12
2022-06-20 23:41:11,176:INFO:   <<< max_words: 32
2022-06-20 23:41:11,176:INFO:   <<< n_display: 50
2022-06-20 23:41:11,176:INFO:   <<< n_gpu: 1
2022-06-20 23:41:11,176:INFO:   <<< n_pair: 1
2022-06-20 23:41:11,176:INFO:   <<< negative_weighting: 1
2022-06-20 23:41:11,177:INFO:   <<< num_thread_reader: 2
2022-06-20 23:41:11,177:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 23:41:11,177:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 23:41:11,177:INFO:   <<< rank: 0
2022-06-20 23:41:11,177:INFO:   <<< resume_model: None
2022-06-20 23:41:11,177:INFO:   <<< sampled_use_mil: False
2022-06-20 23:41:11,177:INFO:   <<< seed: 42
2022-06-20 23:41:11,177:INFO:   <<< sim_header: meanP
2022-06-20 23:41:11,177:INFO:   <<< slice_framepos: 2
2022-06-20 23:41:11,177:INFO:   <<< task_type: retrieval
2022-06-20 23:41:11,177:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 23:41:11,177:INFO:   <<< train_csv: data/.train.csv
2022-06-20 23:41:11,177:INFO:   <<< train_frame_order: 0
2022-06-20 23:41:11,177:INFO:   <<< use_mil: False
2022-06-20 23:41:11,177:INFO:   <<< val_csv: data/.val.csv
2022-06-20 23:41:11,177:INFO:   <<< video_dim: 1024
2022-06-20 23:41:11,178:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 23:41:11,178:INFO:   <<< warmup_proportion: 0.1
2022-06-20 23:41:11,178:INFO:   <<< world_size: 1
2022-06-20 23:41:11,178:INFO: device: cuda:0 n_gpu: 1
2022-06-20 23:41:11,914:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 23:41:11,915:WARNING: Test retrieval by loose type.
2022-06-20 23:41:11,915:WARNING: 	 embed_dim: 512
2022-06-20 23:41:11,915:WARNING: 	 image_resolution: 224
2022-06-20 23:41:11,915:WARNING: 	 vision_layers: 12
2022-06-20 23:41:11,915:WARNING: 	 vision_width: 768
2022-06-20 23:41:11,915:WARNING: 	 vision_patch_size: 32
2022-06-20 23:41:11,915:WARNING: 	 context_length: 77
2022-06-20 23:41:11,915:WARNING: 	 vocab_size: 49408
2022-06-20 23:41:11,915:WARNING: 	 transformer_width: 512
2022-06-20 23:41:11,915:WARNING: 	 transformer_heads: 8
2022-06-20 23:41:11,915:WARNING: 	 transformer_layers: 12
2022-06-20 23:41:11,915:WARNING: 		 linear_patch: 3d
2022-06-20 23:41:11,915:WARNING: 	 cut_top_layer: 0
2022-06-20 23:41:19,364:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-20 23:41:31,483:INFO: ***** Running test *****
2022-06-20 23:41:31,484:INFO:   Num examples = 27763
2022-06-20 23:41:31,484:INFO:   Batch size = 16
2022-06-20 23:41:31,484:INFO:   Num steps = 1736
2022-06-20 23:41:31,484:INFO: ***** Running val *****
2022-06-20 23:41:31,484:INFO:   Num examples = 4290
2022-06-20 23:41:34,075:INFO: ***** Running training *****
2022-06-20 23:41:34,075:INFO:   Num examples = 48774
2022-06-20 23:41:34,075:INFO:   Batch size = 64
2022-06-20 23:41:34,075:INFO:   Num steps = 3810
2022-06-20 23:42:41,649:INFO: Effective parameters:
2022-06-20 23:42:41,649:INFO:   <<< batch_size: 128
2022-06-20 23:42:41,649:INFO:   <<< batch_size_val: 16
2022-06-20 23:42:41,650:INFO:   <<< cache_dir: 
2022-06-20 23:42:41,650:INFO:   <<< coef_lr: 0.001
2022-06-20 23:42:41,650:INFO:   <<< cross_model: cross-base
2022-06-20 23:42:41,650:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 23:42:41,650:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 23:42:41,650:INFO:   <<< datatype: msvd
2022-06-20 23:42:41,650:INFO:   <<< do_eval: False
2022-06-20 23:42:41,650:INFO:   <<< do_lower_case: False
2022-06-20 23:42:41,650:INFO:   <<< do_pretrain: False
2022-06-20 23:42:41,650:INFO:   <<< do_train: True
2022-06-20 23:42:41,650:INFO:   <<< epochs: 5
2022-06-20 23:42:41,650:INFO:   <<< eval_frame_order: 0
2022-06-20 23:42:41,650:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 23:42:41,650:INFO:   <<< feature_framerate: 1
2022-06-20 23:42:41,650:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 23:42:41,650:INFO:   <<< fp16: False
2022-06-20 23:42:41,650:INFO:   <<< fp16_opt_level: O1
2022-06-20 23:42:41,650:INFO:   <<< freeze_layer_num: 0
2022-06-20 23:42:41,650:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 23:42:41,650:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 23:42:41,650:INFO:   <<< init_model: None
2022-06-20 23:42:41,650:INFO:   <<< linear_patch: 3d
2022-06-20 23:42:41,650:INFO:   <<< local_rank: 0
2022-06-20 23:42:41,650:INFO:   <<< loose_type: True
2022-06-20 23:42:41,650:INFO:   <<< lr: 0.0001
2022-06-20 23:42:41,650:INFO:   <<< lr_decay: 0.9
2022-06-20 23:42:41,650:INFO:   <<< margin: 0.1
2022-06-20 23:42:41,650:INFO:   <<< max_frames: 12
2022-06-20 23:42:41,650:INFO:   <<< max_words: 32
2022-06-20 23:42:41,650:INFO:   <<< n_display: 50
2022-06-20 23:42:41,650:INFO:   <<< n_gpu: 1
2022-06-20 23:42:41,651:INFO:   <<< n_pair: 1
2022-06-20 23:42:41,651:INFO:   <<< negative_weighting: 1
2022-06-20 23:42:41,651:INFO:   <<< num_thread_reader: 2
2022-06-20 23:42:41,651:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 23:42:41,651:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 23:42:41,651:INFO:   <<< rank: 0
2022-06-20 23:42:41,651:INFO:   <<< resume_model: None
2022-06-20 23:42:41,651:INFO:   <<< sampled_use_mil: False
2022-06-20 23:42:41,651:INFO:   <<< seed: 42
2022-06-20 23:42:41,651:INFO:   <<< sim_header: meanP
2022-06-20 23:42:41,651:INFO:   <<< slice_framepos: 2
2022-06-20 23:42:41,651:INFO:   <<< task_type: retrieval
2022-06-20 23:42:41,651:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 23:42:41,651:INFO:   <<< train_csv: data/.train.csv
2022-06-20 23:42:41,651:INFO:   <<< train_frame_order: 0
2022-06-20 23:42:41,651:INFO:   <<< use_mil: False
2022-06-20 23:42:41,651:INFO:   <<< val_csv: data/.val.csv
2022-06-20 23:42:41,651:INFO:   <<< video_dim: 1024
2022-06-20 23:42:41,651:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 23:42:41,651:INFO:   <<< warmup_proportion: 0.1
2022-06-20 23:42:41,651:INFO:   <<< world_size: 1
2022-06-20 23:42:41,651:INFO: device: cuda:0 n_gpu: 1
2022-06-20 23:42:42,377:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 23:42:42,378:WARNING: Test retrieval by loose type.
2022-06-20 23:42:42,378:WARNING: 	 embed_dim: 512
2022-06-20 23:42:42,378:WARNING: 	 image_resolution: 224
2022-06-20 23:42:42,378:WARNING: 	 vision_layers: 12
2022-06-20 23:42:42,378:WARNING: 	 vision_width: 768
2022-06-20 23:42:42,378:WARNING: 	 vision_patch_size: 32
2022-06-20 23:42:42,378:WARNING: 	 context_length: 77
2022-06-20 23:42:42,378:WARNING: 	 vocab_size: 49408
2022-06-20 23:42:42,378:WARNING: 	 transformer_width: 512
2022-06-20 23:42:42,378:WARNING: 	 transformer_heads: 8
2022-06-20 23:42:42,378:WARNING: 	 transformer_layers: 12
2022-06-20 23:42:42,378:WARNING: 		 linear_patch: 3d
2022-06-20 23:42:42,378:WARNING: 	 cut_top_layer: 0
2022-06-20 23:42:50,264:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-20 23:43:00,469:INFO: ***** Running test *****
2022-06-20 23:43:00,469:INFO:   Num examples = 27763
2022-06-20 23:43:00,470:INFO:   Batch size = 16
2022-06-20 23:43:00,470:INFO:   Num steps = 1736
2022-06-20 23:43:00,470:INFO: ***** Running val *****
2022-06-20 23:43:00,470:INFO:   Num examples = 4290
2022-06-20 23:43:02,599:INFO: ***** Running training *****
2022-06-20 23:43:02,599:INFO:   Num examples = 48774
2022-06-20 23:43:02,599:INFO:   Batch size = 128
2022-06-20 23:43:02,599:INFO:   Num steps = 1905
2022-06-20 23:52:32,980:INFO: Effective parameters:
2022-06-20 23:52:32,981:INFO:   <<< batch_size: 128
2022-06-20 23:52:32,981:INFO:   <<< batch_size_val: 16
2022-06-20 23:52:32,981:INFO:   <<< cache_dir: 
2022-06-20 23:52:32,981:INFO:   <<< coef_lr: 0.001
2022-06-20 23:52:32,981:INFO:   <<< cross_model: cross-base
2022-06-20 23:52:32,981:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 23:52:32,981:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 23:52:32,981:INFO:   <<< datatype: msvd
2022-06-20 23:52:32,981:INFO:   <<< do_eval: False
2022-06-20 23:52:32,981:INFO:   <<< do_lower_case: False
2022-06-20 23:52:32,981:INFO:   <<< do_pretrain: False
2022-06-20 23:52:32,982:INFO:   <<< do_train: True
2022-06-20 23:52:32,982:INFO:   <<< epochs: 5
2022-06-20 23:52:32,982:INFO:   <<< eval_frame_order: 0
2022-06-20 23:52:32,982:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 23:52:32,982:INFO:   <<< feature_framerate: 1
2022-06-20 23:52:32,982:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 23:52:32,982:INFO:   <<< fp16: False
2022-06-20 23:52:32,982:INFO:   <<< fp16_opt_level: O1
2022-06-20 23:52:32,982:INFO:   <<< freeze_layer_num: 0
2022-06-20 23:52:32,982:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 23:52:32,982:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 23:52:32,982:INFO:   <<< init_model: None
2022-06-20 23:52:32,982:INFO:   <<< linear_patch: 3d
2022-06-20 23:52:32,982:INFO:   <<< local_rank: 0
2022-06-20 23:52:32,983:INFO:   <<< loose_type: True
2022-06-20 23:52:32,983:INFO:   <<< lr: 0.0001
2022-06-20 23:52:32,983:INFO:   <<< lr_decay: 0.9
2022-06-20 23:52:32,983:INFO:   <<< margin: 0.1
2022-06-20 23:52:32,983:INFO:   <<< max_frames: 12
2022-06-20 23:52:32,983:INFO:   <<< max_words: 32
2022-06-20 23:52:32,983:INFO:   <<< n_display: 50
2022-06-20 23:52:32,983:INFO:   <<< n_gpu: 1
2022-06-20 23:52:32,983:INFO:   <<< n_pair: 1
2022-06-20 23:52:32,983:INFO:   <<< negative_weighting: 1
2022-06-20 23:52:32,983:INFO:   <<< num_thread_reader: 2
2022-06-20 23:52:32,983:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 23:52:32,983:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 23:52:32,983:INFO:   <<< rank: 0
2022-06-20 23:52:32,984:INFO:   <<< resume_model: None
2022-06-20 23:52:32,984:INFO:   <<< sampled_use_mil: False
2022-06-20 23:52:32,984:INFO:   <<< seed: 42
2022-06-20 23:52:32,984:INFO:   <<< sim_header: meanP
2022-06-20 23:52:32,984:INFO:   <<< slice_framepos: 2
2022-06-20 23:52:32,984:INFO:   <<< task_type: retrieval
2022-06-20 23:52:32,984:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 23:52:32,984:INFO:   <<< train_csv: data/.train.csv
2022-06-20 23:52:32,984:INFO:   <<< train_frame_order: 0
2022-06-20 23:52:32,984:INFO:   <<< use_mil: False
2022-06-20 23:52:32,984:INFO:   <<< val_csv: data/.val.csv
2022-06-20 23:52:32,984:INFO:   <<< video_dim: 1024
2022-06-20 23:52:32,984:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 23:52:32,984:INFO:   <<< warmup_proportion: 0.1
2022-06-20 23:52:32,984:INFO:   <<< world_size: 1
2022-06-20 23:52:32,985:INFO: device: cuda:0 n_gpu: 1
2022-06-20 23:52:33,673:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 23:52:33,674:WARNING: Test retrieval by loose type.
2022-06-20 23:52:33,674:WARNING: 	 embed_dim: 512
2022-06-20 23:52:33,674:WARNING: 	 image_resolution: 224
2022-06-20 23:52:33,674:WARNING: 	 vision_layers: 12
2022-06-20 23:52:33,674:WARNING: 	 vision_width: 768
2022-06-20 23:52:33,674:WARNING: 	 vision_patch_size: 32
2022-06-20 23:52:33,674:WARNING: 	 context_length: 77
2022-06-20 23:52:33,674:WARNING: 	 vocab_size: 49408
2022-06-20 23:52:33,674:WARNING: 	 transformer_width: 512
2022-06-20 23:52:33,674:WARNING: 	 transformer_heads: 8
2022-06-20 23:52:33,674:WARNING: 	 transformer_layers: 12
2022-06-20 23:52:33,674:WARNING: 		 linear_patch: 3d
2022-06-20 23:52:33,674:WARNING: 	 cut_top_layer: 0
2022-06-20 23:52:40,757:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-20 23:52:52,645:INFO: ***** Running test *****
2022-06-20 23:52:52,645:INFO:   Num examples = 27763
2022-06-20 23:52:52,646:INFO:   Batch size = 16
2022-06-20 23:52:52,646:INFO:   Num steps = 1736
2022-06-20 23:52:52,646:INFO: ***** Running val *****
2022-06-20 23:52:52,646:INFO:   Num examples = 4290
2022-06-20 23:52:54,858:INFO: ***** Running training *****
2022-06-20 23:52:54,858:INFO:   Num examples = 48774
2022-06-20 23:52:54,858:INFO:   Batch size = 128
2022-06-20 23:52:54,858:INFO:   Num steps = 1905
2022-06-20 23:58:49,454:INFO: Effective parameters:
2022-06-20 23:58:49,454:INFO:   <<< batch_size: 128
2022-06-20 23:58:49,455:INFO:   <<< batch_size_val: 16
2022-06-20 23:58:49,455:INFO:   <<< cache_dir: 
2022-06-20 23:58:49,455:INFO:   <<< coef_lr: 0.001
2022-06-20 23:58:49,455:INFO:   <<< cross_model: cross-base
2022-06-20 23:58:49,455:INFO:   <<< cross_num_hidden_layers: 4
2022-06-20 23:58:49,455:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-20 23:58:49,455:INFO:   <<< datatype: msvd
2022-06-20 23:58:49,455:INFO:   <<< do_eval: False
2022-06-20 23:58:49,455:INFO:   <<< do_lower_case: False
2022-06-20 23:58:49,455:INFO:   <<< do_pretrain: False
2022-06-20 23:58:49,455:INFO:   <<< do_train: True
2022-06-20 23:58:49,455:INFO:   <<< epochs: 5
2022-06-20 23:58:49,455:INFO:   <<< eval_frame_order: 0
2022-06-20 23:58:49,455:INFO:   <<< expand_msrvtt_sentences: False
2022-06-20 23:58:49,455:INFO:   <<< feature_framerate: 1
2022-06-20 23:58:49,455:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-20 23:58:49,455:INFO:   <<< fp16: False
2022-06-20 23:58:49,455:INFO:   <<< fp16_opt_level: O1
2022-06-20 23:58:49,455:INFO:   <<< freeze_layer_num: 0
2022-06-20 23:58:49,455:INFO:   <<< gradient_accumulation_steps: 1
2022-06-20 23:58:49,455:INFO:   <<< hard_negative_rate: 0.5
2022-06-20 23:58:49,455:INFO:   <<< init_model: None
2022-06-20 23:58:49,455:INFO:   <<< linear_patch: 3d
2022-06-20 23:58:49,455:INFO:   <<< local_rank: 0
2022-06-20 23:58:49,455:INFO:   <<< loose_type: True
2022-06-20 23:58:49,455:INFO:   <<< lr: 0.0001
2022-06-20 23:58:49,455:INFO:   <<< lr_decay: 0.9
2022-06-20 23:58:49,455:INFO:   <<< margin: 0.1
2022-06-20 23:58:49,455:INFO:   <<< max_frames: 12
2022-06-20 23:58:49,456:INFO:   <<< max_words: 32
2022-06-20 23:58:49,456:INFO:   <<< n_display: 50
2022-06-20 23:58:49,456:INFO:   <<< n_gpu: 1
2022-06-20 23:58:49,456:INFO:   <<< n_pair: 1
2022-06-20 23:58:49,456:INFO:   <<< negative_weighting: 1
2022-06-20 23:58:49,456:INFO:   <<< num_thread_reader: 2
2022-06-20 23:58:49,456:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-20 23:58:49,456:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-20 23:58:49,456:INFO:   <<< rank: 0
2022-06-20 23:58:49,456:INFO:   <<< resume_model: None
2022-06-20 23:58:49,456:INFO:   <<< sampled_use_mil: False
2022-06-20 23:58:49,456:INFO:   <<< seed: 42
2022-06-20 23:58:49,456:INFO:   <<< sim_header: meanP
2022-06-20 23:58:49,456:INFO:   <<< slice_framepos: 2
2022-06-20 23:58:49,456:INFO:   <<< task_type: retrieval
2022-06-20 23:58:49,456:INFO:   <<< text_num_hidden_layers: 12
2022-06-20 23:58:49,456:INFO:   <<< train_csv: data/.train.csv
2022-06-20 23:58:49,456:INFO:   <<< train_frame_order: 0
2022-06-20 23:58:49,456:INFO:   <<< use_mil: False
2022-06-20 23:58:49,456:INFO:   <<< val_csv: data/.val.csv
2022-06-20 23:58:49,456:INFO:   <<< video_dim: 1024
2022-06-20 23:58:49,456:INFO:   <<< visual_num_hidden_layers: 12
2022-06-20 23:58:49,456:INFO:   <<< warmup_proportion: 0.1
2022-06-20 23:58:49,456:INFO:   <<< world_size: 1
2022-06-20 23:58:49,456:INFO: device: cuda:0 n_gpu: 1
2022-06-20 23:58:50,241:WARNING: Stage-One:True, Stage-Two:False
2022-06-20 23:58:50,241:WARNING: Test retrieval by loose type.
2022-06-20 23:58:50,241:WARNING: 	 embed_dim: 512
2022-06-20 23:58:50,241:WARNING: 	 image_resolution: 224
2022-06-20 23:58:50,241:WARNING: 	 vision_layers: 12
2022-06-20 23:58:50,241:WARNING: 	 vision_width: 768
2022-06-20 23:58:50,241:WARNING: 	 vision_patch_size: 32
2022-06-20 23:58:50,241:WARNING: 	 context_length: 77
2022-06-20 23:58:50,241:WARNING: 	 vocab_size: 49408
2022-06-20 23:58:50,241:WARNING: 	 transformer_width: 512
2022-06-20 23:58:50,241:WARNING: 	 transformer_heads: 8
2022-06-20 23:58:50,241:WARNING: 	 transformer_layers: 12
2022-06-20 23:58:50,241:WARNING: 		 linear_patch: 3d
2022-06-20 23:58:50,241:WARNING: 	 cut_top_layer: 0
2022-06-20 23:58:57,706:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-20 23:59:11,309:INFO: ***** Running test *****
2022-06-20 23:59:11,309:INFO:   Num examples = 27763
2022-06-20 23:59:11,309:INFO:   Batch size = 16
2022-06-20 23:59:11,309:INFO:   Num steps = 1736
2022-06-20 23:59:11,309:INFO: ***** Running val *****
2022-06-20 23:59:11,309:INFO:   Num examples = 4290
2022-06-20 23:59:12,013:INFO: ***** Running training *****
2022-06-20 23:59:12,013:INFO:   Num examples = 48774
2022-06-20 23:59:12,013:INFO:   Batch size = 128
2022-06-20 23:59:12,013:INFO:   Num steps = 1905
2022-06-21 00:03:03,919:INFO: Effective parameters:
2022-06-21 00:03:03,919:INFO:   <<< batch_size: 128
2022-06-21 00:03:03,919:INFO:   <<< batch_size_val: 16
2022-06-21 00:03:03,919:INFO:   <<< cache_dir: 
2022-06-21 00:03:03,919:INFO:   <<< coef_lr: 0.001
2022-06-21 00:03:03,919:INFO:   <<< cross_model: cross-base
2022-06-21 00:03:03,919:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:03:03,919:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:03:03,920:INFO:   <<< datatype: msvd
2022-06-21 00:03:03,920:INFO:   <<< do_eval: False
2022-06-21 00:03:03,920:INFO:   <<< do_lower_case: False
2022-06-21 00:03:03,920:INFO:   <<< do_pretrain: False
2022-06-21 00:03:03,920:INFO:   <<< do_train: True
2022-06-21 00:03:03,920:INFO:   <<< epochs: 5
2022-06-21 00:03:03,920:INFO:   <<< eval_frame_order: 0
2022-06-21 00:03:03,920:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:03:03,920:INFO:   <<< feature_framerate: 1
2022-06-21 00:03:03,920:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:03:03,920:INFO:   <<< fp16: False
2022-06-21 00:03:03,920:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:03:03,920:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:03:03,920:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:03:03,920:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:03:03,921:INFO:   <<< init_model: None
2022-06-21 00:03:03,921:INFO:   <<< linear_patch: 3d
2022-06-21 00:03:03,921:INFO:   <<< local_rank: 0
2022-06-21 00:03:03,921:INFO:   <<< loose_type: True
2022-06-21 00:03:03,921:INFO:   <<< lr: 0.0001
2022-06-21 00:03:03,921:INFO:   <<< lr_decay: 0.9
2022-06-21 00:03:03,921:INFO:   <<< margin: 0.1
2022-06-21 00:03:03,921:INFO:   <<< max_frames: 12
2022-06-21 00:03:03,921:INFO:   <<< max_words: 32
2022-06-21 00:03:03,921:INFO:   <<< n_display: 50
2022-06-21 00:03:03,921:INFO:   <<< n_gpu: 1
2022-06-21 00:03:03,921:INFO:   <<< n_pair: 1
2022-06-21 00:03:03,921:INFO:   <<< negative_weighting: 1
2022-06-21 00:03:03,921:INFO:   <<< num_thread_reader: 2
2022-06-21 00:03:03,922:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:03:03,922:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:03:03,922:INFO:   <<< rank: 0
2022-06-21 00:03:03,922:INFO:   <<< resume_model: None
2022-06-21 00:03:03,922:INFO:   <<< sampled_use_mil: False
2022-06-21 00:03:03,922:INFO:   <<< seed: 42
2022-06-21 00:03:03,922:INFO:   <<< sim_header: meanP
2022-06-21 00:03:03,922:INFO:   <<< slice_framepos: 2
2022-06-21 00:03:03,922:INFO:   <<< task_type: retrieval
2022-06-21 00:03:03,922:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:03:03,922:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:03:03,922:INFO:   <<< train_frame_order: 0
2022-06-21 00:03:03,922:INFO:   <<< use_mil: False
2022-06-21 00:03:03,922:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:03:03,923:INFO:   <<< video_dim: 1024
2022-06-21 00:03:03,923:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:03:03,923:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:03:03,923:INFO:   <<< world_size: 1
2022-06-21 00:03:03,923:INFO: device: cuda:0 n_gpu: 1
2022-06-21 00:03:04,632:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:03:04,632:WARNING: Test retrieval by loose type.
2022-06-21 00:03:04,632:WARNING: 	 embed_dim: 512
2022-06-21 00:03:04,633:WARNING: 	 image_resolution: 224
2022-06-21 00:03:04,633:WARNING: 	 vision_layers: 12
2022-06-21 00:03:04,633:WARNING: 	 vision_width: 768
2022-06-21 00:03:04,633:WARNING: 	 vision_patch_size: 32
2022-06-21 00:03:04,633:WARNING: 	 context_length: 77
2022-06-21 00:03:04,633:WARNING: 	 vocab_size: 49408
2022-06-21 00:03:04,633:WARNING: 	 transformer_width: 512
2022-06-21 00:03:04,633:WARNING: 	 transformer_heads: 8
2022-06-21 00:03:04,633:WARNING: 	 transformer_layers: 12
2022-06-21 00:03:04,633:WARNING: 		 linear_patch: 3d
2022-06-21 00:03:04,633:WARNING: 	 cut_top_layer: 0
2022-06-21 00:03:12,008:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 00:03:23,719:INFO: ***** Running test *****
2022-06-21 00:03:23,719:INFO:   Num examples = 27763
2022-06-21 00:03:23,719:INFO:   Batch size = 16
2022-06-21 00:03:23,719:INFO:   Num steps = 1736
2022-06-21 00:03:23,719:INFO: ***** Running val *****
2022-06-21 00:03:23,719:INFO:   Num examples = 4290
2022-06-21 00:03:24,596:INFO: ***** Running training *****
2022-06-21 00:03:24,596:INFO:   Num examples = 48774
2022-06-21 00:03:24,596:INFO:   Batch size = 128
2022-06-21 00:03:24,596:INFO:   Num steps = 1905
2022-06-21 00:08:00,900:INFO: Effective parameters:
2022-06-21 00:08:00,901:INFO:   <<< batch_size: 128
2022-06-21 00:08:00,901:INFO:   <<< batch_size_val: 16
2022-06-21 00:08:00,901:INFO:   <<< cache_dir: 
2022-06-21 00:08:00,901:INFO:   <<< coef_lr: 0.001
2022-06-21 00:08:00,901:INFO:   <<< cross_model: cross-base
2022-06-21 00:08:00,901:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:08:00,901:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:08:00,901:INFO:   <<< datatype: msvd
2022-06-21 00:08:00,901:INFO:   <<< do_eval: False
2022-06-21 00:08:00,901:INFO:   <<< do_lower_case: False
2022-06-21 00:08:00,901:INFO:   <<< do_pretrain: False
2022-06-21 00:08:00,901:INFO:   <<< do_train: True
2022-06-21 00:08:00,901:INFO:   <<< epochs: 5
2022-06-21 00:08:00,901:INFO:   <<< eval_frame_order: 0
2022-06-21 00:08:00,901:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:08:00,901:INFO:   <<< feature_framerate: 1
2022-06-21 00:08:00,901:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:08:00,901:INFO:   <<< fp16: False
2022-06-21 00:08:00,901:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:08:00,901:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:08:00,901:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:08:00,901:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:08:00,901:INFO:   <<< init_model: None
2022-06-21 00:08:00,901:INFO:   <<< linear_patch: 3d
2022-06-21 00:08:00,901:INFO:   <<< local_rank: 0
2022-06-21 00:08:00,901:INFO:   <<< loose_type: True
2022-06-21 00:08:00,901:INFO:   <<< lr: 0.0001
2022-06-21 00:08:00,901:INFO:   <<< lr_decay: 0.9
2022-06-21 00:08:00,901:INFO:   <<< margin: 0.1
2022-06-21 00:08:00,901:INFO:   <<< max_frames: 12
2022-06-21 00:08:00,901:INFO:   <<< max_words: 32
2022-06-21 00:08:00,901:INFO:   <<< n_display: 50
2022-06-21 00:08:00,901:INFO:   <<< n_gpu: 1
2022-06-21 00:08:00,901:INFO:   <<< n_pair: 1
2022-06-21 00:08:00,901:INFO:   <<< negative_weighting: 1
2022-06-21 00:08:00,902:INFO:   <<< num_thread_reader: 2
2022-06-21 00:08:00,902:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:08:00,902:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:08:00,902:INFO:   <<< rank: 0
2022-06-21 00:08:00,902:INFO:   <<< resume_model: None
2022-06-21 00:08:00,902:INFO:   <<< sampled_use_mil: False
2022-06-21 00:08:00,902:INFO:   <<< seed: 42
2022-06-21 00:08:00,902:INFO:   <<< sim_header: meanP
2022-06-21 00:08:00,902:INFO:   <<< slice_framepos: 2
2022-06-21 00:08:00,902:INFO:   <<< task_type: retrieval
2022-06-21 00:08:00,902:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:08:00,902:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:08:00,902:INFO:   <<< train_frame_order: 0
2022-06-21 00:08:00,902:INFO:   <<< use_mil: False
2022-06-21 00:08:00,902:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:08:00,902:INFO:   <<< video_dim: 1024
2022-06-21 00:08:00,902:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:08:00,902:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:08:00,902:INFO:   <<< world_size: 1
2022-06-21 00:08:00,902:INFO: device: cuda:0 n_gpu: 1
2022-06-21 00:08:02,041:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:08:02,042:WARNING: Test retrieval by loose type.
2022-06-21 00:08:02,042:WARNING: 	 embed_dim: 512
2022-06-21 00:08:02,042:WARNING: 	 image_resolution: 224
2022-06-21 00:08:02,042:WARNING: 	 vision_layers: 12
2022-06-21 00:08:02,042:WARNING: 	 vision_width: 768
2022-06-21 00:08:02,042:WARNING: 	 vision_patch_size: 32
2022-06-21 00:08:02,042:WARNING: 	 context_length: 77
2022-06-21 00:08:02,042:WARNING: 	 vocab_size: 49408
2022-06-21 00:08:02,042:WARNING: 	 transformer_width: 512
2022-06-21 00:08:02,043:WARNING: 	 transformer_heads: 8
2022-06-21 00:08:02,043:WARNING: 	 transformer_layers: 12
2022-06-21 00:08:02,043:WARNING: 		 linear_patch: 3d
2022-06-21 00:08:02,043:WARNING: 	 cut_top_layer: 0
2022-06-21 00:08:09,367:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 00:08:20,921:INFO: ***** Running test *****
2022-06-21 00:08:20,921:INFO:   Num examples = 27763
2022-06-21 00:08:20,922:INFO:   Batch size = 16
2022-06-21 00:08:20,922:INFO:   Num steps = 1736
2022-06-21 00:08:20,922:INFO: ***** Running val *****
2022-06-21 00:08:20,922:INFO:   Num examples = 4290
2022-06-21 00:08:22,989:INFO: ***** Running training *****
2022-06-21 00:08:22,989:INFO:   Num examples = 48774
2022-06-21 00:08:22,989:INFO:   Batch size = 128
2022-06-21 00:08:22,989:INFO:   Num steps = 1905
2022-06-21 00:11:30,954:INFO: Effective parameters:
2022-06-21 00:11:30,955:INFO:   <<< batch_size: 128
2022-06-21 00:11:30,955:INFO:   <<< batch_size_val: 16
2022-06-21 00:11:30,955:INFO:   <<< cache_dir: 
2022-06-21 00:11:30,955:INFO:   <<< coef_lr: 0.001
2022-06-21 00:11:30,955:INFO:   <<< cross_model: cross-base
2022-06-21 00:11:30,955:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:11:30,956:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:11:30,956:INFO:   <<< datatype: msvd
2022-06-21 00:11:30,956:INFO:   <<< do_eval: False
2022-06-21 00:11:30,956:INFO:   <<< do_lower_case: False
2022-06-21 00:11:30,956:INFO:   <<< do_pretrain: False
2022-06-21 00:11:30,956:INFO:   <<< do_train: True
2022-06-21 00:11:30,956:INFO:   <<< epochs: 5
2022-06-21 00:11:30,956:INFO:   <<< eval_frame_order: 0
2022-06-21 00:11:30,956:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:11:30,957:INFO:   <<< feature_framerate: 1
2022-06-21 00:11:30,957:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:11:30,957:INFO:   <<< fp16: False
2022-06-21 00:11:30,957:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:11:30,957:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:11:30,957:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:11:30,957:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:11:30,957:INFO:   <<< init_model: None
2022-06-21 00:11:30,957:INFO:   <<< linear_patch: 3d
2022-06-21 00:11:30,957:INFO:   <<< local_rank: 0
2022-06-21 00:11:30,958:INFO:   <<< loose_type: True
2022-06-21 00:11:30,958:INFO:   <<< lr: 0.0001
2022-06-21 00:11:30,958:INFO:   <<< lr_decay: 0.9
2022-06-21 00:11:30,958:INFO:   <<< margin: 0.1
2022-06-21 00:11:30,958:INFO:   <<< max_frames: 12
2022-06-21 00:11:30,958:INFO:   <<< max_words: 32
2022-06-21 00:11:30,958:INFO:   <<< n_display: 50
2022-06-21 00:11:30,958:INFO:   <<< n_gpu: 1
2022-06-21 00:11:30,958:INFO:   <<< n_pair: 1
2022-06-21 00:11:30,959:INFO:   <<< negative_weighting: 1
2022-06-21 00:11:30,959:INFO:   <<< num_thread_reader: 2
2022-06-21 00:11:30,959:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:11:30,959:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:11:30,959:INFO:   <<< rank: 0
2022-06-21 00:11:30,959:INFO:   <<< resume_model: None
2022-06-21 00:11:30,959:INFO:   <<< sampled_use_mil: False
2022-06-21 00:11:30,959:INFO:   <<< seed: 42
2022-06-21 00:11:30,959:INFO:   <<< sim_header: meanP
2022-06-21 00:11:30,959:INFO:   <<< slice_framepos: 2
2022-06-21 00:11:30,959:INFO:   <<< task_type: retrieval
2022-06-21 00:11:30,959:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:11:30,959:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:11:30,959:INFO:   <<< train_frame_order: 0
2022-06-21 00:11:30,959:INFO:   <<< use_mil: False
2022-06-21 00:11:30,959:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:11:30,959:INFO:   <<< video_dim: 1024
2022-06-21 00:11:30,959:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:11:30,959:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:11:30,959:INFO:   <<< world_size: 2
2022-06-21 00:11:30,959:INFO: device: cuda:0 n_gpu: 1
2022-06-21 00:11:31,830:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:11:31,830:WARNING: Test retrieval by loose type.
2022-06-21 00:11:31,831:WARNING: 	 embed_dim: 512
2022-06-21 00:11:31,831:WARNING: 	 image_resolution: 224
2022-06-21 00:11:31,831:WARNING: 	 vision_layers: 12
2022-06-21 00:11:31,831:WARNING: 	 vision_width: 768
2022-06-21 00:11:31,831:WARNING: 	 vision_patch_size: 32
2022-06-21 00:11:31,831:WARNING: 	 context_length: 77
2022-06-21 00:11:31,831:WARNING: 	 vocab_size: 49408
2022-06-21 00:11:31,831:WARNING: 	 transformer_width: 512
2022-06-21 00:11:31,831:WARNING: 	 transformer_heads: 8
2022-06-21 00:11:31,831:WARNING: 	 transformer_layers: 12
2022-06-21 00:11:31,831:WARNING: 		 linear_patch: 3d
2022-06-21 00:11:31,831:WARNING: 	 cut_top_layer: 0
2022-06-21 00:14:00,654:INFO: device: cuda:1 n_gpu: 2
2022-06-21 00:14:00,659:INFO: Effective parameters:
2022-06-21 00:14:00,659:INFO:   <<< batch_size: 128
2022-06-21 00:14:00,659:INFO:   <<< batch_size_val: 16
2022-06-21 00:14:00,659:INFO:   <<< cache_dir: 
2022-06-21 00:14:00,659:INFO:   <<< coef_lr: 0.001
2022-06-21 00:14:00,659:INFO:   <<< cross_model: cross-base
2022-06-21 00:14:00,659:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:14:00,659:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:14:00,659:INFO:   <<< datatype: msvd
2022-06-21 00:14:00,659:INFO:   <<< do_eval: False
2022-06-21 00:14:00,659:INFO:   <<< do_lower_case: False
2022-06-21 00:14:00,660:INFO:   <<< do_pretrain: False
2022-06-21 00:14:00,660:INFO:   <<< do_train: True
2022-06-21 00:14:00,660:INFO:   <<< epochs: 5
2022-06-21 00:14:00,660:INFO:   <<< eval_frame_order: 0
2022-06-21 00:14:00,660:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:14:00,660:INFO:   <<< feature_framerate: 1
2022-06-21 00:14:00,660:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:14:00,660:INFO:   <<< fp16: False
2022-06-21 00:14:00,660:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:14:00,660:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:14:00,660:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:14:00,660:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:14:00,660:INFO:   <<< init_model: None
2022-06-21 00:14:00,660:INFO:   <<< linear_patch: 3d
2022-06-21 00:14:00,660:INFO:   <<< local_rank: 0
2022-06-21 00:14:00,660:INFO:   <<< loose_type: True
2022-06-21 00:14:00,661:INFO:   <<< lr: 0.0001
2022-06-21 00:14:00,661:INFO:   <<< lr_decay: 0.9
2022-06-21 00:14:00,661:INFO:   <<< margin: 0.1
2022-06-21 00:14:00,661:INFO:   <<< max_frames: 12
2022-06-21 00:14:00,661:INFO:   <<< max_words: 32
2022-06-21 00:14:00,661:INFO:   <<< n_display: 50
2022-06-21 00:14:00,661:INFO:   <<< n_gpu: 1
2022-06-21 00:14:00,661:INFO:   <<< n_pair: 1
2022-06-21 00:14:00,661:INFO:   <<< negative_weighting: 1
2022-06-21 00:14:00,661:INFO:   <<< num_thread_reader: 2
2022-06-21 00:14:00,661:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:14:00,661:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:14:00,661:INFO:   <<< rank: 0
2022-06-21 00:14:00,661:INFO:   <<< resume_model: None
2022-06-21 00:14:00,661:INFO:   <<< sampled_use_mil: False
2022-06-21 00:14:00,662:INFO:   <<< seed: 42
2022-06-21 00:14:00,662:INFO:   <<< sim_header: meanP
2022-06-21 00:14:00,662:INFO:   <<< slice_framepos: 2
2022-06-21 00:14:00,662:INFO:   <<< task_type: retrieval
2022-06-21 00:14:00,662:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:14:00,662:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:14:00,662:INFO:   <<< train_frame_order: 0
2022-06-21 00:14:00,662:INFO:   <<< use_mil: False
2022-06-21 00:14:00,662:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:14:00,662:INFO:   <<< video_dim: 1024
2022-06-21 00:14:00,662:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:14:00,662:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:14:00,662:INFO:   <<< world_size: 2
2022-06-21 00:14:00,662:INFO: device: cuda:0 n_gpu: 2
2022-06-21 00:14:01,515:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:14:01,516:WARNING: Test retrieval by loose type.
2022-06-21 00:14:01,516:WARNING: 	 embed_dim: 512
2022-06-21 00:14:01,516:WARNING: 	 image_resolution: 224
2022-06-21 00:14:01,516:WARNING: 	 vision_layers: 12
2022-06-21 00:14:01,516:WARNING: 	 vision_width: 768
2022-06-21 00:14:01,516:WARNING: 	 vision_patch_size: 32
2022-06-21 00:14:01,516:WARNING: 	 context_length: 77
2022-06-21 00:14:01,516:WARNING: 	 vocab_size: 49408
2022-06-21 00:14:01,516:WARNING: 	 transformer_width: 512
2022-06-21 00:14:01,516:WARNING: 	 transformer_heads: 8
2022-06-21 00:14:01,516:WARNING: 	 transformer_layers: 12
2022-06-21 00:14:01,516:WARNING: 		 linear_patch: 3d
2022-06-21 00:14:01,516:WARNING: 	 cut_top_layer: 0
2022-06-21 00:14:08,931:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 00:14:21,104:INFO: ***** Running test *****
2022-06-21 00:14:21,104:INFO:   Num examples = 27763
2022-06-21 00:14:21,104:INFO:   Batch size = 16
2022-06-21 00:14:21,104:INFO:   Num steps = 1736
2022-06-21 00:14:21,104:INFO: ***** Running val *****
2022-06-21 00:14:21,104:INFO:   Num examples = 4290
2022-06-21 00:20:09,674:INFO: device: cuda:1 n_gpu: 2
2022-06-21 00:20:09,683:INFO: Effective parameters:
2022-06-21 00:20:09,683:INFO:   <<< batch_size: 128
2022-06-21 00:20:09,683:INFO:   <<< batch_size_val: 16
2022-06-21 00:20:09,683:INFO:   <<< cache_dir: 
2022-06-21 00:20:09,683:INFO:   <<< coef_lr: 0.001
2022-06-21 00:20:09,683:INFO:   <<< cross_model: cross-base
2022-06-21 00:20:09,683:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:20:09,683:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:20:09,683:INFO:   <<< datatype: msvd
2022-06-21 00:20:09,683:INFO:   <<< do_eval: False
2022-06-21 00:20:09,683:INFO:   <<< do_lower_case: False
2022-06-21 00:20:09,683:INFO:   <<< do_pretrain: False
2022-06-21 00:20:09,684:INFO:   <<< do_train: True
2022-06-21 00:20:09,684:INFO:   <<< epochs: 5
2022-06-21 00:20:09,684:INFO:   <<< eval_frame_order: 0
2022-06-21 00:20:09,684:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:20:09,684:INFO:   <<< feature_framerate: 1
2022-06-21 00:20:09,684:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:20:09,684:INFO:   <<< fp16: False
2022-06-21 00:20:09,684:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:20:09,684:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:20:09,684:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:20:09,684:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:20:09,684:INFO:   <<< init_model: None
2022-06-21 00:20:09,684:INFO:   <<< linear_patch: 3d
2022-06-21 00:20:09,684:INFO:   <<< local_rank: 0
2022-06-21 00:20:09,684:INFO:   <<< loose_type: True
2022-06-21 00:20:09,684:INFO:   <<< lr: 0.0001
2022-06-21 00:20:09,684:INFO:   <<< lr_decay: 0.9
2022-06-21 00:20:09,684:INFO:   <<< margin: 0.1
2022-06-21 00:20:09,684:INFO:   <<< max_frames: 12
2022-06-21 00:20:09,684:INFO:   <<< max_words: 32
2022-06-21 00:20:09,685:INFO:   <<< n_display: 50
2022-06-21 00:20:09,685:INFO:   <<< n_gpu: 1
2022-06-21 00:20:09,685:INFO:   <<< n_pair: 1
2022-06-21 00:20:09,685:INFO:   <<< negative_weighting: 1
2022-06-21 00:20:09,685:INFO:   <<< num_thread_reader: 2
2022-06-21 00:20:09,685:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:20:09,685:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:20:09,685:INFO:   <<< rank: 0
2022-06-21 00:20:09,685:INFO:   <<< resume_model: None
2022-06-21 00:20:09,685:INFO:   <<< sampled_use_mil: False
2022-06-21 00:20:09,685:INFO:   <<< seed: 42
2022-06-21 00:20:09,685:INFO:   <<< sim_header: meanP
2022-06-21 00:20:09,685:INFO:   <<< slice_framepos: 2
2022-06-21 00:20:09,685:INFO:   <<< task_type: retrieval
2022-06-21 00:20:09,685:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:20:09,685:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:20:09,685:INFO:   <<< train_frame_order: 0
2022-06-21 00:20:09,685:INFO:   <<< use_mil: False
2022-06-21 00:20:09,685:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:20:09,685:INFO:   <<< video_dim: 1024
2022-06-21 00:20:09,686:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:20:09,686:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:20:09,686:INFO:   <<< world_size: 2
2022-06-21 00:20:09,686:INFO: device: cuda:0 n_gpu: 2
2022-06-21 00:20:10,557:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:20:10,558:WARNING: Test retrieval by loose type.
2022-06-21 00:20:10,558:WARNING: 	 embed_dim: 512
2022-06-21 00:20:10,558:WARNING: 	 image_resolution: 224
2022-06-21 00:20:10,558:WARNING: 	 vision_layers: 12
2022-06-21 00:20:10,558:WARNING: 	 vision_width: 768
2022-06-21 00:20:10,558:WARNING: 	 vision_patch_size: 32
2022-06-21 00:20:10,559:WARNING: 	 context_length: 77
2022-06-21 00:20:10,559:WARNING: 	 vocab_size: 49408
2022-06-21 00:20:10,559:WARNING: 	 transformer_width: 512
2022-06-21 00:20:10,559:WARNING: 	 transformer_heads: 8
2022-06-21 00:20:10,559:WARNING: 	 transformer_layers: 12
2022-06-21 00:20:10,559:WARNING: 		 linear_patch: 3d
2022-06-21 00:20:10,559:WARNING: 	 cut_top_layer: 0
2022-06-21 00:20:17,930:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 00:20:28,970:INFO: ***** Running test *****
2022-06-21 00:20:28,971:INFO:   Num examples = 27763
2022-06-21 00:20:28,971:INFO:   Batch size = 16
2022-06-21 00:20:28,971:INFO:   Num steps = 1736
2022-06-21 00:20:28,971:INFO: ***** Running val *****
2022-06-21 00:20:28,971:INFO:   Num examples = 4290
2022-06-21 00:21:52,051:INFO: device: cuda:1 n_gpu: 2
2022-06-21 00:21:52,051:INFO: Effective parameters:
2022-06-21 00:21:52,051:INFO:   <<< batch_size: 128
2022-06-21 00:21:52,052:INFO:   <<< batch_size_val: 16
2022-06-21 00:21:52,052:INFO:   <<< cache_dir: 
2022-06-21 00:21:52,052:INFO:   <<< coef_lr: 0.001
2022-06-21 00:21:52,052:INFO:   <<< cross_model: cross-base
2022-06-21 00:21:52,052:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:21:52,052:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:21:52,052:INFO:   <<< datatype: msvd
2022-06-21 00:21:52,052:INFO:   <<< do_eval: False
2022-06-21 00:21:52,052:INFO:   <<< do_lower_case: False
2022-06-21 00:21:52,052:INFO:   <<< do_pretrain: False
2022-06-21 00:21:52,052:INFO:   <<< do_train: True
2022-06-21 00:21:52,052:INFO:   <<< epochs: 5
2022-06-21 00:21:52,052:INFO:   <<< eval_frame_order: 0
2022-06-21 00:21:52,052:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:21:52,052:INFO:   <<< feature_framerate: 1
2022-06-21 00:21:52,052:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:21:52,052:INFO:   <<< fp16: False
2022-06-21 00:21:52,052:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:21:52,052:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:21:52,052:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:21:52,053:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:21:52,053:INFO:   <<< init_model: None
2022-06-21 00:21:52,053:INFO:   <<< linear_patch: 3d
2022-06-21 00:21:52,053:INFO:   <<< local_rank: 0
2022-06-21 00:21:52,053:INFO:   <<< loose_type: True
2022-06-21 00:21:52,053:INFO:   <<< lr: 0.0001
2022-06-21 00:21:52,053:INFO:   <<< lr_decay: 0.9
2022-06-21 00:21:52,053:INFO:   <<< margin: 0.1
2022-06-21 00:21:52,053:INFO:   <<< max_frames: 12
2022-06-21 00:21:52,053:INFO:   <<< max_words: 32
2022-06-21 00:21:52,053:INFO:   <<< n_display: 50
2022-06-21 00:21:52,053:INFO:   <<< n_gpu: 1
2022-06-21 00:21:52,053:INFO:   <<< n_pair: 1
2022-06-21 00:21:52,053:INFO:   <<< negative_weighting: 1
2022-06-21 00:21:52,053:INFO:   <<< num_thread_reader: 2
2022-06-21 00:21:52,053:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:21:52,053:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:21:52,053:INFO:   <<< rank: 0
2022-06-21 00:21:52,054:INFO:   <<< resume_model: None
2022-06-21 00:21:52,054:INFO:   <<< sampled_use_mil: False
2022-06-21 00:21:52,054:INFO:   <<< seed: 42
2022-06-21 00:21:52,054:INFO:   <<< sim_header: meanP
2022-06-21 00:21:52,054:INFO:   <<< slice_framepos: 2
2022-06-21 00:21:52,054:INFO:   <<< task_type: retrieval
2022-06-21 00:21:52,054:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:21:52,054:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:21:52,054:INFO:   <<< train_frame_order: 0
2022-06-21 00:21:52,054:INFO:   <<< use_mil: False
2022-06-21 00:21:52,054:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:21:52,054:INFO:   <<< video_dim: 1024
2022-06-21 00:21:52,054:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:21:52,054:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:21:52,054:INFO:   <<< world_size: 4
2022-06-21 00:21:52,054:INFO: device: cuda:0 n_gpu: 2
2022-06-21 00:21:52,981:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:21:52,981:WARNING: Test retrieval by loose type.
2022-06-21 00:21:52,981:WARNING: 	 embed_dim: 512
2022-06-21 00:21:52,981:WARNING: 	 image_resolution: 224
2022-06-21 00:21:52,981:WARNING: 	 vision_layers: 12
2022-06-21 00:21:52,981:WARNING: 	 vision_width: 768
2022-06-21 00:21:52,981:WARNING: 	 vision_patch_size: 32
2022-06-21 00:21:52,981:WARNING: 	 context_length: 77
2022-06-21 00:21:52,981:WARNING: 	 vocab_size: 49408
2022-06-21 00:21:52,981:WARNING: 	 transformer_width: 512
2022-06-21 00:21:52,981:WARNING: 	 transformer_heads: 8
2022-06-21 00:21:52,982:WARNING: 	 transformer_layers: 12
2022-06-21 00:21:52,982:WARNING: 		 linear_patch: 3d
2022-06-21 00:21:52,982:WARNING: 	 cut_top_layer: 0
2022-06-21 00:23:17,920:INFO: device: cuda:1 n_gpu: 2
2022-06-21 00:23:17,928:INFO: Effective parameters:
2022-06-21 00:23:17,928:INFO:   <<< batch_size: 128
2022-06-21 00:23:17,928:INFO:   <<< batch_size_val: 16
2022-06-21 00:23:17,928:INFO:   <<< cache_dir: 
2022-06-21 00:23:17,928:INFO:   <<< coef_lr: 0.001
2022-06-21 00:23:17,928:INFO:   <<< cross_model: cross-base
2022-06-21 00:23:17,928:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:23:17,928:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:23:17,928:INFO:   <<< datatype: msvd
2022-06-21 00:23:17,928:INFO:   <<< do_eval: False
2022-06-21 00:23:17,928:INFO:   <<< do_lower_case: False
2022-06-21 00:23:17,928:INFO:   <<< do_pretrain: False
2022-06-21 00:23:17,929:INFO:   <<< do_train: True
2022-06-21 00:23:17,929:INFO:   <<< epochs: 5
2022-06-21 00:23:17,929:INFO:   <<< eval_frame_order: 0
2022-06-21 00:23:17,929:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:23:17,929:INFO:   <<< feature_framerate: 1
2022-06-21 00:23:17,929:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:23:17,929:INFO:   <<< fp16: False
2022-06-21 00:23:17,929:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:23:17,929:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:23:17,929:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:23:17,929:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:23:17,929:INFO:   <<< init_model: None
2022-06-21 00:23:17,929:INFO:   <<< linear_patch: 3d
2022-06-21 00:23:17,929:INFO:   <<< local_rank: 0
2022-06-21 00:23:17,929:INFO:   <<< loose_type: True
2022-06-21 00:23:17,929:INFO:   <<< lr: 0.0001
2022-06-21 00:23:17,929:INFO:   <<< lr_decay: 0.9
2022-06-21 00:23:17,930:INFO:   <<< margin: 0.1
2022-06-21 00:23:17,930:INFO:   <<< max_frames: 12
2022-06-21 00:23:17,930:INFO:   <<< max_words: 32
2022-06-21 00:23:17,930:INFO:   <<< n_display: 50
2022-06-21 00:23:17,930:INFO:   <<< n_gpu: 1
2022-06-21 00:23:17,930:INFO:   <<< n_pair: 1
2022-06-21 00:23:17,930:INFO:   <<< negative_weighting: 1
2022-06-21 00:23:17,930:INFO:   <<< num_thread_reader: 2
2022-06-21 00:23:17,930:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:23:17,930:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:23:17,930:INFO:   <<< rank: 0
2022-06-21 00:23:17,930:INFO:   <<< resume_model: None
2022-06-21 00:23:17,930:INFO:   <<< sampled_use_mil: False
2022-06-21 00:23:17,930:INFO:   <<< seed: 42
2022-06-21 00:23:17,930:INFO:   <<< sim_header: meanP
2022-06-21 00:23:17,930:INFO:   <<< slice_framepos: 2
2022-06-21 00:23:17,930:INFO:   <<< task_type: retrieval
2022-06-21 00:23:17,930:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:23:17,931:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:23:17,931:INFO:   <<< train_frame_order: 0
2022-06-21 00:23:17,931:INFO:   <<< use_mil: False
2022-06-21 00:23:17,931:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:23:17,931:INFO:   <<< video_dim: 1024
2022-06-21 00:23:17,931:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:23:17,931:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:23:17,931:INFO:   <<< world_size: 2
2022-06-21 00:23:17,931:INFO: device: cuda:0 n_gpu: 2
2022-06-21 00:23:18,776:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:23:18,776:WARNING: Test retrieval by loose type.
2022-06-21 00:23:18,776:WARNING: 	 embed_dim: 512
2022-06-21 00:23:18,776:WARNING: 	 image_resolution: 224
2022-06-21 00:23:18,777:WARNING: 	 vision_layers: 12
2022-06-21 00:23:18,777:WARNING: 	 vision_width: 768
2022-06-21 00:23:18,777:WARNING: 	 vision_patch_size: 32
2022-06-21 00:23:18,777:WARNING: 	 context_length: 77
2022-06-21 00:23:18,777:WARNING: 	 vocab_size: 49408
2022-06-21 00:23:18,777:WARNING: 	 transformer_width: 512
2022-06-21 00:23:18,777:WARNING: 	 transformer_heads: 8
2022-06-21 00:23:18,777:WARNING: 	 transformer_layers: 12
2022-06-21 00:23:18,777:WARNING: 		 linear_patch: 3d
2022-06-21 00:23:18,777:WARNING: 	 cut_top_layer: 0
2022-06-21 00:23:26,135:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 00:23:38,498:INFO: ***** Running test *****
2022-06-21 00:23:38,498:INFO:   Num examples = 27763
2022-06-21 00:23:38,498:INFO:   Batch size = 16
2022-06-21 00:23:38,498:INFO:   Num steps = 1736
2022-06-21 00:23:38,498:INFO: ***** Running val *****
2022-06-21 00:23:38,498:INFO:   Num examples = 4290
2022-06-21 00:25:35,687:INFO: Effective parameters:
2022-06-21 00:25:35,687:INFO:   <<< batch_size: 128
2022-06-21 00:25:35,688:INFO:   <<< batch_size_val: 16
2022-06-21 00:25:35,688:INFO:   <<< cache_dir: 
2022-06-21 00:25:35,688:INFO:   <<< coef_lr: 0.001
2022-06-21 00:25:35,688:INFO:   <<< cross_model: cross-base
2022-06-21 00:25:35,688:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:25:35,688:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:25:35,688:INFO:   <<< datatype: msvd
2022-06-21 00:25:35,688:INFO:   <<< do_eval: False
2022-06-21 00:25:35,688:INFO:   <<< do_lower_case: False
2022-06-21 00:25:35,688:INFO:   <<< do_pretrain: False
2022-06-21 00:25:35,688:INFO:   <<< do_train: True
2022-06-21 00:25:35,688:INFO:   <<< epochs: 5
2022-06-21 00:25:35,688:INFO:   <<< eval_frame_order: 0
2022-06-21 00:25:35,688:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:25:35,688:INFO:   <<< feature_framerate: 1
2022-06-21 00:25:35,688:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:25:35,688:INFO:   <<< fp16: False
2022-06-21 00:25:35,689:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:25:35,689:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:25:35,689:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:25:35,689:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:25:35,689:INFO:   <<< init_model: None
2022-06-21 00:25:35,689:INFO:   <<< linear_patch: 3d
2022-06-21 00:25:35,689:INFO:   <<< local_rank: 0
2022-06-21 00:25:35,689:INFO:   <<< loose_type: True
2022-06-21 00:25:35,689:INFO:   <<< lr: 0.0001
2022-06-21 00:25:35,689:INFO:   <<< lr_decay: 0.9
2022-06-21 00:25:35,689:INFO:   <<< margin: 0.1
2022-06-21 00:25:35,689:INFO:   <<< max_frames: 12
2022-06-21 00:25:35,689:INFO:   <<< max_words: 32
2022-06-21 00:25:35,689:INFO:   <<< n_display: 50
2022-06-21 00:25:35,689:INFO:   <<< n_gpu: 1
2022-06-21 00:25:35,689:INFO:   <<< n_pair: 1
2022-06-21 00:25:35,689:INFO:   <<< negative_weighting: 1
2022-06-21 00:25:35,690:INFO:   <<< num_thread_reader: 2
2022-06-21 00:25:35,690:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:25:35,690:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:25:35,690:INFO:   <<< rank: 0
2022-06-21 00:25:35,690:INFO:   <<< resume_model: None
2022-06-21 00:25:35,690:INFO:   <<< sampled_use_mil: False
2022-06-21 00:25:35,690:INFO:   <<< seed: 42
2022-06-21 00:25:35,690:INFO:   <<< sim_header: meanP
2022-06-21 00:25:35,690:INFO:   <<< slice_framepos: 2
2022-06-21 00:25:35,690:INFO:   <<< task_type: retrieval
2022-06-21 00:25:35,690:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:25:35,690:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:25:35,690:INFO:   <<< train_frame_order: 0
2022-06-21 00:25:35,690:INFO:   <<< use_mil: False
2022-06-21 00:25:35,690:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:25:35,690:INFO:   <<< video_dim: 1024
2022-06-21 00:25:35,690:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:25:35,690:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:25:35,690:INFO:   <<< world_size: 1
2022-06-21 00:25:35,691:INFO: device: cuda:0 n_gpu: 2
2022-06-21 00:25:36,452:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:25:36,452:WARNING: Test retrieval by loose type.
2022-06-21 00:25:36,453:WARNING: 	 embed_dim: 512
2022-06-21 00:25:36,453:WARNING: 	 image_resolution: 224
2022-06-21 00:25:36,453:WARNING: 	 vision_layers: 12
2022-06-21 00:25:36,453:WARNING: 	 vision_width: 768
2022-06-21 00:25:36,453:WARNING: 	 vision_patch_size: 32
2022-06-21 00:25:36,453:WARNING: 	 context_length: 77
2022-06-21 00:25:36,453:WARNING: 	 vocab_size: 49408
2022-06-21 00:25:36,453:WARNING: 	 transformer_width: 512
2022-06-21 00:25:36,453:WARNING: 	 transformer_heads: 8
2022-06-21 00:25:36,453:WARNING: 	 transformer_layers: 12
2022-06-21 00:25:36,453:WARNING: 		 linear_patch: 3d
2022-06-21 00:25:36,453:WARNING: 	 cut_top_layer: 0
2022-06-21 00:25:43,600:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 00:25:55,666:INFO: ***** Running test *****
2022-06-21 00:25:55,666:INFO:   Num examples = 27763
2022-06-21 00:25:55,666:INFO:   Batch size = 16
2022-06-21 00:25:55,666:INFO:   Num steps = 1736
2022-06-21 00:25:55,666:INFO: ***** Running val *****
2022-06-21 00:25:55,666:INFO:   Num examples = 4290
2022-06-21 00:25:56,671:INFO: ***** Running training *****
2022-06-21 00:25:56,672:INFO:   Num examples = 48774
2022-06-21 00:25:56,672:INFO:   Batch size = 128
2022-06-21 00:25:56,672:INFO:   Num steps = 3810
2022-06-21 00:32:34,967:INFO: Effective parameters:
2022-06-21 00:32:34,967:INFO:   <<< batch_size: 128
2022-06-21 00:32:34,967:INFO:   <<< batch_size_val: 16
2022-06-21 00:32:34,967:INFO:   <<< cache_dir: 
2022-06-21 00:32:34,967:INFO:   <<< coef_lr: 0.001
2022-06-21 00:32:34,967:INFO:   <<< cross_model: cross-base
2022-06-21 00:32:34,967:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:32:34,967:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:32:34,967:INFO:   <<< datatype: msvd
2022-06-21 00:32:34,967:INFO:   <<< do_eval: False
2022-06-21 00:32:34,967:INFO:   <<< do_lower_case: False
2022-06-21 00:32:34,967:INFO:   <<< do_pretrain: False
2022-06-21 00:32:34,967:INFO:   <<< do_train: True
2022-06-21 00:32:34,967:INFO:   <<< epochs: 5
2022-06-21 00:32:34,968:INFO:   <<< eval_frame_order: 0
2022-06-21 00:32:34,968:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:32:34,968:INFO:   <<< feature_framerate: 1
2022-06-21 00:32:34,968:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:32:34,968:INFO:   <<< fp16: False
2022-06-21 00:32:34,968:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:32:34,968:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:32:34,968:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:32:34,968:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:32:34,968:INFO:   <<< init_model: None
2022-06-21 00:32:34,968:INFO:   <<< linear_patch: 3d
2022-06-21 00:32:34,968:INFO:   <<< local_rank: 0
2022-06-21 00:32:34,968:INFO:   <<< loose_type: True
2022-06-21 00:32:34,968:INFO:   <<< lr: 0.0001
2022-06-21 00:32:34,968:INFO:   <<< lr_decay: 0.9
2022-06-21 00:32:34,968:INFO:   <<< margin: 0.1
2022-06-21 00:32:34,968:INFO:   <<< max_frames: 16
2022-06-21 00:32:34,968:INFO:   <<< max_words: 32
2022-06-21 00:32:34,968:INFO:   <<< n_display: 50
2022-06-21 00:32:34,968:INFO:   <<< n_gpu: 1
2022-06-21 00:32:34,968:INFO:   <<< n_pair: 1
2022-06-21 00:32:34,968:INFO:   <<< negative_weighting: 1
2022-06-21 00:32:34,968:INFO:   <<< num_thread_reader: 2
2022-06-21 00:32:34,968:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:32:34,968:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:32:34,968:INFO:   <<< rank: 0
2022-06-21 00:32:34,968:INFO:   <<< resume_model: None
2022-06-21 00:32:34,968:INFO:   <<< sampled_use_mil: False
2022-06-21 00:32:34,968:INFO:   <<< seed: 42
2022-06-21 00:32:34,968:INFO:   <<< sim_header: meanP
2022-06-21 00:32:34,968:INFO:   <<< slice_framepos: 2
2022-06-21 00:32:34,968:INFO:   <<< task_type: retrieval
2022-06-21 00:32:34,968:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:32:34,968:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:32:34,968:INFO:   <<< train_frame_order: 0
2022-06-21 00:32:34,968:INFO:   <<< use_mil: False
2022-06-21 00:32:34,969:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:32:34,969:INFO:   <<< video_dim: 1024
2022-06-21 00:32:34,969:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:32:34,969:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:32:34,969:INFO:   <<< world_size: 1
2022-06-21 00:32:34,969:INFO: device: cuda:0 n_gpu: 2
2022-06-21 00:32:35,673:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:32:35,673:WARNING: Test retrieval by loose type.
2022-06-21 00:32:35,673:WARNING: 	 embed_dim: 512
2022-06-21 00:32:35,674:WARNING: 	 image_resolution: 224
2022-06-21 00:32:35,674:WARNING: 	 vision_layers: 12
2022-06-21 00:32:35,674:WARNING: 	 vision_width: 768
2022-06-21 00:32:35,674:WARNING: 	 vision_patch_size: 32
2022-06-21 00:32:35,674:WARNING: 	 context_length: 77
2022-06-21 00:32:35,674:WARNING: 	 vocab_size: 49408
2022-06-21 00:32:35,674:WARNING: 	 transformer_width: 512
2022-06-21 00:32:35,674:WARNING: 	 transformer_heads: 8
2022-06-21 00:32:35,674:WARNING: 	 transformer_layers: 12
2022-06-21 00:32:35,674:WARNING: 		 linear_patch: 3d
2022-06-21 00:32:35,674:WARNING: 	 cut_top_layer: 0
2022-06-21 00:32:43,142:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 00:32:53,876:INFO: ***** Running test *****
2022-06-21 00:32:53,876:INFO:   Num examples = 27763
2022-06-21 00:32:53,876:INFO:   Batch size = 16
2022-06-21 00:32:53,876:INFO:   Num steps = 1736
2022-06-21 00:32:53,876:INFO: ***** Running val *****
2022-06-21 00:32:53,876:INFO:   Num examples = 4290
2022-06-21 00:32:54,951:INFO: ***** Running training *****
2022-06-21 00:32:54,951:INFO:   Num examples = 48774
2022-06-21 00:32:54,952:INFO:   Batch size = 128
2022-06-21 00:32:54,952:INFO:   Num steps = 3810
2022-06-21 00:47:39,985:INFO: Effective parameters:
2022-06-21 00:47:39,985:INFO:   <<< batch_size: 128
2022-06-21 00:47:39,986:INFO:   <<< batch_size_val: 16
2022-06-21 00:47:39,986:INFO:   <<< cache_dir: 
2022-06-21 00:47:39,986:INFO:   <<< coef_lr: 0.001
2022-06-21 00:47:39,986:INFO:   <<< cross_model: cross-base
2022-06-21 00:47:39,986:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:47:39,986:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:47:39,986:INFO:   <<< datatype: msvd
2022-06-21 00:47:39,986:INFO:   <<< do_eval: False
2022-06-21 00:47:39,986:INFO:   <<< do_lower_case: False
2022-06-21 00:47:39,986:INFO:   <<< do_pretrain: False
2022-06-21 00:47:39,986:INFO:   <<< do_train: True
2022-06-21 00:47:39,986:INFO:   <<< epochs: 5
2022-06-21 00:47:39,986:INFO:   <<< eval_frame_order: 0
2022-06-21 00:47:39,986:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:47:39,986:INFO:   <<< feature_framerate: 1
2022-06-21 00:47:39,986:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:47:39,987:INFO:   <<< fp16: False
2022-06-21 00:47:39,987:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:47:39,987:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:47:39,987:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:47:39,987:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:47:39,987:INFO:   <<< init_model: None
2022-06-21 00:47:39,987:INFO:   <<< linear_patch: 3d
2022-06-21 00:47:39,987:INFO:   <<< local_rank: 0
2022-06-21 00:47:39,987:INFO:   <<< loose_type: True
2022-06-21 00:47:39,987:INFO:   <<< lr: 0.0001
2022-06-21 00:47:39,987:INFO:   <<< lr_decay: 0.9
2022-06-21 00:47:39,987:INFO:   <<< margin: 0.1
2022-06-21 00:47:39,987:INFO:   <<< max_frames: 16
2022-06-21 00:47:39,987:INFO:   <<< max_words: 32
2022-06-21 00:47:39,987:INFO:   <<< n_display: 50
2022-06-21 00:47:39,987:INFO:   <<< n_gpu: 1
2022-06-21 00:47:39,987:INFO:   <<< n_pair: 1
2022-06-21 00:47:39,987:INFO:   <<< negative_weighting: 1
2022-06-21 00:47:39,988:INFO:   <<< num_thread_reader: 2
2022-06-21 00:47:39,988:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:47:39,988:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:47:39,988:INFO:   <<< rank: 0
2022-06-21 00:47:39,988:INFO:   <<< resume_model: None
2022-06-21 00:47:39,988:INFO:   <<< sampled_use_mil: False
2022-06-21 00:47:39,988:INFO:   <<< seed: 42
2022-06-21 00:47:39,988:INFO:   <<< sim_header: meanP
2022-06-21 00:47:39,988:INFO:   <<< slice_framepos: 2
2022-06-21 00:47:39,988:INFO:   <<< task_type: retrieval
2022-06-21 00:47:39,988:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:47:39,988:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:47:39,988:INFO:   <<< train_frame_order: 0
2022-06-21 00:47:39,988:INFO:   <<< use_mil: False
2022-06-21 00:47:39,988:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:47:39,988:INFO:   <<< video_dim: 1024
2022-06-21 00:47:39,989:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:47:39,989:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:47:39,989:INFO:   <<< world_size: 1
2022-06-21 00:47:39,989:INFO: device: cuda:0 n_gpu: 2
2022-06-21 00:47:40,719:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:47:40,719:WARNING: Test retrieval by loose type.
2022-06-21 00:47:40,719:WARNING: 	 embed_dim: 512
2022-06-21 00:47:40,719:WARNING: 	 image_resolution: 224
2022-06-21 00:47:40,719:WARNING: 	 vision_layers: 12
2022-06-21 00:47:40,719:WARNING: 	 vision_width: 768
2022-06-21 00:47:40,719:WARNING: 	 vision_patch_size: 32
2022-06-21 00:47:40,719:WARNING: 	 context_length: 77
2022-06-21 00:47:40,720:WARNING: 	 vocab_size: 49408
2022-06-21 00:47:40,720:WARNING: 	 transformer_width: 512
2022-06-21 00:47:40,720:WARNING: 	 transformer_heads: 8
2022-06-21 00:47:40,720:WARNING: 	 transformer_layers: 12
2022-06-21 00:47:40,720:WARNING: 		 linear_patch: 3d
2022-06-21 00:47:40,720:WARNING: 	 cut_top_layer: 0
2022-06-21 00:47:48,431:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 00:47:58,714:INFO: ***** Running test *****
2022-06-21 00:47:58,714:INFO:   Num examples = 27763
2022-06-21 00:47:58,714:INFO:   Batch size = 16
2022-06-21 00:47:58,714:INFO:   Num steps = 1736
2022-06-21 00:47:58,714:INFO: ***** Running val *****
2022-06-21 00:47:58,714:INFO:   Num examples = 4290
2022-06-21 00:47:59,596:INFO: ***** Running training *****
2022-06-21 00:47:59,596:INFO:   Num examples = 48774
2022-06-21 00:47:59,596:INFO:   Batch size = 128
2022-06-21 00:47:59,596:INFO:   Num steps = 3810
2022-06-21 00:49:24,199:INFO: Effective parameters:
2022-06-21 00:49:24,199:INFO:   <<< batch_size: 128
2022-06-21 00:49:24,199:INFO:   <<< batch_size_val: 16
2022-06-21 00:49:24,199:INFO:   <<< cache_dir: 
2022-06-21 00:49:24,199:INFO:   <<< coef_lr: 0.001
2022-06-21 00:49:24,199:INFO:   <<< cross_model: cross-base
2022-06-21 00:49:24,199:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:49:24,200:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:49:24,200:INFO:   <<< datatype: msvd
2022-06-21 00:49:24,200:INFO:   <<< do_eval: False
2022-06-21 00:49:24,200:INFO:   <<< do_lower_case: False
2022-06-21 00:49:24,200:INFO:   <<< do_pretrain: False
2022-06-21 00:49:24,200:INFO:   <<< do_train: True
2022-06-21 00:49:24,200:INFO:   <<< epochs: 5
2022-06-21 00:49:24,200:INFO:   <<< eval_frame_order: 0
2022-06-21 00:49:24,200:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:49:24,200:INFO:   <<< feature_framerate: 1
2022-06-21 00:49:24,200:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:49:24,200:INFO:   <<< fp16: False
2022-06-21 00:49:24,200:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:49:24,200:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:49:24,200:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:49:24,200:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:49:24,200:INFO:   <<< init_model: None
2022-06-21 00:49:24,200:INFO:   <<< linear_patch: 3d
2022-06-21 00:49:24,201:INFO:   <<< local_rank: 0
2022-06-21 00:49:24,201:INFO:   <<< loose_type: True
2022-06-21 00:49:24,201:INFO:   <<< lr: 0.0001
2022-06-21 00:49:24,201:INFO:   <<< lr_decay: 0.9
2022-06-21 00:49:24,201:INFO:   <<< margin: 0.1
2022-06-21 00:49:24,201:INFO:   <<< max_frames: 16
2022-06-21 00:49:24,201:INFO:   <<< max_words: 32
2022-06-21 00:49:24,201:INFO:   <<< n_display: 50
2022-06-21 00:49:24,201:INFO:   <<< n_gpu: 1
2022-06-21 00:49:24,201:INFO:   <<< n_pair: 1
2022-06-21 00:49:24,201:INFO:   <<< negative_weighting: 1
2022-06-21 00:49:24,201:INFO:   <<< num_thread_reader: 2
2022-06-21 00:49:24,201:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:49:24,201:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:49:24,201:INFO:   <<< rank: 0
2022-06-21 00:49:24,201:INFO:   <<< resume_model: None
2022-06-21 00:49:24,201:INFO:   <<< sampled_use_mil: False
2022-06-21 00:49:24,201:INFO:   <<< seed: 42
2022-06-21 00:49:24,201:INFO:   <<< sim_header: meanP
2022-06-21 00:49:24,202:INFO:   <<< slice_framepos: 2
2022-06-21 00:49:24,202:INFO:   <<< task_type: retrieval
2022-06-21 00:49:24,202:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:49:24,202:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:49:24,202:INFO:   <<< train_frame_order: 0
2022-06-21 00:49:24,202:INFO:   <<< use_mil: False
2022-06-21 00:49:24,202:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:49:24,202:INFO:   <<< video_dim: 1024
2022-06-21 00:49:24,202:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:49:24,202:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:49:24,202:INFO:   <<< world_size: 1
2022-06-21 00:49:24,202:INFO: device: cuda:0 n_gpu: 2
2022-06-21 00:49:24,983:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:49:24,983:WARNING: Test retrieval by loose type.
2022-06-21 00:49:24,984:WARNING: 	 embed_dim: 512
2022-06-21 00:49:24,984:WARNING: 	 image_resolution: 224
2022-06-21 00:49:24,984:WARNING: 	 vision_layers: 12
2022-06-21 00:49:24,984:WARNING: 	 vision_width: 768
2022-06-21 00:49:24,985:WARNING: 	 vision_patch_size: 32
2022-06-21 00:49:24,985:WARNING: 	 context_length: 77
2022-06-21 00:49:24,985:WARNING: 	 vocab_size: 49408
2022-06-21 00:49:24,985:WARNING: 	 transformer_width: 512
2022-06-21 00:49:24,985:WARNING: 	 transformer_heads: 8
2022-06-21 00:49:24,985:WARNING: 	 transformer_layers: 12
2022-06-21 00:49:24,985:WARNING: 		 linear_patch: 3d
2022-06-21 00:49:24,985:WARNING: 	 cut_top_layer: 0
2022-06-21 00:49:32,757:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 00:49:45,730:INFO: ***** Running test *****
2022-06-21 00:49:45,730:INFO:   Num examples = 27763
2022-06-21 00:49:45,730:INFO:   Batch size = 16
2022-06-21 00:49:45,730:INFO:   Num steps = 1736
2022-06-21 00:49:45,730:INFO: ***** Running val *****
2022-06-21 00:49:45,731:INFO:   Num examples = 4290
2022-06-21 00:49:46,812:INFO: ***** Running training *****
2022-06-21 00:49:46,812:INFO:   Num examples = 48774
2022-06-21 00:49:46,812:INFO:   Batch size = 128
2022-06-21 00:49:46,812:INFO:   Num steps = 3810
2022-06-21 00:55:11,981:INFO: Effective parameters:
2022-06-21 00:55:11,981:INFO:   <<< batch_size: 128
2022-06-21 00:55:11,981:INFO:   <<< batch_size_val: 16
2022-06-21 00:55:11,981:INFO:   <<< cache_dir: 
2022-06-21 00:55:11,981:INFO:   <<< coef_lr: 0.001
2022-06-21 00:55:11,981:INFO:   <<< cross_model: cross-base
2022-06-21 00:55:11,981:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:55:11,981:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:55:11,982:INFO:   <<< datatype: msvd
2022-06-21 00:55:11,982:INFO:   <<< do_eval: False
2022-06-21 00:55:11,982:INFO:   <<< do_lower_case: False
2022-06-21 00:55:11,982:INFO:   <<< do_pretrain: False
2022-06-21 00:55:11,982:INFO:   <<< do_train: True
2022-06-21 00:55:11,982:INFO:   <<< epochs: 5
2022-06-21 00:55:11,982:INFO:   <<< eval_frame_order: 0
2022-06-21 00:55:11,982:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:55:11,982:INFO:   <<< feature_framerate: 1
2022-06-21 00:55:11,982:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:55:11,982:INFO:   <<< fp16: False
2022-06-21 00:55:11,982:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:55:11,982:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:55:11,982:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:55:11,982:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:55:11,983:INFO:   <<< init_model: None
2022-06-21 00:55:11,983:INFO:   <<< linear_patch: 3d
2022-06-21 00:55:11,983:INFO:   <<< local_rank: 0
2022-06-21 00:55:11,983:INFO:   <<< loose_type: True
2022-06-21 00:55:11,983:INFO:   <<< lr: 0.0001
2022-06-21 00:55:11,983:INFO:   <<< lr_decay: 0.9
2022-06-21 00:55:11,983:INFO:   <<< margin: 0.1
2022-06-21 00:55:11,983:INFO:   <<< max_frames: 16
2022-06-21 00:55:11,983:INFO:   <<< max_words: 32
2022-06-21 00:55:11,983:INFO:   <<< n_display: 50
2022-06-21 00:55:11,983:INFO:   <<< n_gpu: 1
2022-06-21 00:55:11,983:INFO:   <<< n_pair: 1
2022-06-21 00:55:11,983:INFO:   <<< negative_weighting: 1
2022-06-21 00:55:11,983:INFO:   <<< num_thread_reader: 2
2022-06-21 00:55:11,983:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:55:11,983:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:55:11,983:INFO:   <<< rank: 0
2022-06-21 00:55:11,983:INFO:   <<< resume_model: None
2022-06-21 00:55:11,983:INFO:   <<< sampled_use_mil: False
2022-06-21 00:55:11,984:INFO:   <<< seed: 42
2022-06-21 00:55:11,984:INFO:   <<< sim_header: meanP
2022-06-21 00:55:11,984:INFO:   <<< slice_framepos: 2
2022-06-21 00:55:11,984:INFO:   <<< task_type: retrieval
2022-06-21 00:55:11,984:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:55:11,984:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:55:11,984:INFO:   <<< train_frame_order: 0
2022-06-21 00:55:11,984:INFO:   <<< use_mil: False
2022-06-21 00:55:11,984:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:55:11,984:INFO:   <<< video_dim: 1024
2022-06-21 00:55:11,984:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:55:11,984:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:55:11,984:INFO:   <<< world_size: 1
2022-06-21 00:55:11,984:INFO: device: cuda:0 n_gpu: 2
2022-06-21 00:55:12,766:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:55:12,766:WARNING: Test retrieval by loose type.
2022-06-21 00:55:12,767:WARNING: 	 embed_dim: 512
2022-06-21 00:55:12,767:WARNING: 	 image_resolution: 224
2022-06-21 00:55:12,767:WARNING: 	 vision_layers: 12
2022-06-21 00:55:12,767:WARNING: 	 vision_width: 768
2022-06-21 00:55:12,767:WARNING: 	 vision_patch_size: 32
2022-06-21 00:55:12,767:WARNING: 	 context_length: 77
2022-06-21 00:55:12,767:WARNING: 	 vocab_size: 49408
2022-06-21 00:55:12,767:WARNING: 	 transformer_width: 512
2022-06-21 00:55:12,767:WARNING: 	 transformer_heads: 8
2022-06-21 00:55:12,767:WARNING: 	 transformer_layers: 12
2022-06-21 00:55:12,767:WARNING: 		 linear_patch: 3d
2022-06-21 00:55:12,767:WARNING: 	 cut_top_layer: 0
2022-06-21 00:55:20,084:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 00:55:30,342:INFO: ***** Running test *****
2022-06-21 00:55:30,343:INFO:   Num examples = 27763
2022-06-21 00:55:30,343:INFO:   Batch size = 16
2022-06-21 00:55:30,343:INFO:   Num steps = 1736
2022-06-21 00:55:30,343:INFO: ***** Running val *****
2022-06-21 00:55:30,343:INFO:   Num examples = 4290
2022-06-21 00:55:32,335:INFO: ***** Running training *****
2022-06-21 00:55:32,335:INFO:   Num examples = 48774
2022-06-21 00:55:32,335:INFO:   Batch size = 128
2022-06-21 00:55:32,335:INFO:   Num steps = 3810
2022-06-21 00:58:36,998:INFO: Effective parameters:
2022-06-21 00:58:36,998:INFO:   <<< batch_size: 128
2022-06-21 00:58:36,998:INFO:   <<< batch_size_val: 16
2022-06-21 00:58:36,998:INFO:   <<< cache_dir: 
2022-06-21 00:58:36,998:INFO:   <<< coef_lr: 0.001
2022-06-21 00:58:36,999:INFO:   <<< cross_model: cross-base
2022-06-21 00:58:36,999:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 00:58:36,999:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 00:58:36,999:INFO:   <<< datatype: msvd
2022-06-21 00:58:36,999:INFO:   <<< do_eval: False
2022-06-21 00:58:36,999:INFO:   <<< do_lower_case: False
2022-06-21 00:58:36,999:INFO:   <<< do_pretrain: False
2022-06-21 00:58:36,999:INFO:   <<< do_train: True
2022-06-21 00:58:36,999:INFO:   <<< epochs: 5
2022-06-21 00:58:36,999:INFO:   <<< eval_frame_order: 0
2022-06-21 00:58:36,999:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 00:58:36,999:INFO:   <<< feature_framerate: 1
2022-06-21 00:58:36,999:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 00:58:36,999:INFO:   <<< fp16: False
2022-06-21 00:58:36,999:INFO:   <<< fp16_opt_level: O1
2022-06-21 00:58:36,999:INFO:   <<< freeze_layer_num: 0
2022-06-21 00:58:36,999:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 00:58:36,999:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 00:58:36,999:INFO:   <<< init_model: None
2022-06-21 00:58:37,000:INFO:   <<< linear_patch: 3d
2022-06-21 00:58:37,000:INFO:   <<< local_rank: 0
2022-06-21 00:58:37,000:INFO:   <<< loose_type: True
2022-06-21 00:58:37,000:INFO:   <<< lr: 0.0001
2022-06-21 00:58:37,000:INFO:   <<< lr_decay: 0.9
2022-06-21 00:58:37,000:INFO:   <<< margin: 0.1
2022-06-21 00:58:37,000:INFO:   <<< max_frames: 16
2022-06-21 00:58:37,000:INFO:   <<< max_words: 32
2022-06-21 00:58:37,000:INFO:   <<< n_display: 50
2022-06-21 00:58:37,000:INFO:   <<< n_gpu: 1
2022-06-21 00:58:37,000:INFO:   <<< n_pair: 1
2022-06-21 00:58:37,000:INFO:   <<< negative_weighting: 1
2022-06-21 00:58:37,000:INFO:   <<< num_thread_reader: 2
2022-06-21 00:58:37,000:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 00:58:37,000:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 00:58:37,000:INFO:   <<< rank: 0
2022-06-21 00:58:37,000:INFO:   <<< resume_model: None
2022-06-21 00:58:37,000:INFO:   <<< sampled_use_mil: False
2022-06-21 00:58:37,000:INFO:   <<< seed: 42
2022-06-21 00:58:37,000:INFO:   <<< sim_header: meanP
2022-06-21 00:58:37,001:INFO:   <<< slice_framepos: 2
2022-06-21 00:58:37,001:INFO:   <<< task_type: retrieval
2022-06-21 00:58:37,001:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 00:58:37,001:INFO:   <<< train_csv: data/.train.csv
2022-06-21 00:58:37,001:INFO:   <<< train_frame_order: 0
2022-06-21 00:58:37,001:INFO:   <<< use_mil: False
2022-06-21 00:58:37,001:INFO:   <<< val_csv: data/.val.csv
2022-06-21 00:58:37,001:INFO:   <<< video_dim: 1024
2022-06-21 00:58:37,001:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 00:58:37,001:INFO:   <<< warmup_proportion: 0.1
2022-06-21 00:58:37,001:INFO:   <<< world_size: 1
2022-06-21 00:58:37,001:INFO: device: cuda:0 n_gpu: 2
2022-06-21 00:58:37,719:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 00:58:37,719:WARNING: Test retrieval by loose type.
2022-06-21 00:58:37,719:WARNING: 	 embed_dim: 512
2022-06-21 00:58:37,719:WARNING: 	 image_resolution: 224
2022-06-21 00:58:37,719:WARNING: 	 vision_layers: 12
2022-06-21 00:58:37,719:WARNING: 	 vision_width: 768
2022-06-21 00:58:37,719:WARNING: 	 vision_patch_size: 32
2022-06-21 00:58:37,719:WARNING: 	 context_length: 77
2022-06-21 00:58:37,719:WARNING: 	 vocab_size: 49408
2022-06-21 00:58:37,719:WARNING: 	 transformer_width: 512
2022-06-21 00:58:37,720:WARNING: 	 transformer_heads: 8
2022-06-21 00:58:37,720:WARNING: 	 transformer_layers: 12
2022-06-21 00:58:37,720:WARNING: 		 linear_patch: 3d
2022-06-21 00:58:37,720:WARNING: 	 cut_top_layer: 0
2022-06-21 00:58:44,820:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 00:58:56,439:INFO: ***** Running test *****
2022-06-21 00:58:56,440:INFO:   Num examples = 27763
2022-06-21 00:58:56,440:INFO:   Batch size = 16
2022-06-21 00:58:56,440:INFO:   Num steps = 1736
2022-06-21 00:58:56,440:INFO: ***** Running val *****
2022-06-21 00:58:56,440:INFO:   Num examples = 4290
2022-06-21 00:58:57,202:INFO: ***** Running training *****
2022-06-21 00:58:57,202:INFO:   Num examples = 48774
2022-06-21 00:58:57,202:INFO:   Batch size = 128
2022-06-21 00:58:57,202:INFO:   Num steps = 3810
2022-06-21 01:02:30,325:INFO: Effective parameters:
2022-06-21 01:02:30,325:INFO:   <<< batch_size: 128
2022-06-21 01:02:30,325:INFO:   <<< batch_size_val: 16
2022-06-21 01:02:30,325:INFO:   <<< cache_dir: 
2022-06-21 01:02:30,325:INFO:   <<< coef_lr: 0.001
2022-06-21 01:02:30,325:INFO:   <<< cross_model: cross-base
2022-06-21 01:02:30,325:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 01:02:30,325:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 01:02:30,325:INFO:   <<< datatype: msvd
2022-06-21 01:02:30,325:INFO:   <<< do_eval: False
2022-06-21 01:02:30,325:INFO:   <<< do_lower_case: False
2022-06-21 01:02:30,325:INFO:   <<< do_pretrain: False
2022-06-21 01:02:30,325:INFO:   <<< do_train: True
2022-06-21 01:02:30,325:INFO:   <<< epochs: 5
2022-06-21 01:02:30,325:INFO:   <<< eval_frame_order: 0
2022-06-21 01:02:30,325:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 01:02:30,325:INFO:   <<< feature_framerate: 1
2022-06-21 01:02:30,325:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 01:02:30,325:INFO:   <<< fp16: False
2022-06-21 01:02:30,325:INFO:   <<< fp16_opt_level: O1
2022-06-21 01:02:30,325:INFO:   <<< freeze_layer_num: 0
2022-06-21 01:02:30,325:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 01:02:30,325:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 01:02:30,325:INFO:   <<< init_model: None
2022-06-21 01:02:30,325:INFO:   <<< linear_patch: 3d
2022-06-21 01:02:30,325:INFO:   <<< local_rank: 0
2022-06-21 01:02:30,325:INFO:   <<< loose_type: True
2022-06-21 01:02:30,325:INFO:   <<< lr: 0.0001
2022-06-21 01:02:30,325:INFO:   <<< lr_decay: 0.9
2022-06-21 01:02:30,326:INFO:   <<< margin: 0.1
2022-06-21 01:02:30,326:INFO:   <<< max_frames: 16
2022-06-21 01:02:30,326:INFO:   <<< max_words: 32
2022-06-21 01:02:30,326:INFO:   <<< n_display: 50
2022-06-21 01:02:30,326:INFO:   <<< n_gpu: 1
2022-06-21 01:02:30,326:INFO:   <<< n_pair: 1
2022-06-21 01:02:30,326:INFO:   <<< negative_weighting: 1
2022-06-21 01:02:30,326:INFO:   <<< num_thread_reader: 2
2022-06-21 01:02:30,326:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 01:02:30,326:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 01:02:30,326:INFO:   <<< rank: 0
2022-06-21 01:02:30,326:INFO:   <<< resume_model: None
2022-06-21 01:02:30,326:INFO:   <<< sampled_use_mil: False
2022-06-21 01:02:30,326:INFO:   <<< seed: 42
2022-06-21 01:02:30,326:INFO:   <<< sim_header: meanP
2022-06-21 01:02:30,326:INFO:   <<< slice_framepos: 2
2022-06-21 01:02:30,326:INFO:   <<< task_type: retrieval
2022-06-21 01:02:30,326:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 01:02:30,326:INFO:   <<< train_csv: data/.train.csv
2022-06-21 01:02:30,326:INFO:   <<< train_frame_order: 0
2022-06-21 01:02:30,326:INFO:   <<< use_mil: False
2022-06-21 01:02:30,326:INFO:   <<< val_csv: data/.val.csv
2022-06-21 01:02:30,326:INFO:   <<< video_dim: 1024
2022-06-21 01:02:30,326:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 01:02:30,326:INFO:   <<< warmup_proportion: 0.1
2022-06-21 01:02:30,326:INFO:   <<< world_size: 1
2022-06-21 01:02:30,326:INFO: device: cuda:0 n_gpu: 2
2022-06-21 01:02:31,075:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 01:02:31,075:WARNING: Test retrieval by loose type.
2022-06-21 01:02:31,076:WARNING: 	 embed_dim: 512
2022-06-21 01:02:31,076:WARNING: 	 image_resolution: 224
2022-06-21 01:02:31,076:WARNING: 	 vision_layers: 12
2022-06-21 01:02:31,076:WARNING: 	 vision_width: 768
2022-06-21 01:02:31,076:WARNING: 	 vision_patch_size: 32
2022-06-21 01:02:31,076:WARNING: 	 context_length: 77
2022-06-21 01:02:31,076:WARNING: 	 vocab_size: 49408
2022-06-21 01:02:31,076:WARNING: 	 transformer_width: 512
2022-06-21 01:02:31,076:WARNING: 	 transformer_heads: 8
2022-06-21 01:02:31,076:WARNING: 	 transformer_layers: 12
2022-06-21 01:02:31,076:WARNING: 		 linear_patch: 3d
2022-06-21 01:02:31,076:WARNING: 	 cut_top_layer: 0
2022-06-21 01:02:38,158:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 01:02:50,838:INFO: ***** Running test *****
2022-06-21 01:02:50,839:INFO:   Num examples = 27763
2022-06-21 01:02:50,839:INFO:   Batch size = 16
2022-06-21 01:02:50,839:INFO:   Num steps = 1736
2022-06-21 01:02:50,839:INFO: ***** Running val *****
2022-06-21 01:02:50,839:INFO:   Num examples = 4290
2022-06-21 01:02:53,362:INFO: ***** Running training *****
2022-06-21 01:02:53,362:INFO:   Num examples = 48774
2022-06-21 01:02:53,362:INFO:   Batch size = 128
2022-06-21 01:02:53,362:INFO:   Num steps = 3810
2022-06-21 01:10:01,107:INFO: Effective parameters:
2022-06-21 01:10:01,107:INFO:   <<< batch_size: 128
2022-06-21 01:10:01,108:INFO:   <<< batch_size_val: 16
2022-06-21 01:10:01,108:INFO:   <<< cache_dir: 
2022-06-21 01:10:01,108:INFO:   <<< coef_lr: 0.001
2022-06-21 01:10:01,108:INFO:   <<< cross_model: cross-base
2022-06-21 01:10:01,108:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 01:10:01,108:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 01:10:01,108:INFO:   <<< datatype: msvd
2022-06-21 01:10:01,108:INFO:   <<< do_eval: False
2022-06-21 01:10:01,108:INFO:   <<< do_lower_case: False
2022-06-21 01:10:01,108:INFO:   <<< do_pretrain: False
2022-06-21 01:10:01,108:INFO:   <<< do_train: True
2022-06-21 01:10:01,108:INFO:   <<< epochs: 5
2022-06-21 01:10:01,108:INFO:   <<< eval_frame_order: 0
2022-06-21 01:10:01,108:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 01:10:01,108:INFO:   <<< feature_framerate: 1
2022-06-21 01:10:01,108:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 01:10:01,108:INFO:   <<< fp16: False
2022-06-21 01:10:01,108:INFO:   <<< fp16_opt_level: O1
2022-06-21 01:10:01,108:INFO:   <<< freeze_layer_num: 0
2022-06-21 01:10:01,108:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 01:10:01,108:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 01:10:01,109:INFO:   <<< init_model: None
2022-06-21 01:10:01,109:INFO:   <<< linear_patch: 3d
2022-06-21 01:10:01,109:INFO:   <<< local_rank: 0
2022-06-21 01:10:01,109:INFO:   <<< loose_type: True
2022-06-21 01:10:01,109:INFO:   <<< lr: 0.0001
2022-06-21 01:10:01,109:INFO:   <<< lr_decay: 0.9
2022-06-21 01:10:01,109:INFO:   <<< margin: 0.1
2022-06-21 01:10:01,109:INFO:   <<< max_frames: 16
2022-06-21 01:10:01,109:INFO:   <<< max_words: 32
2022-06-21 01:10:01,109:INFO:   <<< n_display: 50
2022-06-21 01:10:01,109:INFO:   <<< n_gpu: 1
2022-06-21 01:10:01,109:INFO:   <<< n_pair: 1
2022-06-21 01:10:01,109:INFO:   <<< negative_weighting: 1
2022-06-21 01:10:01,109:INFO:   <<< num_thread_reader: 2
2022-06-21 01:10:01,109:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 01:10:01,109:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 01:10:01,109:INFO:   <<< rank: 0
2022-06-21 01:10:01,109:INFO:   <<< resume_model: None
2022-06-21 01:10:01,109:INFO:   <<< sampled_use_mil: False
2022-06-21 01:10:01,109:INFO:   <<< seed: 42
2022-06-21 01:10:01,109:INFO:   <<< sim_header: meanP
2022-06-21 01:10:01,109:INFO:   <<< slice_framepos: 2
2022-06-21 01:10:01,110:INFO:   <<< task_type: retrieval
2022-06-21 01:10:01,110:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 01:10:01,110:INFO:   <<< train_csv: data/.train.csv
2022-06-21 01:10:01,110:INFO:   <<< train_frame_order: 0
2022-06-21 01:10:01,110:INFO:   <<< use_mil: False
2022-06-21 01:10:01,110:INFO:   <<< val_csv: data/.val.csv
2022-06-21 01:10:01,110:INFO:   <<< video_dim: 1024
2022-06-21 01:10:01,110:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 01:10:01,110:INFO:   <<< warmup_proportion: 0.1
2022-06-21 01:10:01,110:INFO:   <<< world_size: 1
2022-06-21 01:10:01,110:INFO: device: cuda:0 n_gpu: 2
2022-06-21 01:10:01,839:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 01:10:01,840:WARNING: Test retrieval by loose type.
2022-06-21 01:10:01,840:WARNING: 	 embed_dim: 512
2022-06-21 01:10:01,840:WARNING: 	 image_resolution: 224
2022-06-21 01:10:01,840:WARNING: 	 vision_layers: 12
2022-06-21 01:10:01,840:WARNING: 	 vision_width: 768
2022-06-21 01:10:01,840:WARNING: 	 vision_patch_size: 32
2022-06-21 01:10:01,840:WARNING: 	 context_length: 77
2022-06-21 01:10:01,840:WARNING: 	 vocab_size: 49408
2022-06-21 01:10:01,840:WARNING: 	 transformer_width: 512
2022-06-21 01:10:01,840:WARNING: 	 transformer_heads: 8
2022-06-21 01:10:01,841:WARNING: 	 transformer_layers: 12
2022-06-21 01:10:01,841:WARNING: 		 linear_patch: 3d
2022-06-21 01:10:01,841:WARNING: 	 cut_top_layer: 0
2022-06-21 01:10:09,241:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 01:10:21,853:INFO: ***** Running test *****
2022-06-21 01:10:21,853:INFO:   Num examples = 27763
2022-06-21 01:10:21,853:INFO:   Batch size = 16
2022-06-21 01:10:21,853:INFO:   Num steps = 1736
2022-06-21 01:10:21,853:INFO: ***** Running val *****
2022-06-21 01:10:21,853:INFO:   Num examples = 4290
2022-06-21 01:10:23,818:INFO: ***** Running training *****
2022-06-21 01:10:23,818:INFO:   Num examples = 48774
2022-06-21 01:10:23,818:INFO:   Batch size = 128
2022-06-21 01:10:23,818:INFO:   Num steps = 3810
2022-06-21 01:14:56,505:INFO: Effective parameters:
2022-06-21 01:14:56,506:INFO:   <<< batch_size: 128
2022-06-21 01:14:56,506:INFO:   <<< batch_size_val: 16
2022-06-21 01:14:56,506:INFO:   <<< cache_dir: 
2022-06-21 01:14:56,506:INFO:   <<< coef_lr: 0.001
2022-06-21 01:14:56,506:INFO:   <<< cross_model: cross-base
2022-06-21 01:14:56,506:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 01:14:56,506:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 01:14:56,506:INFO:   <<< datatype: msvd
2022-06-21 01:14:56,506:INFO:   <<< do_eval: False
2022-06-21 01:14:56,506:INFO:   <<< do_lower_case: False
2022-06-21 01:14:56,506:INFO:   <<< do_pretrain: False
2022-06-21 01:14:56,507:INFO:   <<< do_train: True
2022-06-21 01:14:56,507:INFO:   <<< epochs: 5
2022-06-21 01:14:56,507:INFO:   <<< eval_frame_order: 0
2022-06-21 01:14:56,507:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 01:14:56,507:INFO:   <<< feature_framerate: 1
2022-06-21 01:14:56,507:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 01:14:56,507:INFO:   <<< fp16: False
2022-06-21 01:14:56,507:INFO:   <<< fp16_opt_level: O1
2022-06-21 01:14:56,507:INFO:   <<< freeze_layer_num: 0
2022-06-21 01:14:56,507:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 01:14:56,507:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 01:14:56,507:INFO:   <<< init_model: None
2022-06-21 01:14:56,507:INFO:   <<< linear_patch: 3d
2022-06-21 01:14:56,507:INFO:   <<< local_rank: 0
2022-06-21 01:14:56,507:INFO:   <<< loose_type: True
2022-06-21 01:14:56,508:INFO:   <<< lr: 0.0001
2022-06-21 01:14:56,508:INFO:   <<< lr_decay: 0.9
2022-06-21 01:14:56,508:INFO:   <<< margin: 0.1
2022-06-21 01:14:56,508:INFO:   <<< max_frames: 16
2022-06-21 01:14:56,508:INFO:   <<< max_words: 32
2022-06-21 01:14:56,508:INFO:   <<< n_display: 50
2022-06-21 01:14:56,508:INFO:   <<< n_gpu: 1
2022-06-21 01:14:56,508:INFO:   <<< n_pair: 1
2022-06-21 01:14:56,508:INFO:   <<< negative_weighting: 1
2022-06-21 01:14:56,508:INFO:   <<< num_thread_reader: 2
2022-06-21 01:14:56,508:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 01:14:56,508:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 01:14:56,508:INFO:   <<< rank: 0
2022-06-21 01:14:56,508:INFO:   <<< resume_model: None
2022-06-21 01:14:56,508:INFO:   <<< sampled_use_mil: False
2022-06-21 01:14:56,509:INFO:   <<< seed: 42
2022-06-21 01:14:56,509:INFO:   <<< sim_header: meanP
2022-06-21 01:14:56,509:INFO:   <<< slice_framepos: 2
2022-06-21 01:14:56,509:INFO:   <<< task_type: retrieval
2022-06-21 01:14:56,509:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 01:14:56,509:INFO:   <<< train_csv: data/.train.csv
2022-06-21 01:14:56,509:INFO:   <<< train_frame_order: 0
2022-06-21 01:14:56,509:INFO:   <<< use_mil: False
2022-06-21 01:14:56,509:INFO:   <<< val_csv: data/.val.csv
2022-06-21 01:14:56,509:INFO:   <<< video_dim: 1024
2022-06-21 01:14:56,509:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 01:14:56,509:INFO:   <<< warmup_proportion: 0.1
2022-06-21 01:14:56,509:INFO:   <<< world_size: 1
2022-06-21 01:14:56,509:INFO: device: cuda:0 n_gpu: 2
2022-06-21 01:14:57,227:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 01:14:57,229:WARNING: Test retrieval by loose type.
2022-06-21 01:14:57,229:WARNING: 	 embed_dim: 512
2022-06-21 01:14:57,229:WARNING: 	 image_resolution: 224
2022-06-21 01:14:57,229:WARNING: 	 vision_layers: 12
2022-06-21 01:14:57,229:WARNING: 	 vision_width: 768
2022-06-21 01:14:57,229:WARNING: 	 vision_patch_size: 32
2022-06-21 01:14:57,229:WARNING: 	 context_length: 77
2022-06-21 01:14:57,229:WARNING: 	 vocab_size: 49408
2022-06-21 01:14:57,229:WARNING: 	 transformer_width: 512
2022-06-21 01:14:57,229:WARNING: 	 transformer_heads: 8
2022-06-21 01:14:57,229:WARNING: 	 transformer_layers: 12
2022-06-21 01:14:57,229:WARNING: 		 linear_patch: 3d
2022-06-21 01:14:57,229:WARNING: 	 cut_top_layer: 0
2022-06-21 01:15:04,522:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 01:15:15,651:INFO: ***** Running test *****
2022-06-21 01:15:15,651:INFO:   Num examples = 27763
2022-06-21 01:15:15,651:INFO:   Batch size = 16
2022-06-21 01:15:15,651:INFO:   Num steps = 1736
2022-06-21 01:15:15,651:INFO: ***** Running val *****
2022-06-21 01:15:15,651:INFO:   Num examples = 4290
2022-06-21 01:15:17,919:INFO: ***** Running training *****
2022-06-21 01:15:17,920:INFO:   Num examples = 48774
2022-06-21 01:15:17,920:INFO:   Batch size = 128
2022-06-21 01:15:17,920:INFO:   Num steps = 3810
2022-06-21 01:16:26,706:INFO: Effective parameters:
2022-06-21 01:16:26,707:INFO:   <<< batch_size: 128
2022-06-21 01:16:26,707:INFO:   <<< batch_size_val: 16
2022-06-21 01:16:26,707:INFO:   <<< cache_dir: 
2022-06-21 01:16:26,707:INFO:   <<< coef_lr: 0.001
2022-06-21 01:16:26,707:INFO:   <<< cross_model: cross-base
2022-06-21 01:16:26,707:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 01:16:26,707:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 01:16:26,707:INFO:   <<< datatype: msvd
2022-06-21 01:16:26,707:INFO:   <<< do_eval: False
2022-06-21 01:16:26,707:INFO:   <<< do_lower_case: False
2022-06-21 01:16:26,707:INFO:   <<< do_pretrain: False
2022-06-21 01:16:26,707:INFO:   <<< do_train: True
2022-06-21 01:16:26,707:INFO:   <<< epochs: 5
2022-06-21 01:16:26,707:INFO:   <<< eval_frame_order: 0
2022-06-21 01:16:26,707:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 01:16:26,707:INFO:   <<< feature_framerate: 1
2022-06-21 01:16:26,707:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 01:16:26,707:INFO:   <<< fp16: False
2022-06-21 01:16:26,707:INFO:   <<< fp16_opt_level: O1
2022-06-21 01:16:26,707:INFO:   <<< freeze_layer_num: 0
2022-06-21 01:16:26,707:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 01:16:26,707:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 01:16:26,707:INFO:   <<< init_model: None
2022-06-21 01:16:26,707:INFO:   <<< linear_patch: 3d
2022-06-21 01:16:26,707:INFO:   <<< local_rank: 0
2022-06-21 01:16:26,707:INFO:   <<< loose_type: True
2022-06-21 01:16:26,707:INFO:   <<< lr: 0.0001
2022-06-21 01:16:26,707:INFO:   <<< lr_decay: 0.9
2022-06-21 01:16:26,707:INFO:   <<< margin: 0.1
2022-06-21 01:16:26,707:INFO:   <<< max_frames: 16
2022-06-21 01:16:26,707:INFO:   <<< max_words: 32
2022-06-21 01:16:26,707:INFO:   <<< n_display: 50
2022-06-21 01:16:26,708:INFO:   <<< n_gpu: 1
2022-06-21 01:16:26,708:INFO:   <<< n_pair: 1
2022-06-21 01:16:26,708:INFO:   <<< negative_weighting: 1
2022-06-21 01:16:26,708:INFO:   <<< num_thread_reader: 2
2022-06-21 01:16:26,708:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 01:16:26,708:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 01:16:26,708:INFO:   <<< rank: 0
2022-06-21 01:16:26,708:INFO:   <<< resume_model: None
2022-06-21 01:16:26,708:INFO:   <<< sampled_use_mil: False
2022-06-21 01:16:26,708:INFO:   <<< seed: 42
2022-06-21 01:16:26,708:INFO:   <<< sim_header: meanP
2022-06-21 01:16:26,708:INFO:   <<< slice_framepos: 2
2022-06-21 01:16:26,708:INFO:   <<< task_type: retrieval
2022-06-21 01:16:26,708:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 01:16:26,708:INFO:   <<< train_csv: data/.train.csv
2022-06-21 01:16:26,708:INFO:   <<< train_frame_order: 0
2022-06-21 01:16:26,708:INFO:   <<< use_mil: False
2022-06-21 01:16:26,708:INFO:   <<< val_csv: data/.val.csv
2022-06-21 01:16:26,708:INFO:   <<< video_dim: 1024
2022-06-21 01:16:26,708:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 01:16:26,708:INFO:   <<< warmup_proportion: 0.1
2022-06-21 01:16:26,708:INFO:   <<< world_size: 1
2022-06-21 01:16:26,708:INFO: device: cuda:0 n_gpu: 2
2022-06-21 01:16:27,458:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 01:16:27,459:WARNING: Test retrieval by loose type.
2022-06-21 01:16:27,459:WARNING: 	 embed_dim: 512
2022-06-21 01:16:27,459:WARNING: 	 image_resolution: 224
2022-06-21 01:16:27,459:WARNING: 	 vision_layers: 12
2022-06-21 01:16:27,459:WARNING: 	 vision_width: 768
2022-06-21 01:16:27,459:WARNING: 	 vision_patch_size: 32
2022-06-21 01:16:27,459:WARNING: 	 context_length: 77
2022-06-21 01:16:27,459:WARNING: 	 vocab_size: 49408
2022-06-21 01:16:27,459:WARNING: 	 transformer_width: 512
2022-06-21 01:16:27,459:WARNING: 	 transformer_heads: 8
2022-06-21 01:16:27,459:WARNING: 	 transformer_layers: 12
2022-06-21 01:16:27,459:WARNING: 		 linear_patch: 3d
2022-06-21 01:16:27,459:WARNING: 	 cut_top_layer: 0
2022-06-21 01:16:34,523:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 01:16:46,984:INFO: ***** Running test *****
2022-06-21 01:16:46,985:INFO:   Num examples = 27763
2022-06-21 01:16:46,985:INFO:   Batch size = 16
2022-06-21 01:16:46,985:INFO:   Num steps = 1736
2022-06-21 01:16:46,985:INFO: ***** Running val *****
2022-06-21 01:16:46,985:INFO:   Num examples = 4290
2022-06-21 01:16:48,910:INFO: ***** Running training *****
2022-06-21 01:16:48,910:INFO:   Num examples = 48774
2022-06-21 01:16:48,911:INFO:   Batch size = 128
2022-06-21 01:16:48,911:INFO:   Num steps = 3810
2022-06-21 01:19:59,792:INFO: Effective parameters:
2022-06-21 01:19:59,793:INFO:   <<< batch_size: 128
2022-06-21 01:19:59,793:INFO:   <<< batch_size_val: 16
2022-06-21 01:19:59,793:INFO:   <<< cache_dir: 
2022-06-21 01:19:59,793:INFO:   <<< coef_lr: 0.001
2022-06-21 01:19:59,793:INFO:   <<< cross_model: cross-base
2022-06-21 01:19:59,793:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 01:19:59,793:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 01:19:59,793:INFO:   <<< datatype: msvd
2022-06-21 01:19:59,793:INFO:   <<< do_eval: False
2022-06-21 01:19:59,793:INFO:   <<< do_lower_case: False
2022-06-21 01:19:59,793:INFO:   <<< do_pretrain: False
2022-06-21 01:19:59,793:INFO:   <<< do_train: True
2022-06-21 01:19:59,793:INFO:   <<< epochs: 5
2022-06-21 01:19:59,794:INFO:   <<< eval_frame_order: 0
2022-06-21 01:19:59,794:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 01:19:59,794:INFO:   <<< feature_framerate: 1
2022-06-21 01:19:59,794:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 01:19:59,794:INFO:   <<< fp16: False
2022-06-21 01:19:59,794:INFO:   <<< fp16_opt_level: O1
2022-06-21 01:19:59,794:INFO:   <<< freeze_layer_num: 0
2022-06-21 01:19:59,794:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 01:19:59,794:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 01:19:59,794:INFO:   <<< init_model: None
2022-06-21 01:19:59,794:INFO:   <<< linear_patch: 3d
2022-06-21 01:19:59,794:INFO:   <<< local_rank: 0
2022-06-21 01:19:59,794:INFO:   <<< loose_type: True
2022-06-21 01:19:59,794:INFO:   <<< lr: 0.0001
2022-06-21 01:19:59,794:INFO:   <<< lr_decay: 0.9
2022-06-21 01:19:59,795:INFO:   <<< margin: 0.1
2022-06-21 01:19:59,795:INFO:   <<< max_frames: 16
2022-06-21 01:19:59,795:INFO:   <<< max_words: 32
2022-06-21 01:19:59,795:INFO:   <<< n_display: 50
2022-06-21 01:19:59,795:INFO:   <<< n_gpu: 1
2022-06-21 01:19:59,795:INFO:   <<< n_pair: 1
2022-06-21 01:19:59,795:INFO:   <<< negative_weighting: 1
2022-06-21 01:19:59,795:INFO:   <<< num_thread_reader: 2
2022-06-21 01:19:59,795:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 01:19:59,795:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 01:19:59,795:INFO:   <<< rank: 0
2022-06-21 01:19:59,795:INFO:   <<< resume_model: None
2022-06-21 01:19:59,795:INFO:   <<< sampled_use_mil: False
2022-06-21 01:19:59,795:INFO:   <<< seed: 42
2022-06-21 01:19:59,795:INFO:   <<< sim_header: meanP
2022-06-21 01:19:59,795:INFO:   <<< slice_framepos: 2
2022-06-21 01:19:59,795:INFO:   <<< task_type: retrieval
2022-06-21 01:19:59,796:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 01:19:59,796:INFO:   <<< train_csv: data/.train.csv
2022-06-21 01:19:59,796:INFO:   <<< train_frame_order: 0
2022-06-21 01:19:59,796:INFO:   <<< use_mil: False
2022-06-21 01:19:59,796:INFO:   <<< val_csv: data/.val.csv
2022-06-21 01:19:59,796:INFO:   <<< video_dim: 1024
2022-06-21 01:19:59,796:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 01:19:59,796:INFO:   <<< warmup_proportion: 0.1
2022-06-21 01:19:59,796:INFO:   <<< world_size: 1
2022-06-21 01:19:59,796:INFO: device: cuda:0 n_gpu: 2
2022-06-21 01:20:00,562:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 01:20:00,562:WARNING: Test retrieval by loose type.
2022-06-21 01:20:00,563:WARNING: 	 embed_dim: 512
2022-06-21 01:20:00,563:WARNING: 	 image_resolution: 224
2022-06-21 01:20:00,563:WARNING: 	 vision_layers: 12
2022-06-21 01:20:00,563:WARNING: 	 vision_width: 768
2022-06-21 01:20:00,563:WARNING: 	 vision_patch_size: 32
2022-06-21 01:20:00,563:WARNING: 	 context_length: 77
2022-06-21 01:20:00,563:WARNING: 	 vocab_size: 49408
2022-06-21 01:20:00,563:WARNING: 	 transformer_width: 512
2022-06-21 01:20:00,563:WARNING: 	 transformer_heads: 8
2022-06-21 01:20:00,563:WARNING: 	 transformer_layers: 12
2022-06-21 01:20:00,563:WARNING: 		 linear_patch: 3d
2022-06-21 01:20:00,563:WARNING: 	 cut_top_layer: 0
2022-06-21 01:20:07,651:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 01:20:19,900:INFO: ***** Running test *****
2022-06-21 01:20:19,900:INFO:   Num examples = 27763
2022-06-21 01:20:19,900:INFO:   Batch size = 16
2022-06-21 01:20:19,901:INFO:   Num steps = 1736
2022-06-21 01:20:19,901:INFO: ***** Running val *****
2022-06-21 01:20:19,901:INFO:   Num examples = 4290
2022-06-21 01:20:21,742:INFO: ***** Running training *****
2022-06-21 01:20:21,743:INFO:   Num examples = 48774
2022-06-21 01:20:21,743:INFO:   Batch size = 128
2022-06-21 01:20:21,743:INFO:   Num steps = 3810
2022-06-21 01:32:03,485:INFO: Effective parameters:
2022-06-21 01:32:03,485:INFO:   <<< batch_size: 128
2022-06-21 01:32:03,485:INFO:   <<< batch_size_val: 16
2022-06-21 01:32:03,485:INFO:   <<< cache_dir: 
2022-06-21 01:32:03,485:INFO:   <<< coef_lr: 0.001
2022-06-21 01:32:03,485:INFO:   <<< cross_model: cross-base
2022-06-21 01:32:03,485:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 01:32:03,485:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 01:32:03,485:INFO:   <<< datatype: msvd
2022-06-21 01:32:03,485:INFO:   <<< do_eval: False
2022-06-21 01:32:03,485:INFO:   <<< do_lower_case: False
2022-06-21 01:32:03,485:INFO:   <<< do_pretrain: False
2022-06-21 01:32:03,485:INFO:   <<< do_train: True
2022-06-21 01:32:03,485:INFO:   <<< epochs: 5
2022-06-21 01:32:03,485:INFO:   <<< eval_frame_order: 0
2022-06-21 01:32:03,485:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 01:32:03,486:INFO:   <<< feature_framerate: 1
2022-06-21 01:32:03,486:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 01:32:03,486:INFO:   <<< fp16: False
2022-06-21 01:32:03,486:INFO:   <<< fp16_opt_level: O1
2022-06-21 01:32:03,486:INFO:   <<< freeze_layer_num: 0
2022-06-21 01:32:03,486:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 01:32:03,486:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 01:32:03,486:INFO:   <<< init_model: None
2022-06-21 01:32:03,486:INFO:   <<< linear_patch: 3d
2022-06-21 01:32:03,486:INFO:   <<< local_rank: 0
2022-06-21 01:32:03,486:INFO:   <<< loose_type: True
2022-06-21 01:32:03,486:INFO:   <<< lr: 0.0001
2022-06-21 01:32:03,486:INFO:   <<< lr_decay: 0.9
2022-06-21 01:32:03,486:INFO:   <<< margin: 0.1
2022-06-21 01:32:03,486:INFO:   <<< max_frames: 16
2022-06-21 01:32:03,486:INFO:   <<< max_words: 32
2022-06-21 01:32:03,486:INFO:   <<< n_display: 50
2022-06-21 01:32:03,486:INFO:   <<< n_gpu: 1
2022-06-21 01:32:03,486:INFO:   <<< n_pair: 1
2022-06-21 01:32:03,486:INFO:   <<< negative_weighting: 1
2022-06-21 01:32:03,486:INFO:   <<< num_thread_reader: 2
2022-06-21 01:32:03,486:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 01:32:03,486:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 01:32:03,486:INFO:   <<< rank: 0
2022-06-21 01:32:03,486:INFO:   <<< resume_model: None
2022-06-21 01:32:03,486:INFO:   <<< sampled_use_mil: False
2022-06-21 01:32:03,486:INFO:   <<< seed: 42
2022-06-21 01:32:03,486:INFO:   <<< sim_header: meanP
2022-06-21 01:32:03,486:INFO:   <<< slice_framepos: 2
2022-06-21 01:32:03,486:INFO:   <<< task_type: retrieval
2022-06-21 01:32:03,486:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 01:32:03,487:INFO:   <<< train_csv: data/.train.csv
2022-06-21 01:32:03,487:INFO:   <<< train_frame_order: 0
2022-06-21 01:32:03,487:INFO:   <<< use_mil: False
2022-06-21 01:32:03,487:INFO:   <<< val_csv: data/.val.csv
2022-06-21 01:32:03,487:INFO:   <<< video_dim: 1024
2022-06-21 01:32:03,487:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 01:32:03,487:INFO:   <<< warmup_proportion: 0.1
2022-06-21 01:32:03,487:INFO:   <<< world_size: 1
2022-06-21 01:32:03,487:INFO: device: cuda:0 n_gpu: 2
2022-06-21 01:32:04,184:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 01:32:04,185:WARNING: Test retrieval by loose type.
2022-06-21 01:32:04,185:WARNING: 	 embed_dim: 512
2022-06-21 01:32:04,186:WARNING: 	 image_resolution: 224
2022-06-21 01:32:04,186:WARNING: 	 vision_layers: 12
2022-06-21 01:32:04,186:WARNING: 	 vision_width: 768
2022-06-21 01:32:04,186:WARNING: 	 vision_patch_size: 32
2022-06-21 01:32:04,186:WARNING: 	 context_length: 77
2022-06-21 01:32:04,186:WARNING: 	 vocab_size: 49408
2022-06-21 01:32:04,186:WARNING: 	 transformer_width: 512
2022-06-21 01:32:04,187:WARNING: 	 transformer_heads: 8
2022-06-21 01:32:04,187:WARNING: 	 transformer_layers: 12
2022-06-21 01:32:04,187:WARNING: 		 linear_patch: 3d
2022-06-21 01:32:04,187:WARNING: 	 cut_top_layer: 0
2022-06-21 01:32:11,572:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 01:32:21,487:INFO: ***** Running test *****
2022-06-21 01:32:21,487:INFO:   Num examples = 27763
2022-06-21 01:32:21,487:INFO:   Batch size = 16
2022-06-21 01:32:21,487:INFO:   Num steps = 1736
2022-06-21 01:32:21,487:INFO: ***** Running val *****
2022-06-21 01:32:21,487:INFO:   Num examples = 4290
2022-06-21 01:32:23,459:INFO: ***** Running training *****
2022-06-21 01:32:23,460:INFO:   Num examples = 48774
2022-06-21 01:32:23,460:INFO:   Batch size = 128
2022-06-21 01:32:23,460:INFO:   Num steps = 3810
2022-06-21 01:40:34,719:INFO: Effective parameters:
2022-06-21 01:40:34,719:INFO:   <<< batch_size: 128
2022-06-21 01:40:34,719:INFO:   <<< batch_size_val: 16
2022-06-21 01:40:34,719:INFO:   <<< cache_dir: 
2022-06-21 01:40:34,719:INFO:   <<< coef_lr: 0.001
2022-06-21 01:40:34,719:INFO:   <<< cross_model: cross-base
2022-06-21 01:40:34,719:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 01:40:34,719:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 01:40:34,719:INFO:   <<< datatype: msvd
2022-06-21 01:40:34,719:INFO:   <<< do_eval: False
2022-06-21 01:40:34,719:INFO:   <<< do_lower_case: False
2022-06-21 01:40:34,719:INFO:   <<< do_pretrain: False
2022-06-21 01:40:34,719:INFO:   <<< do_train: True
2022-06-21 01:40:34,719:INFO:   <<< epochs: 5
2022-06-21 01:40:34,719:INFO:   <<< eval_frame_order: 0
2022-06-21 01:40:34,719:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 01:40:34,719:INFO:   <<< feature_framerate: 1
2022-06-21 01:40:34,719:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 01:40:34,719:INFO:   <<< fp16: False
2022-06-21 01:40:34,719:INFO:   <<< fp16_opt_level: O1
2022-06-21 01:40:34,719:INFO:   <<< freeze_layer_num: 0
2022-06-21 01:40:34,720:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 01:40:34,720:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 01:40:34,720:INFO:   <<< init_model: None
2022-06-21 01:40:34,720:INFO:   <<< linear_patch: 3d
2022-06-21 01:40:34,720:INFO:   <<< local_rank: 0
2022-06-21 01:40:34,720:INFO:   <<< loose_type: True
2022-06-21 01:40:34,720:INFO:   <<< lr: 0.0001
2022-06-21 01:40:34,720:INFO:   <<< lr_decay: 0.9
2022-06-21 01:40:34,720:INFO:   <<< margin: 0.1
2022-06-21 01:40:34,720:INFO:   <<< max_frames: 16
2022-06-21 01:40:34,720:INFO:   <<< max_words: 32
2022-06-21 01:40:34,720:INFO:   <<< n_display: 50
2022-06-21 01:40:34,720:INFO:   <<< n_gpu: 1
2022-06-21 01:40:34,720:INFO:   <<< n_pair: 1
2022-06-21 01:40:34,720:INFO:   <<< negative_weighting: 1
2022-06-21 01:40:34,720:INFO:   <<< num_thread_reader: 2
2022-06-21 01:40:34,720:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 01:40:34,720:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 01:40:34,720:INFO:   <<< rank: 0
2022-06-21 01:40:34,720:INFO:   <<< resume_model: None
2022-06-21 01:40:34,720:INFO:   <<< sampled_use_mil: False
2022-06-21 01:40:34,720:INFO:   <<< seed: 42
2022-06-21 01:40:34,720:INFO:   <<< sim_header: meanP
2022-06-21 01:40:34,720:INFO:   <<< slice_framepos: 2
2022-06-21 01:40:34,720:INFO:   <<< task_type: retrieval
2022-06-21 01:40:34,721:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 01:40:34,721:INFO:   <<< train_csv: data/.train.csv
2022-06-21 01:40:34,721:INFO:   <<< train_frame_order: 0
2022-06-21 01:40:34,721:INFO:   <<< use_mil: False
2022-06-21 01:40:34,721:INFO:   <<< val_csv: data/.val.csv
2022-06-21 01:40:34,721:INFO:   <<< video_dim: 1024
2022-06-21 01:40:34,721:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 01:40:34,721:INFO:   <<< warmup_proportion: 0.1
2022-06-21 01:40:34,721:INFO:   <<< world_size: 1
2022-06-21 01:40:34,721:INFO: device: cuda:0 n_gpu: 2
2022-06-21 01:40:35,497:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 01:40:35,497:WARNING: Test retrieval by loose type.
2022-06-21 01:40:35,498:WARNING: 	 embed_dim: 512
2022-06-21 01:40:35,498:WARNING: 	 image_resolution: 224
2022-06-21 01:40:35,498:WARNING: 	 vision_layers: 12
2022-06-21 01:40:35,498:WARNING: 	 vision_width: 768
2022-06-21 01:40:35,498:WARNING: 	 vision_patch_size: 32
2022-06-21 01:40:35,498:WARNING: 	 context_length: 77
2022-06-21 01:40:35,498:WARNING: 	 vocab_size: 49408
2022-06-21 01:40:35,498:WARNING: 	 transformer_width: 512
2022-06-21 01:40:35,498:WARNING: 	 transformer_heads: 8
2022-06-21 01:40:35,498:WARNING: 	 transformer_layers: 12
2022-06-21 01:40:35,498:WARNING: 		 linear_patch: 3d
2022-06-21 01:40:35,498:WARNING: 	 cut_top_layer: 0
2022-06-21 01:40:42,795:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 01:40:52,845:INFO: ***** Running test *****
2022-06-21 01:40:52,846:INFO:   Num examples = 27763
2022-06-21 01:40:52,846:INFO:   Batch size = 16
2022-06-21 01:40:52,846:INFO:   Num steps = 1736
2022-06-21 01:40:52,846:INFO: ***** Running val *****
2022-06-21 01:40:52,846:INFO:   Num examples = 4290
2022-06-21 01:40:53,617:INFO: ***** Running training *****
2022-06-21 01:40:53,618:INFO:   Num examples = 48774
2022-06-21 01:40:53,618:INFO:   Batch size = 128
2022-06-21 01:40:53,618:INFO:   Num steps = 3810
2022-06-21 01:42:14,465:INFO: Effective parameters:
2022-06-21 01:42:14,466:INFO:   <<< batch_size: 128
2022-06-21 01:42:14,466:INFO:   <<< batch_size_val: 16
2022-06-21 01:42:14,466:INFO:   <<< cache_dir: 
2022-06-21 01:42:14,466:INFO:   <<< coef_lr: 0.001
2022-06-21 01:42:14,466:INFO:   <<< cross_model: cross-base
2022-06-21 01:42:14,466:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 01:42:14,466:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 01:42:14,466:INFO:   <<< datatype: msvd
2022-06-21 01:42:14,466:INFO:   <<< do_eval: False
2022-06-21 01:42:14,466:INFO:   <<< do_lower_case: False
2022-06-21 01:42:14,466:INFO:   <<< do_pretrain: False
2022-06-21 01:42:14,466:INFO:   <<< do_train: True
2022-06-21 01:42:14,466:INFO:   <<< epochs: 5
2022-06-21 01:42:14,467:INFO:   <<< eval_frame_order: 0
2022-06-21 01:42:14,467:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 01:42:14,467:INFO:   <<< feature_framerate: 1
2022-06-21 01:42:14,467:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 01:42:14,467:INFO:   <<< fp16: False
2022-06-21 01:42:14,467:INFO:   <<< fp16_opt_level: O1
2022-06-21 01:42:14,467:INFO:   <<< freeze_layer_num: 0
2022-06-21 01:42:14,467:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 01:42:14,467:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 01:42:14,467:INFO:   <<< init_model: None
2022-06-21 01:42:14,467:INFO:   <<< linear_patch: 3d
2022-06-21 01:42:14,467:INFO:   <<< local_rank: 0
2022-06-21 01:42:14,467:INFO:   <<< loose_type: True
2022-06-21 01:42:14,467:INFO:   <<< lr: 0.0001
2022-06-21 01:42:14,467:INFO:   <<< lr_decay: 0.9
2022-06-21 01:42:14,467:INFO:   <<< margin: 0.1
2022-06-21 01:42:14,468:INFO:   <<< max_frames: 16
2022-06-21 01:42:14,468:INFO:   <<< max_words: 32
2022-06-21 01:42:14,468:INFO:   <<< n_display: 50
2022-06-21 01:42:14,468:INFO:   <<< n_gpu: 1
2022-06-21 01:42:14,468:INFO:   <<< n_pair: 1
2022-06-21 01:42:14,468:INFO:   <<< negative_weighting: 1
2022-06-21 01:42:14,468:INFO:   <<< num_thread_reader: 2
2022-06-21 01:42:14,468:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 01:42:14,468:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 01:42:14,468:INFO:   <<< rank: 0
2022-06-21 01:42:14,468:INFO:   <<< resume_model: None
2022-06-21 01:42:14,468:INFO:   <<< sampled_use_mil: False
2022-06-21 01:42:14,468:INFO:   <<< seed: 42
2022-06-21 01:42:14,468:INFO:   <<< sim_header: meanP
2022-06-21 01:42:14,468:INFO:   <<< slice_framepos: 2
2022-06-21 01:42:14,468:INFO:   <<< task_type: retrieval
2022-06-21 01:42:14,469:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 01:42:14,469:INFO:   <<< train_csv: data/.train.csv
2022-06-21 01:42:14,469:INFO:   <<< train_frame_order: 0
2022-06-21 01:42:14,469:INFO:   <<< use_mil: False
2022-06-21 01:42:14,469:INFO:   <<< val_csv: data/.val.csv
2022-06-21 01:42:14,469:INFO:   <<< video_dim: 1024
2022-06-21 01:42:14,469:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 01:42:14,469:INFO:   <<< warmup_proportion: 0.1
2022-06-21 01:42:14,469:INFO:   <<< world_size: 1
2022-06-21 01:42:14,469:INFO: device: cuda:0 n_gpu: 2
2022-06-21 01:42:15,244:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 01:42:15,244:WARNING: Test retrieval by loose type.
2022-06-21 01:42:15,245:WARNING: 	 embed_dim: 512
2022-06-21 01:42:15,245:WARNING: 	 image_resolution: 224
2022-06-21 01:42:15,245:WARNING: 	 vision_layers: 12
2022-06-21 01:42:15,245:WARNING: 	 vision_width: 768
2022-06-21 01:42:15,245:WARNING: 	 vision_patch_size: 32
2022-06-21 01:42:15,245:WARNING: 	 context_length: 77
2022-06-21 01:42:15,245:WARNING: 	 vocab_size: 49408
2022-06-21 01:42:15,245:WARNING: 	 transformer_width: 512
2022-06-21 01:42:15,245:WARNING: 	 transformer_heads: 8
2022-06-21 01:42:15,245:WARNING: 	 transformer_layers: 12
2022-06-21 01:42:15,245:WARNING: 		 linear_patch: 3d
2022-06-21 01:42:15,245:WARNING: 	 cut_top_layer: 0
2022-06-21 01:42:22,587:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 01:42:33,042:INFO: ***** Running test *****
2022-06-21 01:42:33,043:INFO:   Num examples = 27763
2022-06-21 01:42:33,043:INFO:   Batch size = 16
2022-06-21 01:42:33,043:INFO:   Num steps = 1736
2022-06-21 01:42:33,043:INFO: ***** Running val *****
2022-06-21 01:42:33,043:INFO:   Num examples = 4290
2022-06-21 01:42:35,127:INFO: ***** Running training *****
2022-06-21 01:42:35,127:INFO:   Num examples = 48774
2022-06-21 01:42:35,127:INFO:   Batch size = 128
2022-06-21 01:42:35,127:INFO:   Num steps = 3810
2022-06-21 01:44:16,650:INFO: Effective parameters:
2022-06-21 01:44:16,650:INFO:   <<< batch_size: 128
2022-06-21 01:44:16,650:INFO:   <<< batch_size_val: 16
2022-06-21 01:44:16,650:INFO:   <<< cache_dir: 
2022-06-21 01:44:16,650:INFO:   <<< coef_lr: 0.001
2022-06-21 01:44:16,650:INFO:   <<< cross_model: cross-base
2022-06-21 01:44:16,650:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 01:44:16,650:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 01:44:16,650:INFO:   <<< datatype: msvd
2022-06-21 01:44:16,650:INFO:   <<< do_eval: False
2022-06-21 01:44:16,650:INFO:   <<< do_lower_case: False
2022-06-21 01:44:16,650:INFO:   <<< do_pretrain: False
2022-06-21 01:44:16,650:INFO:   <<< do_train: True
2022-06-21 01:44:16,650:INFO:   <<< epochs: 5
2022-06-21 01:44:16,650:INFO:   <<< eval_frame_order: 0
2022-06-21 01:44:16,651:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 01:44:16,651:INFO:   <<< feature_framerate: 1
2022-06-21 01:44:16,651:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 01:44:16,651:INFO:   <<< fp16: False
2022-06-21 01:44:16,651:INFO:   <<< fp16_opt_level: O1
2022-06-21 01:44:16,651:INFO:   <<< freeze_layer_num: 0
2022-06-21 01:44:16,651:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 01:44:16,651:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 01:44:16,651:INFO:   <<< init_model: None
2022-06-21 01:44:16,651:INFO:   <<< linear_patch: 3d
2022-06-21 01:44:16,651:INFO:   <<< local_rank: 0
2022-06-21 01:44:16,651:INFO:   <<< loose_type: True
2022-06-21 01:44:16,651:INFO:   <<< lr: 0.0001
2022-06-21 01:44:16,651:INFO:   <<< lr_decay: 0.9
2022-06-21 01:44:16,651:INFO:   <<< margin: 0.1
2022-06-21 01:44:16,651:INFO:   <<< max_frames: 16
2022-06-21 01:44:16,651:INFO:   <<< max_words: 32
2022-06-21 01:44:16,651:INFO:   <<< n_display: 50
2022-06-21 01:44:16,651:INFO:   <<< n_gpu: 1
2022-06-21 01:44:16,651:INFO:   <<< n_pair: 1
2022-06-21 01:44:16,651:INFO:   <<< negative_weighting: 1
2022-06-21 01:44:16,651:INFO:   <<< num_thread_reader: 2
2022-06-21 01:44:16,651:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 01:44:16,651:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 01:44:16,651:INFO:   <<< rank: 0
2022-06-21 01:44:16,651:INFO:   <<< resume_model: None
2022-06-21 01:44:16,651:INFO:   <<< sampled_use_mil: False
2022-06-21 01:44:16,651:INFO:   <<< seed: 42
2022-06-21 01:44:16,651:INFO:   <<< sim_header: meanP
2022-06-21 01:44:16,651:INFO:   <<< slice_framepos: 2
2022-06-21 01:44:16,651:INFO:   <<< task_type: retrieval
2022-06-21 01:44:16,652:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 01:44:16,652:INFO:   <<< train_csv: data/.train.csv
2022-06-21 01:44:16,652:INFO:   <<< train_frame_order: 0
2022-06-21 01:44:16,652:INFO:   <<< use_mil: False
2022-06-21 01:44:16,652:INFO:   <<< val_csv: data/.val.csv
2022-06-21 01:44:16,652:INFO:   <<< video_dim: 1024
2022-06-21 01:44:16,652:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 01:44:16,652:INFO:   <<< warmup_proportion: 0.1
2022-06-21 01:44:16,652:INFO:   <<< world_size: 1
2022-06-21 01:44:16,652:INFO: device: cuda:0 n_gpu: 2
2022-06-21 01:44:17,502:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 01:44:17,503:WARNING: Test retrieval by loose type.
2022-06-21 01:44:17,503:WARNING: 	 embed_dim: 512
2022-06-21 01:44:17,503:WARNING: 	 image_resolution: 224
2022-06-21 01:44:17,503:WARNING: 	 vision_layers: 12
2022-06-21 01:44:17,503:WARNING: 	 vision_width: 768
2022-06-21 01:44:17,503:WARNING: 	 vision_patch_size: 32
2022-06-21 01:44:17,503:WARNING: 	 context_length: 77
2022-06-21 01:44:17,503:WARNING: 	 vocab_size: 49408
2022-06-21 01:44:17,503:WARNING: 	 transformer_width: 512
2022-06-21 01:44:17,503:WARNING: 	 transformer_heads: 8
2022-06-21 01:44:17,504:WARNING: 	 transformer_layers: 12
2022-06-21 01:44:17,504:WARNING: 		 linear_patch: 3d
2022-06-21 01:44:17,504:WARNING: 	 cut_top_layer: 0
2022-06-21 01:44:24,745:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 01:44:37,418:INFO: ***** Running test *****
2022-06-21 01:44:37,418:INFO:   Num examples = 27763
2022-06-21 01:44:37,418:INFO:   Batch size = 16
2022-06-21 01:44:37,418:INFO:   Num steps = 1736
2022-06-21 01:44:37,418:INFO: ***** Running val *****
2022-06-21 01:44:37,418:INFO:   Num examples = 4290
2022-06-21 01:44:38,210:INFO: ***** Running training *****
2022-06-21 01:44:38,210:INFO:   Num examples = 48774
2022-06-21 01:44:38,210:INFO:   Batch size = 128
2022-06-21 01:44:38,210:INFO:   Num steps = 3810
2022-06-21 01:54:54,796:INFO: Effective parameters:
2022-06-21 01:54:54,796:INFO:   <<< batch_size: 128
2022-06-21 01:54:54,796:INFO:   <<< batch_size_val: 16
2022-06-21 01:54:54,796:INFO:   <<< cache_dir: 
2022-06-21 01:54:54,796:INFO:   <<< coef_lr: 0.001
2022-06-21 01:54:54,796:INFO:   <<< cross_model: cross-base
2022-06-21 01:54:54,796:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 01:54:54,796:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 01:54:54,796:INFO:   <<< datatype: msvd
2022-06-21 01:54:54,796:INFO:   <<< do_eval: False
2022-06-21 01:54:54,797:INFO:   <<< do_lower_case: False
2022-06-21 01:54:54,797:INFO:   <<< do_pretrain: False
2022-06-21 01:54:54,797:INFO:   <<< do_train: True
2022-06-21 01:54:54,797:INFO:   <<< epochs: 5
2022-06-21 01:54:54,797:INFO:   <<< eval_frame_order: 0
2022-06-21 01:54:54,797:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 01:54:54,797:INFO:   <<< feature_framerate: 1
2022-06-21 01:54:54,797:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 01:54:54,797:INFO:   <<< fp16: False
2022-06-21 01:54:54,797:INFO:   <<< fp16_opt_level: O1
2022-06-21 01:54:54,797:INFO:   <<< freeze_layer_num: 0
2022-06-21 01:54:54,797:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 01:54:54,797:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 01:54:54,797:INFO:   <<< init_model: None
2022-06-21 01:54:54,797:INFO:   <<< linear_patch: 3d
2022-06-21 01:54:54,797:INFO:   <<< local_rank: 0
2022-06-21 01:54:54,797:INFO:   <<< loose_type: True
2022-06-21 01:54:54,797:INFO:   <<< lr: 0.0001
2022-06-21 01:54:54,797:INFO:   <<< lr_decay: 0.9
2022-06-21 01:54:54,798:INFO:   <<< margin: 0.1
2022-06-21 01:54:54,798:INFO:   <<< max_frames: 16
2022-06-21 01:54:54,798:INFO:   <<< max_words: 32
2022-06-21 01:54:54,798:INFO:   <<< n_display: 50
2022-06-21 01:54:54,798:INFO:   <<< n_gpu: 1
2022-06-21 01:54:54,798:INFO:   <<< n_pair: 1
2022-06-21 01:54:54,798:INFO:   <<< negative_weighting: 1
2022-06-21 01:54:54,798:INFO:   <<< num_thread_reader: 2
2022-06-21 01:54:54,798:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 01:54:54,798:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 01:54:54,798:INFO:   <<< rank: 0
2022-06-21 01:54:54,798:INFO:   <<< resume_model: None
2022-06-21 01:54:54,798:INFO:   <<< sampled_use_mil: False
2022-06-21 01:54:54,798:INFO:   <<< seed: 42
2022-06-21 01:54:54,798:INFO:   <<< sim_header: meanP
2022-06-21 01:54:54,798:INFO:   <<< slice_framepos: 2
2022-06-21 01:54:54,798:INFO:   <<< task_type: retrieval
2022-06-21 01:54:54,798:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 01:54:54,799:INFO:   <<< train_csv: data/.train.csv
2022-06-21 01:54:54,799:INFO:   <<< train_frame_order: 0
2022-06-21 01:54:54,799:INFO:   <<< use_mil: False
2022-06-21 01:54:54,799:INFO:   <<< val_csv: data/.val.csv
2022-06-21 01:54:54,799:INFO:   <<< video_dim: 1024
2022-06-21 01:54:54,799:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 01:54:54,799:INFO:   <<< warmup_proportion: 0.1
2022-06-21 01:54:54,799:INFO:   <<< world_size: 1
2022-06-21 01:54:54,799:INFO: device: cuda:0 n_gpu: 2
2022-06-21 01:54:55,537:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 01:54:55,537:WARNING: Test retrieval by loose type.
2022-06-21 01:54:55,538:WARNING: 	 embed_dim: 512
2022-06-21 01:54:55,538:WARNING: 	 image_resolution: 224
2022-06-21 01:54:55,538:WARNING: 	 vision_layers: 12
2022-06-21 01:54:55,538:WARNING: 	 vision_width: 768
2022-06-21 01:54:55,538:WARNING: 	 vision_patch_size: 32
2022-06-21 01:54:55,538:WARNING: 	 context_length: 77
2022-06-21 01:54:55,538:WARNING: 	 vocab_size: 49408
2022-06-21 01:54:55,538:WARNING: 	 transformer_width: 512
2022-06-21 01:54:55,538:WARNING: 	 transformer_heads: 8
2022-06-21 01:54:55,538:WARNING: 	 transformer_layers: 12
2022-06-21 01:54:55,538:WARNING: 		 linear_patch: 3d
2022-06-21 01:54:55,538:WARNING: 	 cut_top_layer: 0
2022-06-21 01:55:03,097:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 01:55:14,458:INFO: ***** Running test *****
2022-06-21 01:55:14,458:INFO:   Num examples = 27763
2022-06-21 01:55:14,458:INFO:   Batch size = 16
2022-06-21 01:55:14,458:INFO:   Num steps = 1736
2022-06-21 01:55:14,458:INFO: ***** Running val *****
2022-06-21 01:55:14,458:INFO:   Num examples = 4290
2022-06-21 01:55:15,164:INFO: ***** Running training *****
2022-06-21 01:55:15,164:INFO:   Num examples = 48774
2022-06-21 01:55:15,164:INFO:   Batch size = 128
2022-06-21 01:55:15,164:INFO:   Num steps = 3810
2022-06-21 02:09:41,498:INFO: Effective parameters:
2022-06-21 02:09:41,499:INFO:   <<< batch_size: 128
2022-06-21 02:09:41,499:INFO:   <<< batch_size_val: 16
2022-06-21 02:09:41,499:INFO:   <<< cache_dir: 
2022-06-21 02:09:41,499:INFO:   <<< coef_lr: 0.001
2022-06-21 02:09:41,499:INFO:   <<< cross_model: cross-base
2022-06-21 02:09:41,499:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:09:41,499:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:09:41,499:INFO:   <<< datatype: msvd
2022-06-21 02:09:41,499:INFO:   <<< do_eval: False
2022-06-21 02:09:41,499:INFO:   <<< do_lower_case: False
2022-06-21 02:09:41,499:INFO:   <<< do_pretrain: False
2022-06-21 02:09:41,499:INFO:   <<< do_train: True
2022-06-21 02:09:41,499:INFO:   <<< epochs: 5
2022-06-21 02:09:41,499:INFO:   <<< eval_frame_order: 0
2022-06-21 02:09:41,499:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:09:41,500:INFO:   <<< feature_framerate: 1
2022-06-21 02:09:41,500:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:09:41,500:INFO:   <<< fp16: False
2022-06-21 02:09:41,500:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:09:41,500:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:09:41,500:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:09:41,500:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:09:41,500:INFO:   <<< init_model: None
2022-06-21 02:09:41,500:INFO:   <<< linear_patch: 3d
2022-06-21 02:09:41,500:INFO:   <<< local_rank: 0
2022-06-21 02:09:41,500:INFO:   <<< loose_type: True
2022-06-21 02:09:41,500:INFO:   <<< lr: 0.0001
2022-06-21 02:09:41,500:INFO:   <<< lr_decay: 0.9
2022-06-21 02:09:41,500:INFO:   <<< margin: 0.1
2022-06-21 02:09:41,500:INFO:   <<< max_frames: 16
2022-06-21 02:09:41,500:INFO:   <<< max_words: 32
2022-06-21 02:09:41,501:INFO:   <<< n_display: 50
2022-06-21 02:09:41,501:INFO:   <<< n_gpu: 1
2022-06-21 02:09:41,501:INFO:   <<< n_pair: 1
2022-06-21 02:09:41,501:INFO:   <<< negative_weighting: 1
2022-06-21 02:09:41,501:INFO:   <<< num_thread_reader: 2
2022-06-21 02:09:41,501:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:09:41,501:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:09:41,501:INFO:   <<< rank: 0
2022-06-21 02:09:41,501:INFO:   <<< resume_model: None
2022-06-21 02:09:41,501:INFO:   <<< sampled_use_mil: False
2022-06-21 02:09:41,501:INFO:   <<< seed: 42
2022-06-21 02:09:41,501:INFO:   <<< sim_header: meanP
2022-06-21 02:09:41,501:INFO:   <<< slice_framepos: 2
2022-06-21 02:09:41,501:INFO:   <<< task_type: retrieval
2022-06-21 02:09:41,501:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:09:41,501:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:09:41,502:INFO:   <<< train_frame_order: 0
2022-06-21 02:09:41,502:INFO:   <<< use_mil: False
2022-06-21 02:09:41,502:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:09:41,502:INFO:   <<< video_dim: 1024
2022-06-21 02:09:41,502:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:09:41,502:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:09:41,502:INFO:   <<< world_size: 1
2022-06-21 02:09:41,502:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:09:42,287:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:09:42,287:WARNING: Test retrieval by loose type.
2022-06-21 02:09:42,287:WARNING: 	 embed_dim: 512
2022-06-21 02:09:42,287:WARNING: 	 image_resolution: 224
2022-06-21 02:09:42,288:WARNING: 	 vision_layers: 12
2022-06-21 02:09:42,288:WARNING: 	 vision_width: 768
2022-06-21 02:09:42,288:WARNING: 	 vision_patch_size: 32
2022-06-21 02:09:42,288:WARNING: 	 context_length: 77
2022-06-21 02:09:42,288:WARNING: 	 vocab_size: 49408
2022-06-21 02:09:42,288:WARNING: 	 transformer_width: 512
2022-06-21 02:09:42,288:WARNING: 	 transformer_heads: 8
2022-06-21 02:09:42,288:WARNING: 	 transformer_layers: 12
2022-06-21 02:09:42,288:WARNING: 		 linear_patch: 3d
2022-06-21 02:09:42,288:WARNING: 	 cut_top_layer: 0
2022-06-21 02:09:49,650:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:10:01,805:INFO: ***** Running test *****
2022-06-21 02:10:01,805:INFO:   Num examples = 27763
2022-06-21 02:10:01,805:INFO:   Batch size = 16
2022-06-21 02:10:01,805:INFO:   Num steps = 1736
2022-06-21 02:10:01,805:INFO: ***** Running val *****
2022-06-21 02:10:01,805:INFO:   Num examples = 4290
2022-06-21 02:10:03,938:INFO: ***** Running training *****
2022-06-21 02:10:03,938:INFO:   Num examples = 48774
2022-06-21 02:10:03,938:INFO:   Batch size = 128
2022-06-21 02:10:03,938:INFO:   Num steps = 3810
2022-06-21 02:11:32,490:INFO: Effective parameters:
2022-06-21 02:11:32,490:INFO:   <<< batch_size: 128
2022-06-21 02:11:32,490:INFO:   <<< batch_size_val: 16
2022-06-21 02:11:32,490:INFO:   <<< cache_dir: 
2022-06-21 02:11:32,490:INFO:   <<< coef_lr: 0.001
2022-06-21 02:11:32,490:INFO:   <<< cross_model: cross-base
2022-06-21 02:11:32,490:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:11:32,491:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:11:32,491:INFO:   <<< datatype: msvd
2022-06-21 02:11:32,491:INFO:   <<< do_eval: False
2022-06-21 02:11:32,491:INFO:   <<< do_lower_case: False
2022-06-21 02:11:32,491:INFO:   <<< do_pretrain: False
2022-06-21 02:11:32,491:INFO:   <<< do_train: True
2022-06-21 02:11:32,491:INFO:   <<< epochs: 5
2022-06-21 02:11:32,491:INFO:   <<< eval_frame_order: 0
2022-06-21 02:11:32,491:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:11:32,491:INFO:   <<< feature_framerate: 1
2022-06-21 02:11:32,491:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:11:32,491:INFO:   <<< fp16: False
2022-06-21 02:11:32,491:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:11:32,491:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:11:32,491:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:11:32,492:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:11:32,492:INFO:   <<< init_model: None
2022-06-21 02:11:32,492:INFO:   <<< linear_patch: 3d
2022-06-21 02:11:32,492:INFO:   <<< local_rank: 0
2022-06-21 02:11:32,492:INFO:   <<< loose_type: True
2022-06-21 02:11:32,492:INFO:   <<< lr: 0.0001
2022-06-21 02:11:32,492:INFO:   <<< lr_decay: 0.9
2022-06-21 02:11:32,492:INFO:   <<< margin: 0.1
2022-06-21 02:11:32,492:INFO:   <<< max_frames: 16
2022-06-21 02:11:32,492:INFO:   <<< max_words: 32
2022-06-21 02:11:32,492:INFO:   <<< n_display: 50
2022-06-21 02:11:32,492:INFO:   <<< n_gpu: 1
2022-06-21 02:11:32,492:INFO:   <<< n_pair: 1
2022-06-21 02:11:32,492:INFO:   <<< negative_weighting: 1
2022-06-21 02:11:32,492:INFO:   <<< num_thread_reader: 2
2022-06-21 02:11:32,492:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:11:32,493:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:11:32,493:INFO:   <<< rank: 0
2022-06-21 02:11:32,493:INFO:   <<< resume_model: None
2022-06-21 02:11:32,493:INFO:   <<< sampled_use_mil: False
2022-06-21 02:11:32,493:INFO:   <<< seed: 42
2022-06-21 02:11:32,493:INFO:   <<< sim_header: meanP
2022-06-21 02:11:32,493:INFO:   <<< slice_framepos: 2
2022-06-21 02:11:32,493:INFO:   <<< task_type: retrieval
2022-06-21 02:11:32,493:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:11:32,493:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:11:32,493:INFO:   <<< train_frame_order: 0
2022-06-21 02:11:32,493:INFO:   <<< use_mil: False
2022-06-21 02:11:32,493:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:11:32,493:INFO:   <<< video_dim: 1024
2022-06-21 02:11:32,493:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:11:32,493:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:11:32,493:INFO:   <<< world_size: 1
2022-06-21 02:11:32,494:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:11:33,192:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:11:33,192:WARNING: Test retrieval by loose type.
2022-06-21 02:11:33,192:WARNING: 	 embed_dim: 512
2022-06-21 02:11:33,192:WARNING: 	 image_resolution: 224
2022-06-21 02:11:33,192:WARNING: 	 vision_layers: 12
2022-06-21 02:11:33,193:WARNING: 	 vision_width: 768
2022-06-21 02:11:33,193:WARNING: 	 vision_patch_size: 32
2022-06-21 02:11:33,193:WARNING: 	 context_length: 77
2022-06-21 02:11:33,193:WARNING: 	 vocab_size: 49408
2022-06-21 02:11:33,193:WARNING: 	 transformer_width: 512
2022-06-21 02:11:33,193:WARNING: 	 transformer_heads: 8
2022-06-21 02:11:33,193:WARNING: 	 transformer_layers: 12
2022-06-21 02:11:33,193:WARNING: 		 linear_patch: 3d
2022-06-21 02:11:33,193:WARNING: 	 cut_top_layer: 0
2022-06-21 02:11:40,376:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:11:50,090:INFO: ***** Running test *****
2022-06-21 02:11:50,090:INFO:   Num examples = 27763
2022-06-21 02:11:50,090:INFO:   Batch size = 16
2022-06-21 02:11:50,090:INFO:   Num steps = 1736
2022-06-21 02:11:50,090:INFO: ***** Running val *****
2022-06-21 02:11:50,090:INFO:   Num examples = 4290
2022-06-21 02:11:52,414:INFO: ***** Running training *****
2022-06-21 02:11:52,414:INFO:   Num examples = 48774
2022-06-21 02:11:52,415:INFO:   Batch size = 128
2022-06-21 02:11:52,415:INFO:   Num steps = 3810
2022-06-21 02:13:37,192:INFO: Effective parameters:
2022-06-21 02:13:37,192:INFO:   <<< batch_size: 128
2022-06-21 02:13:37,193:INFO:   <<< batch_size_val: 16
2022-06-21 02:13:37,193:INFO:   <<< cache_dir: 
2022-06-21 02:13:37,193:INFO:   <<< coef_lr: 0.001
2022-06-21 02:13:37,193:INFO:   <<< cross_model: cross-base
2022-06-21 02:13:37,193:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:13:37,193:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:13:37,193:INFO:   <<< datatype: msvd
2022-06-21 02:13:37,193:INFO:   <<< do_eval: False
2022-06-21 02:13:37,193:INFO:   <<< do_lower_case: False
2022-06-21 02:13:37,193:INFO:   <<< do_pretrain: False
2022-06-21 02:13:37,193:INFO:   <<< do_train: True
2022-06-21 02:13:37,193:INFO:   <<< epochs: 5
2022-06-21 02:13:37,193:INFO:   <<< eval_frame_order: 0
2022-06-21 02:13:37,193:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:13:37,193:INFO:   <<< feature_framerate: 1
2022-06-21 02:13:37,193:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:13:37,193:INFO:   <<< fp16: False
2022-06-21 02:13:37,193:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:13:37,194:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:13:37,194:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:13:37,194:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:13:37,194:INFO:   <<< init_model: None
2022-06-21 02:13:37,194:INFO:   <<< linear_patch: 3d
2022-06-21 02:13:37,194:INFO:   <<< local_rank: 0
2022-06-21 02:13:37,194:INFO:   <<< loose_type: True
2022-06-21 02:13:37,194:INFO:   <<< lr: 0.0001
2022-06-21 02:13:37,194:INFO:   <<< lr_decay: 0.9
2022-06-21 02:13:37,194:INFO:   <<< margin: 0.1
2022-06-21 02:13:37,194:INFO:   <<< max_frames: 16
2022-06-21 02:13:37,194:INFO:   <<< max_words: 32
2022-06-21 02:13:37,194:INFO:   <<< n_display: 50
2022-06-21 02:13:37,194:INFO:   <<< n_gpu: 1
2022-06-21 02:13:37,194:INFO:   <<< n_pair: 1
2022-06-21 02:13:37,194:INFO:   <<< negative_weighting: 1
2022-06-21 02:13:37,194:INFO:   <<< num_thread_reader: 2
2022-06-21 02:13:37,194:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:13:37,194:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:13:37,195:INFO:   <<< rank: 0
2022-06-21 02:13:37,195:INFO:   <<< resume_model: None
2022-06-21 02:13:37,195:INFO:   <<< sampled_use_mil: False
2022-06-21 02:13:37,195:INFO:   <<< seed: 42
2022-06-21 02:13:37,195:INFO:   <<< sim_header: meanP
2022-06-21 02:13:37,195:INFO:   <<< slice_framepos: 2
2022-06-21 02:13:37,195:INFO:   <<< task_type: retrieval
2022-06-21 02:13:37,195:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:13:37,195:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:13:37,195:INFO:   <<< train_frame_order: 0
2022-06-21 02:13:37,195:INFO:   <<< use_mil: False
2022-06-21 02:13:37,195:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:13:37,195:INFO:   <<< video_dim: 1024
2022-06-21 02:13:37,195:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:13:37,195:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:13:37,195:INFO:   <<< world_size: 1
2022-06-21 02:13:37,196:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:13:38,025:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:13:38,026:WARNING: Test retrieval by loose type.
2022-06-21 02:13:38,027:WARNING: 	 embed_dim: 512
2022-06-21 02:13:38,027:WARNING: 	 image_resolution: 224
2022-06-21 02:13:38,027:WARNING: 	 vision_layers: 12
2022-06-21 02:13:38,027:WARNING: 	 vision_width: 768
2022-06-21 02:13:38,027:WARNING: 	 vision_patch_size: 32
2022-06-21 02:13:38,027:WARNING: 	 context_length: 77
2022-06-21 02:13:38,027:WARNING: 	 vocab_size: 49408
2022-06-21 02:13:38,027:WARNING: 	 transformer_width: 512
2022-06-21 02:13:38,027:WARNING: 	 transformer_heads: 8
2022-06-21 02:13:38,027:WARNING: 	 transformer_layers: 12
2022-06-21 02:13:38,027:WARNING: 		 linear_patch: 3d
2022-06-21 02:13:38,027:WARNING: 	 cut_top_layer: 0
2022-06-21 02:13:45,215:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:13:55,634:INFO: ***** Running test *****
2022-06-21 02:13:55,634:INFO:   Num examples = 27763
2022-06-21 02:13:55,634:INFO:   Batch size = 16
2022-06-21 02:13:55,634:INFO:   Num steps = 1736
2022-06-21 02:13:55,634:INFO: ***** Running val *****
2022-06-21 02:13:55,634:INFO:   Num examples = 4290
2022-06-21 02:13:56,698:INFO: ***** Running training *****
2022-06-21 02:13:56,698:INFO:   Num examples = 48774
2022-06-21 02:13:56,698:INFO:   Batch size = 128
2022-06-21 02:13:56,698:INFO:   Num steps = 3810
2022-06-21 02:23:06,999:INFO: Effective parameters:
2022-06-21 02:23:06,999:INFO:   <<< batch_size: 128
2022-06-21 02:23:06,999:INFO:   <<< batch_size_val: 16
2022-06-21 02:23:06,999:INFO:   <<< cache_dir: 
2022-06-21 02:23:06,999:INFO:   <<< coef_lr: 0.001
2022-06-21 02:23:06,999:INFO:   <<< cross_model: cross-base
2022-06-21 02:23:06,999:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:23:06,999:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:23:07,000:INFO:   <<< datatype: msvd
2022-06-21 02:23:07,000:INFO:   <<< do_eval: False
2022-06-21 02:23:07,000:INFO:   <<< do_lower_case: False
2022-06-21 02:23:07,000:INFO:   <<< do_pretrain: False
2022-06-21 02:23:07,000:INFO:   <<< do_train: True
2022-06-21 02:23:07,000:INFO:   <<< epochs: 5
2022-06-21 02:23:07,000:INFO:   <<< eval_frame_order: 0
2022-06-21 02:23:07,000:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:23:07,000:INFO:   <<< feature_framerate: 1
2022-06-21 02:23:07,000:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:23:07,000:INFO:   <<< fp16: False
2022-06-21 02:23:07,000:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:23:07,000:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:23:07,000:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:23:07,000:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:23:07,000:INFO:   <<< init_model: None
2022-06-21 02:23:07,001:INFO:   <<< linear_patch: 3d
2022-06-21 02:23:07,001:INFO:   <<< local_rank: 0
2022-06-21 02:23:07,001:INFO:   <<< loose_type: True
2022-06-21 02:23:07,001:INFO:   <<< lr: 0.0001
2022-06-21 02:23:07,001:INFO:   <<< lr_decay: 0.9
2022-06-21 02:23:07,001:INFO:   <<< margin: 0.1
2022-06-21 02:23:07,001:INFO:   <<< max_frames: 16
2022-06-21 02:23:07,001:INFO:   <<< max_words: 32
2022-06-21 02:23:07,001:INFO:   <<< n_display: 50
2022-06-21 02:23:07,001:INFO:   <<< n_gpu: 1
2022-06-21 02:23:07,001:INFO:   <<< n_pair: 1
2022-06-21 02:23:07,001:INFO:   <<< negative_weighting: 1
2022-06-21 02:23:07,001:INFO:   <<< num_thread_reader: 2
2022-06-21 02:23:07,001:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:23:07,001:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:23:07,001:INFO:   <<< rank: 0
2022-06-21 02:23:07,002:INFO:   <<< resume_model: None
2022-06-21 02:23:07,002:INFO:   <<< sampled_use_mil: False
2022-06-21 02:23:07,002:INFO:   <<< seed: 42
2022-06-21 02:23:07,002:INFO:   <<< sim_header: meanP
2022-06-21 02:23:07,002:INFO:   <<< slice_framepos: 2
2022-06-21 02:23:07,002:INFO:   <<< task_type: retrieval
2022-06-21 02:23:07,002:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:23:07,002:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:23:07,002:INFO:   <<< train_frame_order: 0
2022-06-21 02:23:07,002:INFO:   <<< use_mil: False
2022-06-21 02:23:07,002:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:23:07,002:INFO:   <<< video_dim: 1024
2022-06-21 02:23:07,002:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:23:07,002:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:23:07,002:INFO:   <<< world_size: 1
2022-06-21 02:23:07,003:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:23:07,735:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:23:07,736:WARNING: Test retrieval by loose type.
2022-06-21 02:23:07,736:WARNING: 	 embed_dim: 512
2022-06-21 02:23:07,736:WARNING: 	 image_resolution: 224
2022-06-21 02:23:07,736:WARNING: 	 vision_layers: 12
2022-06-21 02:23:07,736:WARNING: 	 vision_width: 768
2022-06-21 02:23:07,736:WARNING: 	 vision_patch_size: 32
2022-06-21 02:23:07,736:WARNING: 	 context_length: 77
2022-06-21 02:23:07,736:WARNING: 	 vocab_size: 49408
2022-06-21 02:23:07,736:WARNING: 	 transformer_width: 512
2022-06-21 02:23:07,736:WARNING: 	 transformer_heads: 8
2022-06-21 02:23:07,736:WARNING: 	 transformer_layers: 12
2022-06-21 02:23:07,736:WARNING: 		 linear_patch: 3d
2022-06-21 02:23:07,736:WARNING: 	 cut_top_layer: 0
2022-06-21 02:23:14,944:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:23:28,461:INFO: ***** Running test *****
2022-06-21 02:23:28,461:INFO:   Num examples = 27763
2022-06-21 02:23:28,461:INFO:   Batch size = 16
2022-06-21 02:23:28,461:INFO:   Num steps = 1736
2022-06-21 02:23:28,461:INFO: ***** Running val *****
2022-06-21 02:23:28,461:INFO:   Num examples = 4290
2022-06-21 02:23:29,539:INFO: ***** Running training *****
2022-06-21 02:23:29,539:INFO:   Num examples = 48774
2022-06-21 02:23:29,539:INFO:   Batch size = 128
2022-06-21 02:23:29,539:INFO:   Num steps = 3810
2022-06-21 02:32:54,873:INFO: Effective parameters:
2022-06-21 02:32:54,873:INFO:   <<< batch_size: 128
2022-06-21 02:32:54,873:INFO:   <<< batch_size_val: 16
2022-06-21 02:32:54,873:INFO:   <<< cache_dir: 
2022-06-21 02:32:54,873:INFO:   <<< coef_lr: 0.001
2022-06-21 02:32:54,873:INFO:   <<< cross_model: cross-base
2022-06-21 02:32:54,873:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:32:54,873:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:32:54,873:INFO:   <<< datatype: msvd
2022-06-21 02:32:54,873:INFO:   <<< do_eval: False
2022-06-21 02:32:54,873:INFO:   <<< do_lower_case: False
2022-06-21 02:32:54,873:INFO:   <<< do_pretrain: False
2022-06-21 02:32:54,873:INFO:   <<< do_train: True
2022-06-21 02:32:54,873:INFO:   <<< epochs: 5
2022-06-21 02:32:54,873:INFO:   <<< eval_frame_order: 0
2022-06-21 02:32:54,873:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:32:54,873:INFO:   <<< feature_framerate: 1
2022-06-21 02:32:54,873:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:32:54,873:INFO:   <<< fp16: False
2022-06-21 02:32:54,873:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:32:54,873:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:32:54,873:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:32:54,873:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:32:54,873:INFO:   <<< init_model: None
2022-06-21 02:32:54,874:INFO:   <<< linear_patch: 3d
2022-06-21 02:32:54,874:INFO:   <<< local_rank: 0
2022-06-21 02:32:54,874:INFO:   <<< loose_type: True
2022-06-21 02:32:54,874:INFO:   <<< lr: 0.0001
2022-06-21 02:32:54,874:INFO:   <<< lr_decay: 0.9
2022-06-21 02:32:54,874:INFO:   <<< margin: 0.1
2022-06-21 02:32:54,874:INFO:   <<< max_frames: 16
2022-06-21 02:32:54,874:INFO:   <<< max_words: 32
2022-06-21 02:32:54,874:INFO:   <<< n_display: 50
2022-06-21 02:32:54,874:INFO:   <<< n_gpu: 1
2022-06-21 02:32:54,874:INFO:   <<< n_pair: 1
2022-06-21 02:32:54,874:INFO:   <<< negative_weighting: 1
2022-06-21 02:32:54,874:INFO:   <<< num_thread_reader: 2
2022-06-21 02:32:54,874:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:32:54,874:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:32:54,874:INFO:   <<< rank: 0
2022-06-21 02:32:54,874:INFO:   <<< resume_model: None
2022-06-21 02:32:54,874:INFO:   <<< sampled_use_mil: False
2022-06-21 02:32:54,874:INFO:   <<< seed: 42
2022-06-21 02:32:54,874:INFO:   <<< sim_header: meanP
2022-06-21 02:32:54,874:INFO:   <<< slice_framepos: 2
2022-06-21 02:32:54,874:INFO:   <<< task_type: retrieval
2022-06-21 02:32:54,874:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:32:54,874:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:32:54,874:INFO:   <<< train_frame_order: 0
2022-06-21 02:32:54,874:INFO:   <<< use_mil: False
2022-06-21 02:32:54,874:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:32:54,874:INFO:   <<< video_dim: 1024
2022-06-21 02:32:54,874:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:32:54,874:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:32:54,874:INFO:   <<< world_size: 1
2022-06-21 02:32:54,875:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:32:55,572:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:32:55,572:WARNING: Test retrieval by loose type.
2022-06-21 02:32:55,573:WARNING: 	 embed_dim: 512
2022-06-21 02:32:55,573:WARNING: 	 image_resolution: 224
2022-06-21 02:32:55,573:WARNING: 	 vision_layers: 12
2022-06-21 02:32:55,573:WARNING: 	 vision_width: 768
2022-06-21 02:32:55,573:WARNING: 	 vision_patch_size: 32
2022-06-21 02:32:55,573:WARNING: 	 context_length: 77
2022-06-21 02:32:55,573:WARNING: 	 vocab_size: 49408
2022-06-21 02:32:55,573:WARNING: 	 transformer_width: 512
2022-06-21 02:32:55,573:WARNING: 	 transformer_heads: 8
2022-06-21 02:32:55,573:WARNING: 	 transformer_layers: 12
2022-06-21 02:32:55,573:WARNING: 		 linear_patch: 3d
2022-06-21 02:32:55,573:WARNING: 	 cut_top_layer: 0
2022-06-21 02:33:02,792:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:33:12,380:INFO: ***** Running test *****
2022-06-21 02:33:12,380:INFO:   Num examples = 27763
2022-06-21 02:33:12,380:INFO:   Batch size = 16
2022-06-21 02:33:12,380:INFO:   Num steps = 1736
2022-06-21 02:33:12,380:INFO: ***** Running val *****
2022-06-21 02:33:12,380:INFO:   Num examples = 4290
2022-06-21 02:33:14,323:INFO: ***** Running training *****
2022-06-21 02:33:14,323:INFO:   Num examples = 48774
2022-06-21 02:33:14,323:INFO:   Batch size = 128
2022-06-21 02:33:14,323:INFO:   Num steps = 3810
2022-06-21 02:35:54,772:INFO: Effective parameters:
2022-06-21 02:35:54,773:INFO:   <<< batch_size: 128
2022-06-21 02:35:54,773:INFO:   <<< batch_size_val: 16
2022-06-21 02:35:54,773:INFO:   <<< cache_dir: 
2022-06-21 02:35:54,773:INFO:   <<< coef_lr: 0.001
2022-06-21 02:35:54,773:INFO:   <<< cross_model: cross-base
2022-06-21 02:35:54,773:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:35:54,773:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:35:54,773:INFO:   <<< datatype: msvd
2022-06-21 02:35:54,773:INFO:   <<< do_eval: False
2022-06-21 02:35:54,773:INFO:   <<< do_lower_case: False
2022-06-21 02:35:54,773:INFO:   <<< do_pretrain: False
2022-06-21 02:35:54,773:INFO:   <<< do_train: True
2022-06-21 02:35:54,774:INFO:   <<< epochs: 5
2022-06-21 02:35:54,774:INFO:   <<< eval_frame_order: 0
2022-06-21 02:35:54,774:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:35:54,774:INFO:   <<< feature_framerate: 1
2022-06-21 02:35:54,774:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:35:54,774:INFO:   <<< fp16: False
2022-06-21 02:35:54,774:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:35:54,774:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:35:54,774:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:35:54,774:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:35:54,774:INFO:   <<< init_model: None
2022-06-21 02:35:54,774:INFO:   <<< linear_patch: 3d
2022-06-21 02:35:54,774:INFO:   <<< local_rank: 0
2022-06-21 02:35:54,774:INFO:   <<< loose_type: True
2022-06-21 02:35:54,774:INFO:   <<< lr: 0.0001
2022-06-21 02:35:54,775:INFO:   <<< lr_decay: 0.9
2022-06-21 02:35:54,775:INFO:   <<< margin: 0.1
2022-06-21 02:35:54,775:INFO:   <<< max_frames: 16
2022-06-21 02:35:54,775:INFO:   <<< max_words: 32
2022-06-21 02:35:54,775:INFO:   <<< n_display: 50
2022-06-21 02:35:54,775:INFO:   <<< n_gpu: 1
2022-06-21 02:35:54,775:INFO:   <<< n_pair: 1
2022-06-21 02:35:54,775:INFO:   <<< negative_weighting: 1
2022-06-21 02:35:54,775:INFO:   <<< num_thread_reader: 2
2022-06-21 02:35:54,775:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:35:54,775:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:35:54,775:INFO:   <<< rank: 0
2022-06-21 02:35:54,775:INFO:   <<< resume_model: None
2022-06-21 02:35:54,775:INFO:   <<< sampled_use_mil: False
2022-06-21 02:35:54,775:INFO:   <<< seed: 42
2022-06-21 02:35:54,776:INFO:   <<< sim_header: meanP
2022-06-21 02:35:54,776:INFO:   <<< slice_framepos: 2
2022-06-21 02:35:54,776:INFO:   <<< task_type: retrieval
2022-06-21 02:35:54,776:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:35:54,776:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:35:54,776:INFO:   <<< train_frame_order: 0
2022-06-21 02:35:54,776:INFO:   <<< use_mil: False
2022-06-21 02:35:54,776:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:35:54,776:INFO:   <<< video_dim: 1024
2022-06-21 02:35:54,776:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:35:54,776:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:35:54,776:INFO:   <<< world_size: 1
2022-06-21 02:35:54,776:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:35:55,491:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:35:55,492:WARNING: Test retrieval by loose type.
2022-06-21 02:35:55,492:WARNING: 	 embed_dim: 512
2022-06-21 02:35:55,492:WARNING: 	 image_resolution: 224
2022-06-21 02:35:55,492:WARNING: 	 vision_layers: 12
2022-06-21 02:35:55,492:WARNING: 	 vision_width: 768
2022-06-21 02:35:55,492:WARNING: 	 vision_patch_size: 32
2022-06-21 02:35:55,492:WARNING: 	 context_length: 77
2022-06-21 02:35:55,492:WARNING: 	 vocab_size: 49408
2022-06-21 02:35:55,492:WARNING: 	 transformer_width: 512
2022-06-21 02:35:55,492:WARNING: 	 transformer_heads: 8
2022-06-21 02:35:55,492:WARNING: 	 transformer_layers: 12
2022-06-21 02:35:55,492:WARNING: 		 linear_patch: 3d
2022-06-21 02:35:55,492:WARNING: 	 cut_top_layer: 0
2022-06-21 02:36:02,895:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:36:15,498:INFO: ***** Running test *****
2022-06-21 02:36:15,498:INFO:   Num examples = 27763
2022-06-21 02:36:15,499:INFO:   Batch size = 16
2022-06-21 02:36:15,499:INFO:   Num steps = 1736
2022-06-21 02:36:15,499:INFO: ***** Running val *****
2022-06-21 02:36:15,499:INFO:   Num examples = 4290
2022-06-21 02:36:17,911:INFO: ***** Running training *****
2022-06-21 02:36:17,911:INFO:   Num examples = 48774
2022-06-21 02:36:17,911:INFO:   Batch size = 128
2022-06-21 02:36:17,911:INFO:   Num steps = 3810
2022-06-21 02:38:14,944:INFO: Effective parameters:
2022-06-21 02:38:14,944:INFO:   <<< batch_size: 128
2022-06-21 02:38:14,944:INFO:   <<< batch_size_val: 16
2022-06-21 02:38:14,944:INFO:   <<< cache_dir: 
2022-06-21 02:38:14,944:INFO:   <<< coef_lr: 0.001
2022-06-21 02:38:14,944:INFO:   <<< cross_model: cross-base
2022-06-21 02:38:14,945:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:38:14,945:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:38:14,945:INFO:   <<< datatype: msvd
2022-06-21 02:38:14,945:INFO:   <<< do_eval: False
2022-06-21 02:38:14,945:INFO:   <<< do_lower_case: False
2022-06-21 02:38:14,945:INFO:   <<< do_pretrain: False
2022-06-21 02:38:14,945:INFO:   <<< do_train: True
2022-06-21 02:38:14,945:INFO:   <<< epochs: 5
2022-06-21 02:38:14,945:INFO:   <<< eval_frame_order: 0
2022-06-21 02:38:14,945:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:38:14,945:INFO:   <<< feature_framerate: 1
2022-06-21 02:38:14,945:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:38:14,945:INFO:   <<< fp16: False
2022-06-21 02:38:14,945:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:38:14,946:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:38:14,946:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:38:14,946:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:38:14,946:INFO:   <<< init_model: None
2022-06-21 02:38:14,946:INFO:   <<< linear_patch: 3d
2022-06-21 02:38:14,946:INFO:   <<< local_rank: 0
2022-06-21 02:38:14,946:INFO:   <<< loose_type: True
2022-06-21 02:38:14,946:INFO:   <<< lr: 0.0001
2022-06-21 02:38:14,946:INFO:   <<< lr_decay: 0.9
2022-06-21 02:38:14,946:INFO:   <<< margin: 0.1
2022-06-21 02:38:14,946:INFO:   <<< max_frames: 16
2022-06-21 02:38:14,946:INFO:   <<< max_words: 32
2022-06-21 02:38:14,946:INFO:   <<< n_display: 50
2022-06-21 02:38:14,946:INFO:   <<< n_gpu: 1
2022-06-21 02:38:14,946:INFO:   <<< n_pair: 1
2022-06-21 02:38:14,947:INFO:   <<< negative_weighting: 1
2022-06-21 02:38:14,947:INFO:   <<< num_thread_reader: 2
2022-06-21 02:38:14,947:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:38:14,947:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:38:14,947:INFO:   <<< rank: 0
2022-06-21 02:38:14,947:INFO:   <<< resume_model: None
2022-06-21 02:38:14,947:INFO:   <<< sampled_use_mil: False
2022-06-21 02:38:14,947:INFO:   <<< seed: 42
2022-06-21 02:38:14,947:INFO:   <<< sim_header: meanP
2022-06-21 02:38:14,947:INFO:   <<< slice_framepos: 2
2022-06-21 02:38:14,947:INFO:   <<< task_type: retrieval
2022-06-21 02:38:14,947:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:38:14,947:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:38:14,947:INFO:   <<< train_frame_order: 0
2022-06-21 02:38:14,948:INFO:   <<< use_mil: False
2022-06-21 02:38:14,948:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:38:14,948:INFO:   <<< video_dim: 1024
2022-06-21 02:38:14,948:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:38:14,948:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:38:14,948:INFO:   <<< world_size: 1
2022-06-21 02:38:14,948:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:38:15,736:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:38:15,736:WARNING: Test retrieval by loose type.
2022-06-21 02:38:15,737:WARNING: 	 embed_dim: 512
2022-06-21 02:38:15,737:WARNING: 	 image_resolution: 224
2022-06-21 02:38:15,737:WARNING: 	 vision_layers: 12
2022-06-21 02:38:15,737:WARNING: 	 vision_width: 768
2022-06-21 02:38:15,737:WARNING: 	 vision_patch_size: 32
2022-06-21 02:38:15,737:WARNING: 	 context_length: 77
2022-06-21 02:38:15,737:WARNING: 	 vocab_size: 49408
2022-06-21 02:38:15,737:WARNING: 	 transformer_width: 512
2022-06-21 02:38:15,737:WARNING: 	 transformer_heads: 8
2022-06-21 02:38:15,737:WARNING: 	 transformer_layers: 12
2022-06-21 02:38:15,737:WARNING: 		 linear_patch: 3d
2022-06-21 02:38:15,738:WARNING: 	 cut_top_layer: 0
2022-06-21 02:38:23,029:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:38:35,389:INFO: ***** Running test *****
2022-06-21 02:38:35,389:INFO:   Num examples = 27763
2022-06-21 02:38:35,389:INFO:   Batch size = 16
2022-06-21 02:38:35,389:INFO:   Num steps = 1736
2022-06-21 02:38:35,389:INFO: ***** Running val *****
2022-06-21 02:38:35,389:INFO:   Num examples = 4290
2022-06-21 02:38:36,072:INFO: ***** Running training *****
2022-06-21 02:38:36,072:INFO:   Num examples = 48774
2022-06-21 02:38:36,072:INFO:   Batch size = 128
2022-06-21 02:38:36,072:INFO:   Num steps = 3810
2022-06-21 02:43:13,044:INFO: Effective parameters:
2022-06-21 02:43:13,044:INFO:   <<< batch_size: 128
2022-06-21 02:43:13,044:INFO:   <<< batch_size_val: 16
2022-06-21 02:43:13,045:INFO:   <<< cache_dir: 
2022-06-21 02:43:13,045:INFO:   <<< coef_lr: 0.001
2022-06-21 02:43:13,045:INFO:   <<< cross_model: cross-base
2022-06-21 02:43:13,045:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:43:13,045:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:43:13,045:INFO:   <<< datatype: msvd
2022-06-21 02:43:13,045:INFO:   <<< do_eval: False
2022-06-21 02:43:13,045:INFO:   <<< do_lower_case: False
2022-06-21 02:43:13,045:INFO:   <<< do_pretrain: False
2022-06-21 02:43:13,045:INFO:   <<< do_train: True
2022-06-21 02:43:13,045:INFO:   <<< epochs: 5
2022-06-21 02:43:13,045:INFO:   <<< eval_frame_order: 0
2022-06-21 02:43:13,045:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:43:13,045:INFO:   <<< feature_framerate: 1
2022-06-21 02:43:13,045:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:43:13,045:INFO:   <<< fp16: False
2022-06-21 02:43:13,045:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:43:13,045:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:43:13,045:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:43:13,045:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:43:13,045:INFO:   <<< init_model: None
2022-06-21 02:43:13,045:INFO:   <<< linear_patch: 3d
2022-06-21 02:43:13,045:INFO:   <<< local_rank: 0
2022-06-21 02:43:13,045:INFO:   <<< loose_type: True
2022-06-21 02:43:13,045:INFO:   <<< lr: 0.0001
2022-06-21 02:43:13,045:INFO:   <<< lr_decay: 0.9
2022-06-21 02:43:13,045:INFO:   <<< margin: 0.1
2022-06-21 02:43:13,045:INFO:   <<< max_frames: 16
2022-06-21 02:43:13,045:INFO:   <<< max_words: 32
2022-06-21 02:43:13,045:INFO:   <<< n_display: 50
2022-06-21 02:43:13,046:INFO:   <<< n_gpu: 1
2022-06-21 02:43:13,046:INFO:   <<< n_pair: 1
2022-06-21 02:43:13,046:INFO:   <<< negative_weighting: 1
2022-06-21 02:43:13,046:INFO:   <<< num_thread_reader: 2
2022-06-21 02:43:13,046:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:43:13,046:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:43:13,046:INFO:   <<< rank: 0
2022-06-21 02:43:13,046:INFO:   <<< resume_model: None
2022-06-21 02:43:13,046:INFO:   <<< sampled_use_mil: False
2022-06-21 02:43:13,046:INFO:   <<< seed: 42
2022-06-21 02:43:13,046:INFO:   <<< sim_header: meanP
2022-06-21 02:43:13,046:INFO:   <<< slice_framepos: 2
2022-06-21 02:43:13,046:INFO:   <<< task_type: retrieval
2022-06-21 02:43:13,046:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:43:13,046:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:43:13,046:INFO:   <<< train_frame_order: 0
2022-06-21 02:43:13,046:INFO:   <<< use_mil: False
2022-06-21 02:43:13,046:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:43:13,046:INFO:   <<< video_dim: 1024
2022-06-21 02:43:13,046:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:43:13,046:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:43:13,046:INFO:   <<< world_size: 1
2022-06-21 02:43:13,046:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:43:13,814:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:43:13,815:WARNING: Test retrieval by loose type.
2022-06-21 02:43:13,815:WARNING: 	 embed_dim: 512
2022-06-21 02:43:13,815:WARNING: 	 image_resolution: 224
2022-06-21 02:43:13,815:WARNING: 	 vision_layers: 12
2022-06-21 02:43:13,815:WARNING: 	 vision_width: 768
2022-06-21 02:43:13,815:WARNING: 	 vision_patch_size: 32
2022-06-21 02:43:13,815:WARNING: 	 context_length: 77
2022-06-21 02:43:13,815:WARNING: 	 vocab_size: 49408
2022-06-21 02:43:13,815:WARNING: 	 transformer_width: 512
2022-06-21 02:43:13,815:WARNING: 	 transformer_heads: 8
2022-06-21 02:43:13,815:WARNING: 	 transformer_layers: 12
2022-06-21 02:43:13,815:WARNING: 		 linear_patch: 3d
2022-06-21 02:43:13,815:WARNING: 	 cut_top_layer: 0
2022-06-21 02:43:21,348:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:43:32,562:INFO: ***** Running test *****
2022-06-21 02:43:32,562:INFO:   Num examples = 27763
2022-06-21 02:43:32,562:INFO:   Batch size = 16
2022-06-21 02:43:32,562:INFO:   Num steps = 1736
2022-06-21 02:43:32,562:INFO: ***** Running val *****
2022-06-21 02:43:32,563:INFO:   Num examples = 4290
2022-06-21 02:43:33,739:INFO: ***** Running training *****
2022-06-21 02:43:33,740:INFO:   Num examples = 48774
2022-06-21 02:43:33,740:INFO:   Batch size = 128
2022-06-21 02:43:33,740:INFO:   Num steps = 3810
2022-06-21 02:43:56,754:INFO: Effective parameters:
2022-06-21 02:43:56,754:INFO:   <<< batch_size: 128
2022-06-21 02:43:56,754:INFO:   <<< batch_size_val: 16
2022-06-21 02:43:56,754:INFO:   <<< cache_dir: 
2022-06-21 02:43:56,754:INFO:   <<< coef_lr: 0.001
2022-06-21 02:43:56,754:INFO:   <<< cross_model: cross-base
2022-06-21 02:43:56,754:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:43:56,755:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:43:56,755:INFO:   <<< datatype: msvd
2022-06-21 02:43:56,755:INFO:   <<< do_eval: False
2022-06-21 02:43:56,755:INFO:   <<< do_lower_case: False
2022-06-21 02:43:56,755:INFO:   <<< do_pretrain: False
2022-06-21 02:43:56,755:INFO:   <<< do_train: True
2022-06-21 02:43:56,755:INFO:   <<< epochs: 5
2022-06-21 02:43:56,755:INFO:   <<< eval_frame_order: 0
2022-06-21 02:43:56,755:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:43:56,755:INFO:   <<< feature_framerate: 1
2022-06-21 02:43:56,755:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:43:56,755:INFO:   <<< fp16: False
2022-06-21 02:43:56,755:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:43:56,755:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:43:56,755:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:43:56,755:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:43:56,755:INFO:   <<< init_model: None
2022-06-21 02:43:56,755:INFO:   <<< linear_patch: 3d
2022-06-21 02:43:56,756:INFO:   <<< local_rank: 0
2022-06-21 02:43:56,756:INFO:   <<< loose_type: True
2022-06-21 02:43:56,756:INFO:   <<< lr: 0.0001
2022-06-21 02:43:56,756:INFO:   <<< lr_decay: 0.9
2022-06-21 02:43:56,756:INFO:   <<< margin: 0.1
2022-06-21 02:43:56,756:INFO:   <<< max_frames: 16
2022-06-21 02:43:56,756:INFO:   <<< max_words: 32
2022-06-21 02:43:56,756:INFO:   <<< n_display: 50
2022-06-21 02:43:56,756:INFO:   <<< n_gpu: 1
2022-06-21 02:43:56,756:INFO:   <<< n_pair: 1
2022-06-21 02:43:56,756:INFO:   <<< negative_weighting: 1
2022-06-21 02:43:56,756:INFO:   <<< num_thread_reader: 2
2022-06-21 02:43:56,756:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:43:56,756:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:43:56,756:INFO:   <<< rank: 0
2022-06-21 02:43:56,756:INFO:   <<< resume_model: None
2022-06-21 02:43:56,756:INFO:   <<< sampled_use_mil: False
2022-06-21 02:43:56,757:INFO:   <<< seed: 42
2022-06-21 02:43:56,757:INFO:   <<< sim_header: meanP
2022-06-21 02:43:56,757:INFO:   <<< slice_framepos: 2
2022-06-21 02:43:56,757:INFO:   <<< task_type: retrieval
2022-06-21 02:43:56,757:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:43:56,757:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:43:56,757:INFO:   <<< train_frame_order: 0
2022-06-21 02:43:56,757:INFO:   <<< use_mil: False
2022-06-21 02:43:56,757:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:43:56,757:INFO:   <<< video_dim: 1024
2022-06-21 02:43:56,757:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:43:56,757:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:43:56,757:INFO:   <<< world_size: 1
2022-06-21 02:43:56,757:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:43:57,492:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:43:57,492:WARNING: Test retrieval by loose type.
2022-06-21 02:43:57,492:WARNING: 	 embed_dim: 512
2022-06-21 02:43:57,493:WARNING: 	 image_resolution: 224
2022-06-21 02:43:57,493:WARNING: 	 vision_layers: 12
2022-06-21 02:43:57,493:WARNING: 	 vision_width: 768
2022-06-21 02:43:57,493:WARNING: 	 vision_patch_size: 32
2022-06-21 02:43:57,493:WARNING: 	 context_length: 77
2022-06-21 02:43:57,493:WARNING: 	 vocab_size: 49408
2022-06-21 02:43:57,493:WARNING: 	 transformer_width: 512
2022-06-21 02:43:57,493:WARNING: 	 transformer_heads: 8
2022-06-21 02:43:57,493:WARNING: 	 transformer_layers: 12
2022-06-21 02:43:57,493:WARNING: 		 linear_patch: 3d
2022-06-21 02:43:57,493:WARNING: 	 cut_top_layer: 0
2022-06-21 02:44:04,596:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:44:16,174:INFO: ***** Running test *****
2022-06-21 02:44:16,174:INFO:   Num examples = 27763
2022-06-21 02:44:16,174:INFO:   Batch size = 16
2022-06-21 02:44:16,174:INFO:   Num steps = 1736
2022-06-21 02:44:16,174:INFO: ***** Running val *****
2022-06-21 02:44:16,174:INFO:   Num examples = 4290
2022-06-21 02:44:17,251:INFO: ***** Running training *****
2022-06-21 02:44:17,251:INFO:   Num examples = 48774
2022-06-21 02:44:17,251:INFO:   Batch size = 128
2022-06-21 02:44:17,251:INFO:   Num steps = 3810
2022-06-21 02:46:32,713:INFO: Effective parameters:
2022-06-21 02:46:32,713:INFO:   <<< batch_size: 128
2022-06-21 02:46:32,713:INFO:   <<< batch_size_val: 16
2022-06-21 02:46:32,713:INFO:   <<< cache_dir: 
2022-06-21 02:46:32,713:INFO:   <<< coef_lr: 0.001
2022-06-21 02:46:32,713:INFO:   <<< cross_model: cross-base
2022-06-21 02:46:32,713:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:46:32,713:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:46:32,714:INFO:   <<< datatype: msvd
2022-06-21 02:46:32,714:INFO:   <<< do_eval: False
2022-06-21 02:46:32,714:INFO:   <<< do_lower_case: False
2022-06-21 02:46:32,714:INFO:   <<< do_pretrain: False
2022-06-21 02:46:32,714:INFO:   <<< do_train: True
2022-06-21 02:46:32,714:INFO:   <<< epochs: 5
2022-06-21 02:46:32,714:INFO:   <<< eval_frame_order: 0
2022-06-21 02:46:32,714:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:46:32,714:INFO:   <<< feature_framerate: 1
2022-06-21 02:46:32,714:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:46:32,714:INFO:   <<< fp16: False
2022-06-21 02:46:32,714:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:46:32,714:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:46:32,714:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:46:32,715:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:46:32,715:INFO:   <<< init_model: None
2022-06-21 02:46:32,715:INFO:   <<< linear_patch: 3d
2022-06-21 02:46:32,715:INFO:   <<< local_rank: 0
2022-06-21 02:46:32,715:INFO:   <<< loose_type: True
2022-06-21 02:46:32,715:INFO:   <<< lr: 0.0001
2022-06-21 02:46:32,715:INFO:   <<< lr_decay: 0.9
2022-06-21 02:46:32,715:INFO:   <<< margin: 0.1
2022-06-21 02:46:32,715:INFO:   <<< max_frames: 16
2022-06-21 02:46:32,715:INFO:   <<< max_words: 32
2022-06-21 02:46:32,715:INFO:   <<< n_display: 50
2022-06-21 02:46:32,715:INFO:   <<< n_gpu: 1
2022-06-21 02:46:32,715:INFO:   <<< n_pair: 1
2022-06-21 02:46:32,716:INFO:   <<< negative_weighting: 1
2022-06-21 02:46:32,716:INFO:   <<< num_thread_reader: 2
2022-06-21 02:46:32,716:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:46:32,716:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:46:32,716:INFO:   <<< rank: 0
2022-06-21 02:46:32,716:INFO:   <<< resume_model: None
2022-06-21 02:46:32,716:INFO:   <<< sampled_use_mil: False
2022-06-21 02:46:32,716:INFO:   <<< seed: 42
2022-06-21 02:46:32,716:INFO:   <<< sim_header: meanP
2022-06-21 02:46:32,716:INFO:   <<< slice_framepos: 2
2022-06-21 02:46:32,716:INFO:   <<< task_type: retrieval
2022-06-21 02:46:32,716:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:46:32,716:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:46:32,716:INFO:   <<< train_frame_order: 0
2022-06-21 02:46:32,717:INFO:   <<< use_mil: False
2022-06-21 02:46:32,717:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:46:32,717:INFO:   <<< video_dim: 1024
2022-06-21 02:46:32,717:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:46:32,717:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:46:32,717:INFO:   <<< world_size: 1
2022-06-21 02:46:32,717:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:46:33,512:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:46:33,512:WARNING: Test retrieval by loose type.
2022-06-21 02:46:33,512:WARNING: 	 embed_dim: 512
2022-06-21 02:46:33,513:WARNING: 	 image_resolution: 224
2022-06-21 02:46:33,513:WARNING: 	 vision_layers: 12
2022-06-21 02:46:33,513:WARNING: 	 vision_width: 768
2022-06-21 02:46:33,513:WARNING: 	 vision_patch_size: 32
2022-06-21 02:46:33,513:WARNING: 	 context_length: 77
2022-06-21 02:46:33,513:WARNING: 	 vocab_size: 49408
2022-06-21 02:46:33,513:WARNING: 	 transformer_width: 512
2022-06-21 02:46:33,513:WARNING: 	 transformer_heads: 8
2022-06-21 02:46:33,513:WARNING: 	 transformer_layers: 12
2022-06-21 02:46:33,513:WARNING: 		 linear_patch: 3d
2022-06-21 02:46:33,513:WARNING: 	 cut_top_layer: 0
2022-06-21 02:46:40,686:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:46:52,066:INFO: ***** Running test *****
2022-06-21 02:46:52,067:INFO:   Num examples = 27763
2022-06-21 02:46:52,067:INFO:   Batch size = 16
2022-06-21 02:46:52,067:INFO:   Num steps = 1736
2022-06-21 02:46:52,067:INFO: ***** Running val *****
2022-06-21 02:46:52,067:INFO:   Num examples = 4290
2022-06-21 02:46:54,585:INFO: ***** Running training *****
2022-06-21 02:46:54,585:INFO:   Num examples = 48774
2022-06-21 02:46:54,586:INFO:   Batch size = 128
2022-06-21 02:46:54,586:INFO:   Num steps = 3810
2022-06-21 02:48:03,494:INFO: Effective parameters:
2022-06-21 02:48:03,495:INFO:   <<< batch_size: 128
2022-06-21 02:48:03,495:INFO:   <<< batch_size_val: 16
2022-06-21 02:48:03,495:INFO:   <<< cache_dir: 
2022-06-21 02:48:03,495:INFO:   <<< coef_lr: 0.001
2022-06-21 02:48:03,495:INFO:   <<< cross_model: cross-base
2022-06-21 02:48:03,495:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:48:03,495:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:48:03,495:INFO:   <<< datatype: msvd
2022-06-21 02:48:03,496:INFO:   <<< do_eval: False
2022-06-21 02:48:03,496:INFO:   <<< do_lower_case: False
2022-06-21 02:48:03,496:INFO:   <<< do_pretrain: False
2022-06-21 02:48:03,496:INFO:   <<< do_train: True
2022-06-21 02:48:03,496:INFO:   <<< epochs: 5
2022-06-21 02:48:03,496:INFO:   <<< eval_frame_order: 0
2022-06-21 02:48:03,496:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:48:03,496:INFO:   <<< feature_framerate: 1
2022-06-21 02:48:03,496:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:48:03,496:INFO:   <<< fp16: False
2022-06-21 02:48:03,496:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:48:03,496:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:48:03,496:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:48:03,496:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:48:03,496:INFO:   <<< init_model: None
2022-06-21 02:48:03,496:INFO:   <<< linear_patch: 3d
2022-06-21 02:48:03,496:INFO:   <<< local_rank: 0
2022-06-21 02:48:03,496:INFO:   <<< loose_type: True
2022-06-21 02:48:03,496:INFO:   <<< lr: 0.0001
2022-06-21 02:48:03,496:INFO:   <<< lr_decay: 0.9
2022-06-21 02:48:03,497:INFO:   <<< margin: 0.1
2022-06-21 02:48:03,497:INFO:   <<< max_frames: 16
2022-06-21 02:48:03,497:INFO:   <<< max_words: 32
2022-06-21 02:48:03,497:INFO:   <<< n_display: 50
2022-06-21 02:48:03,497:INFO:   <<< n_gpu: 1
2022-06-21 02:48:03,497:INFO:   <<< n_pair: 1
2022-06-21 02:48:03,497:INFO:   <<< negative_weighting: 1
2022-06-21 02:48:03,497:INFO:   <<< num_thread_reader: 2
2022-06-21 02:48:03,497:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:48:03,497:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:48:03,497:INFO:   <<< rank: 0
2022-06-21 02:48:03,497:INFO:   <<< resume_model: None
2022-06-21 02:48:03,497:INFO:   <<< sampled_use_mil: False
2022-06-21 02:48:03,497:INFO:   <<< seed: 42
2022-06-21 02:48:03,497:INFO:   <<< sim_header: meanP
2022-06-21 02:48:03,497:INFO:   <<< slice_framepos: 2
2022-06-21 02:48:03,497:INFO:   <<< task_type: retrieval
2022-06-21 02:48:03,497:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:48:03,497:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:48:03,497:INFO:   <<< train_frame_order: 0
2022-06-21 02:48:03,498:INFO:   <<< use_mil: False
2022-06-21 02:48:03,498:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:48:03,498:INFO:   <<< video_dim: 1024
2022-06-21 02:48:03,498:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:48:03,498:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:48:03,498:INFO:   <<< world_size: 1
2022-06-21 02:48:03,498:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:48:04,915:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:48:04,916:WARNING: Test retrieval by loose type.
2022-06-21 02:48:04,917:WARNING: 	 embed_dim: 512
2022-06-21 02:48:04,917:WARNING: 	 image_resolution: 224
2022-06-21 02:48:04,917:WARNING: 	 vision_layers: 12
2022-06-21 02:48:04,917:WARNING: 	 vision_width: 768
2022-06-21 02:48:04,917:WARNING: 	 vision_patch_size: 32
2022-06-21 02:48:04,917:WARNING: 	 context_length: 77
2022-06-21 02:48:04,917:WARNING: 	 vocab_size: 49408
2022-06-21 02:48:04,917:WARNING: 	 transformer_width: 512
2022-06-21 02:48:04,917:WARNING: 	 transformer_heads: 8
2022-06-21 02:48:04,917:WARNING: 	 transformer_layers: 12
2022-06-21 02:48:04,917:WARNING: 		 linear_patch: 3d
2022-06-21 02:48:04,917:WARNING: 	 cut_top_layer: 0
2022-06-21 02:48:12,019:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:48:22,933:INFO: ***** Running test *****
2022-06-21 02:48:22,934:INFO:   Num examples = 27763
2022-06-21 02:48:22,934:INFO:   Batch size = 16
2022-06-21 02:48:22,934:INFO:   Num steps = 1736
2022-06-21 02:48:22,934:INFO: ***** Running val *****
2022-06-21 02:48:22,934:INFO:   Num examples = 4290
2022-06-21 02:48:24,903:INFO: ***** Running training *****
2022-06-21 02:48:24,903:INFO:   Num examples = 48774
2022-06-21 02:48:24,903:INFO:   Batch size = 128
2022-06-21 02:48:24,903:INFO:   Num steps = 3810
2022-06-21 02:53:22,220:INFO: Effective parameters:
2022-06-21 02:53:22,220:INFO:   <<< batch_size: 128
2022-06-21 02:53:22,220:INFO:   <<< batch_size_val: 16
2022-06-21 02:53:22,220:INFO:   <<< cache_dir: 
2022-06-21 02:53:22,220:INFO:   <<< coef_lr: 0.001
2022-06-21 02:53:22,220:INFO:   <<< cross_model: cross-base
2022-06-21 02:53:22,220:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:53:22,220:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:53:22,220:INFO:   <<< datatype: msvd
2022-06-21 02:53:22,220:INFO:   <<< do_eval: False
2022-06-21 02:53:22,220:INFO:   <<< do_lower_case: False
2022-06-21 02:53:22,221:INFO:   <<< do_pretrain: False
2022-06-21 02:53:22,221:INFO:   <<< do_train: True
2022-06-21 02:53:22,221:INFO:   <<< epochs: 5
2022-06-21 02:53:22,221:INFO:   <<< eval_frame_order: 0
2022-06-21 02:53:22,221:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:53:22,221:INFO:   <<< feature_framerate: 1
2022-06-21 02:53:22,221:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:53:22,221:INFO:   <<< fp16: False
2022-06-21 02:53:22,221:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:53:22,221:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:53:22,221:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:53:22,221:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:53:22,221:INFO:   <<< init_model: None
2022-06-21 02:53:22,221:INFO:   <<< linear_patch: 3d
2022-06-21 02:53:22,221:INFO:   <<< local_rank: 0
2022-06-21 02:53:22,221:INFO:   <<< loose_type: True
2022-06-21 02:53:22,221:INFO:   <<< lr: 0.0001
2022-06-21 02:53:22,222:INFO:   <<< lr_decay: 0.9
2022-06-21 02:53:22,222:INFO:   <<< margin: 0.1
2022-06-21 02:53:22,222:INFO:   <<< max_frames: 16
2022-06-21 02:53:22,222:INFO:   <<< max_words: 32
2022-06-21 02:53:22,222:INFO:   <<< n_display: 50
2022-06-21 02:53:22,222:INFO:   <<< n_gpu: 1
2022-06-21 02:53:22,222:INFO:   <<< n_pair: 1
2022-06-21 02:53:22,222:INFO:   <<< negative_weighting: 1
2022-06-21 02:53:22,222:INFO:   <<< num_thread_reader: 2
2022-06-21 02:53:22,222:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:53:22,222:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:53:22,222:INFO:   <<< rank: 0
2022-06-21 02:53:22,222:INFO:   <<< resume_model: None
2022-06-21 02:53:22,222:INFO:   <<< sampled_use_mil: False
2022-06-21 02:53:22,222:INFO:   <<< seed: 42
2022-06-21 02:53:22,222:INFO:   <<< sim_header: meanP
2022-06-21 02:53:22,222:INFO:   <<< slice_framepos: 2
2022-06-21 02:53:22,223:INFO:   <<< task_type: retrieval
2022-06-21 02:53:22,223:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:53:22,223:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:53:22,223:INFO:   <<< train_frame_order: 0
2022-06-21 02:53:22,223:INFO:   <<< use_mil: False
2022-06-21 02:53:22,223:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:53:22,223:INFO:   <<< video_dim: 1024
2022-06-21 02:53:22,223:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:53:22,223:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:53:22,223:INFO:   <<< world_size: 1
2022-06-21 02:53:22,223:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:53:23,040:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:53:23,041:WARNING: Test retrieval by loose type.
2022-06-21 02:53:23,041:WARNING: 	 embed_dim: 512
2022-06-21 02:53:23,041:WARNING: 	 image_resolution: 224
2022-06-21 02:53:23,041:WARNING: 	 vision_layers: 12
2022-06-21 02:53:23,041:WARNING: 	 vision_width: 768
2022-06-21 02:53:23,041:WARNING: 	 vision_patch_size: 32
2022-06-21 02:53:23,041:WARNING: 	 context_length: 77
2022-06-21 02:53:23,041:WARNING: 	 vocab_size: 49408
2022-06-21 02:53:23,041:WARNING: 	 transformer_width: 512
2022-06-21 02:53:23,041:WARNING: 	 transformer_heads: 8
2022-06-21 02:53:23,041:WARNING: 	 transformer_layers: 12
2022-06-21 02:53:23,041:WARNING: 		 linear_patch: 3d
2022-06-21 02:53:23,041:WARNING: 	 cut_top_layer: 0
2022-06-21 02:53:30,587:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:53:40,285:INFO: ***** Running test *****
2022-06-21 02:53:40,286:INFO:   Num examples = 27763
2022-06-21 02:53:40,286:INFO:   Batch size = 16
2022-06-21 02:53:40,286:INFO:   Num steps = 1736
2022-06-21 02:53:40,286:INFO: ***** Running val *****
2022-06-21 02:53:40,286:INFO:   Num examples = 4290
2022-06-21 02:53:42,143:INFO: ***** Running training *****
2022-06-21 02:53:42,143:INFO:   Num examples = 48774
2022-06-21 02:53:42,143:INFO:   Batch size = 128
2022-06-21 02:53:42,143:INFO:   Num steps = 3810
2022-06-21 02:55:44,336:INFO: Effective parameters:
2022-06-21 02:55:44,336:INFO:   <<< batch_size: 128
2022-06-21 02:55:44,336:INFO:   <<< batch_size_val: 16
2022-06-21 02:55:44,336:INFO:   <<< cache_dir: 
2022-06-21 02:55:44,336:INFO:   <<< coef_lr: 0.001
2022-06-21 02:55:44,336:INFO:   <<< cross_model: cross-base
2022-06-21 02:55:44,336:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:55:44,337:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:55:44,337:INFO:   <<< datatype: msvd
2022-06-21 02:55:44,337:INFO:   <<< do_eval: False
2022-06-21 02:55:44,337:INFO:   <<< do_lower_case: False
2022-06-21 02:55:44,337:INFO:   <<< do_pretrain: False
2022-06-21 02:55:44,337:INFO:   <<< do_train: True
2022-06-21 02:55:44,337:INFO:   <<< epochs: 5
2022-06-21 02:55:44,337:INFO:   <<< eval_frame_order: 0
2022-06-21 02:55:44,337:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:55:44,337:INFO:   <<< feature_framerate: 1
2022-06-21 02:55:44,337:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:55:44,337:INFO:   <<< fp16: False
2022-06-21 02:55:44,337:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:55:44,337:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:55:44,337:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:55:44,337:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:55:44,337:INFO:   <<< init_model: None
2022-06-21 02:55:44,337:INFO:   <<< linear_patch: 3d
2022-06-21 02:55:44,337:INFO:   <<< local_rank: 0
2022-06-21 02:55:44,337:INFO:   <<< loose_type: True
2022-06-21 02:55:44,337:INFO:   <<< lr: 0.0001
2022-06-21 02:55:44,337:INFO:   <<< lr_decay: 0.9
2022-06-21 02:55:44,337:INFO:   <<< margin: 0.1
2022-06-21 02:55:44,337:INFO:   <<< max_frames: 16
2022-06-21 02:55:44,337:INFO:   <<< max_words: 32
2022-06-21 02:55:44,337:INFO:   <<< n_display: 50
2022-06-21 02:55:44,337:INFO:   <<< n_gpu: 1
2022-06-21 02:55:44,337:INFO:   <<< n_pair: 1
2022-06-21 02:55:44,338:INFO:   <<< negative_weighting: 1
2022-06-21 02:55:44,338:INFO:   <<< num_thread_reader: 2
2022-06-21 02:55:44,338:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:55:44,338:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:55:44,338:INFO:   <<< rank: 0
2022-06-21 02:55:44,338:INFO:   <<< resume_model: None
2022-06-21 02:55:44,338:INFO:   <<< sampled_use_mil: False
2022-06-21 02:55:44,338:INFO:   <<< seed: 42
2022-06-21 02:55:44,338:INFO:   <<< sim_header: meanP
2022-06-21 02:55:44,338:INFO:   <<< slice_framepos: 2
2022-06-21 02:55:44,338:INFO:   <<< task_type: retrieval
2022-06-21 02:55:44,338:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:55:44,338:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:55:44,338:INFO:   <<< train_frame_order: 0
2022-06-21 02:55:44,338:INFO:   <<< use_mil: False
2022-06-21 02:55:44,338:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:55:44,338:INFO:   <<< video_dim: 1024
2022-06-21 02:55:44,338:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:55:44,338:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:55:44,338:INFO:   <<< world_size: 1
2022-06-21 02:55:44,338:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:55:45,051:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:55:45,051:WARNING: Test retrieval by loose type.
2022-06-21 02:55:45,052:WARNING: 	 embed_dim: 512
2022-06-21 02:55:45,052:WARNING: 	 image_resolution: 224
2022-06-21 02:55:45,052:WARNING: 	 vision_layers: 12
2022-06-21 02:55:45,052:WARNING: 	 vision_width: 768
2022-06-21 02:55:45,052:WARNING: 	 vision_patch_size: 32
2022-06-21 02:55:45,052:WARNING: 	 context_length: 77
2022-06-21 02:55:45,052:WARNING: 	 vocab_size: 49408
2022-06-21 02:55:45,052:WARNING: 	 transformer_width: 512
2022-06-21 02:55:45,052:WARNING: 	 transformer_heads: 8
2022-06-21 02:55:45,052:WARNING: 	 transformer_layers: 12
2022-06-21 02:55:45,052:WARNING: 		 linear_patch: 3d
2022-06-21 02:55:45,052:WARNING: 	 cut_top_layer: 0
2022-06-21 02:55:52,431:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:56:03,424:INFO: ***** Running test *****
2022-06-21 02:56:03,424:INFO:   Num examples = 27763
2022-06-21 02:56:03,424:INFO:   Batch size = 16
2022-06-21 02:56:03,424:INFO:   Num steps = 1736
2022-06-21 02:56:03,424:INFO: ***** Running val *****
2022-06-21 02:56:03,424:INFO:   Num examples = 4290
2022-06-21 02:56:05,598:INFO: ***** Running training *****
2022-06-21 02:56:05,598:INFO:   Num examples = 48774
2022-06-21 02:56:05,598:INFO:   Batch size = 128
2022-06-21 02:56:05,598:INFO:   Num steps = 3810
2022-06-21 02:57:07,979:INFO: Effective parameters:
2022-06-21 02:57:07,979:INFO:   <<< batch_size: 128
2022-06-21 02:57:07,979:INFO:   <<< batch_size_val: 16
2022-06-21 02:57:07,979:INFO:   <<< cache_dir: 
2022-06-21 02:57:07,979:INFO:   <<< coef_lr: 0.001
2022-06-21 02:57:07,979:INFO:   <<< cross_model: cross-base
2022-06-21 02:57:07,980:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 02:57:07,980:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 02:57:07,980:INFO:   <<< datatype: msvd
2022-06-21 02:57:07,980:INFO:   <<< do_eval: False
2022-06-21 02:57:07,980:INFO:   <<< do_lower_case: False
2022-06-21 02:57:07,980:INFO:   <<< do_pretrain: False
2022-06-21 02:57:07,980:INFO:   <<< do_train: True
2022-06-21 02:57:07,980:INFO:   <<< epochs: 5
2022-06-21 02:57:07,980:INFO:   <<< eval_frame_order: 0
2022-06-21 02:57:07,980:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 02:57:07,980:INFO:   <<< feature_framerate: 1
2022-06-21 02:57:07,980:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 02:57:07,980:INFO:   <<< fp16: False
2022-06-21 02:57:07,981:INFO:   <<< fp16_opt_level: O1
2022-06-21 02:57:07,981:INFO:   <<< freeze_layer_num: 0
2022-06-21 02:57:07,981:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 02:57:07,981:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 02:57:07,981:INFO:   <<< init_model: None
2022-06-21 02:57:07,981:INFO:   <<< linear_patch: 3d
2022-06-21 02:57:07,981:INFO:   <<< local_rank: 0
2022-06-21 02:57:07,981:INFO:   <<< loose_type: True
2022-06-21 02:57:07,981:INFO:   <<< lr: 0.0001
2022-06-21 02:57:07,981:INFO:   <<< lr_decay: 0.9
2022-06-21 02:57:07,981:INFO:   <<< margin: 0.1
2022-06-21 02:57:07,981:INFO:   <<< max_frames: 16
2022-06-21 02:57:07,981:INFO:   <<< max_words: 32
2022-06-21 02:57:07,982:INFO:   <<< n_display: 50
2022-06-21 02:57:07,982:INFO:   <<< n_gpu: 1
2022-06-21 02:57:07,982:INFO:   <<< n_pair: 1
2022-06-21 02:57:07,982:INFO:   <<< negative_weighting: 1
2022-06-21 02:57:07,982:INFO:   <<< num_thread_reader: 2
2022-06-21 02:57:07,982:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 02:57:07,982:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 02:57:07,982:INFO:   <<< rank: 0
2022-06-21 02:57:07,982:INFO:   <<< resume_model: None
2022-06-21 02:57:07,982:INFO:   <<< sampled_use_mil: False
2022-06-21 02:57:07,982:INFO:   <<< seed: 42
2022-06-21 02:57:07,982:INFO:   <<< sim_header: meanP
2022-06-21 02:57:07,982:INFO:   <<< slice_framepos: 2
2022-06-21 02:57:07,983:INFO:   <<< task_type: retrieval
2022-06-21 02:57:07,983:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 02:57:07,983:INFO:   <<< train_csv: data/.train.csv
2022-06-21 02:57:07,983:INFO:   <<< train_frame_order: 0
2022-06-21 02:57:07,983:INFO:   <<< use_mil: False
2022-06-21 02:57:07,983:INFO:   <<< val_csv: data/.val.csv
2022-06-21 02:57:07,983:INFO:   <<< video_dim: 1024
2022-06-21 02:57:07,983:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 02:57:07,983:INFO:   <<< warmup_proportion: 0.1
2022-06-21 02:57:07,983:INFO:   <<< world_size: 1
2022-06-21 02:57:07,983:INFO: device: cuda:0 n_gpu: 2
2022-06-21 02:57:08,810:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 02:57:08,810:WARNING: Test retrieval by loose type.
2022-06-21 02:57:08,811:WARNING: 	 embed_dim: 512
2022-06-21 02:57:08,811:WARNING: 	 image_resolution: 224
2022-06-21 02:57:08,811:WARNING: 	 vision_layers: 12
2022-06-21 02:57:08,811:WARNING: 	 vision_width: 768
2022-06-21 02:57:08,811:WARNING: 	 vision_patch_size: 32
2022-06-21 02:57:08,811:WARNING: 	 context_length: 77
2022-06-21 02:57:08,811:WARNING: 	 vocab_size: 49408
2022-06-21 02:57:08,811:WARNING: 	 transformer_width: 512
2022-06-21 02:57:08,811:WARNING: 	 transformer_heads: 8
2022-06-21 02:57:08,811:WARNING: 	 transformer_layers: 12
2022-06-21 02:57:08,811:WARNING: 		 linear_patch: 3d
2022-06-21 02:57:08,811:WARNING: 	 cut_top_layer: 0
2022-06-21 02:57:16,372:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 02:57:29,204:INFO: ***** Running test *****
2022-06-21 02:57:29,204:INFO:   Num examples = 27763
2022-06-21 02:57:29,204:INFO:   Batch size = 16
2022-06-21 02:57:29,204:INFO:   Num steps = 1736
2022-06-21 02:57:29,204:INFO: ***** Running val *****
2022-06-21 02:57:29,204:INFO:   Num examples = 4290
2022-06-21 02:57:31,277:INFO: ***** Running training *****
2022-06-21 02:57:31,278:INFO:   Num examples = 48774
2022-06-21 02:57:31,278:INFO:   Batch size = 128
2022-06-21 02:57:31,278:INFO:   Num steps = 3810
2022-06-21 03:28:59,064:INFO: Effective parameters:
2022-06-21 03:28:59,064:INFO:   <<< batch_size: 128
2022-06-21 03:28:59,064:INFO:   <<< batch_size_val: 16
2022-06-21 03:28:59,064:INFO:   <<< cache_dir: 
2022-06-21 03:28:59,064:INFO:   <<< coef_lr: 0.001
2022-06-21 03:28:59,064:INFO:   <<< cross_model: cross-base
2022-06-21 03:28:59,064:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 03:28:59,064:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 03:28:59,064:INFO:   <<< datatype: msvd
2022-06-21 03:28:59,064:INFO:   <<< do_eval: False
2022-06-21 03:28:59,064:INFO:   <<< do_lower_case: False
2022-06-21 03:28:59,065:INFO:   <<< do_pretrain: False
2022-06-21 03:28:59,065:INFO:   <<< do_train: True
2022-06-21 03:28:59,065:INFO:   <<< epochs: 5
2022-06-21 03:28:59,065:INFO:   <<< eval_frame_order: 0
2022-06-21 03:28:59,065:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 03:28:59,065:INFO:   <<< feature_framerate: 1
2022-06-21 03:28:59,065:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 03:28:59,065:INFO:   <<< fp16: False
2022-06-21 03:28:59,065:INFO:   <<< fp16_opt_level: O1
2022-06-21 03:28:59,065:INFO:   <<< freeze_layer_num: 0
2022-06-21 03:28:59,065:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 03:28:59,065:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 03:28:59,065:INFO:   <<< init_model: None
2022-06-21 03:28:59,065:INFO:   <<< linear_patch: 3d
2022-06-21 03:28:59,065:INFO:   <<< local_rank: 0
2022-06-21 03:28:59,065:INFO:   <<< loose_type: True
2022-06-21 03:28:59,065:INFO:   <<< lr: 0.0001
2022-06-21 03:28:59,065:INFO:   <<< lr_decay: 0.9
2022-06-21 03:28:59,065:INFO:   <<< margin: 0.1
2022-06-21 03:28:59,066:INFO:   <<< max_frames: 16
2022-06-21 03:28:59,066:INFO:   <<< max_words: 32
2022-06-21 03:28:59,066:INFO:   <<< n_display: 50
2022-06-21 03:28:59,066:INFO:   <<< n_gpu: 1
2022-06-21 03:28:59,066:INFO:   <<< n_pair: 1
2022-06-21 03:28:59,066:INFO:   <<< negative_weighting: 1
2022-06-21 03:28:59,066:INFO:   <<< num_thread_reader: 2
2022-06-21 03:28:59,066:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 03:28:59,066:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 03:28:59,066:INFO:   <<< rank: 0
2022-06-21 03:28:59,066:INFO:   <<< resume_model: None
2022-06-21 03:28:59,066:INFO:   <<< sampled_use_mil: False
2022-06-21 03:28:59,066:INFO:   <<< seed: 42
2022-06-21 03:28:59,066:INFO:   <<< sim_header: meanP
2022-06-21 03:28:59,066:INFO:   <<< slice_framepos: 2
2022-06-21 03:28:59,066:INFO:   <<< task_type: retrieval
2022-06-21 03:28:59,066:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 03:28:59,066:INFO:   <<< train_csv: data/.train.csv
2022-06-21 03:28:59,067:INFO:   <<< train_frame_order: 0
2022-06-21 03:28:59,067:INFO:   <<< use_mil: False
2022-06-21 03:28:59,067:INFO:   <<< val_csv: data/.val.csv
2022-06-21 03:28:59,067:INFO:   <<< video_dim: 1024
2022-06-21 03:28:59,067:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 03:28:59,067:INFO:   <<< warmup_proportion: 0.1
2022-06-21 03:28:59,067:INFO:   <<< world_size: 1
2022-06-21 03:28:59,067:INFO: device: cuda:0 n_gpu: 2
2022-06-21 03:28:59,831:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 03:28:59,831:WARNING: Test retrieval by loose type.
2022-06-21 03:28:59,832:WARNING: 	 embed_dim: 512
2022-06-21 03:28:59,832:WARNING: 	 image_resolution: 224
2022-06-21 03:28:59,832:WARNING: 	 vision_layers: 12
2022-06-21 03:28:59,832:WARNING: 	 vision_width: 768
2022-06-21 03:28:59,832:WARNING: 	 vision_patch_size: 32
2022-06-21 03:28:59,832:WARNING: 	 context_length: 77
2022-06-21 03:28:59,832:WARNING: 	 vocab_size: 49408
2022-06-21 03:28:59,832:WARNING: 	 transformer_width: 512
2022-06-21 03:28:59,832:WARNING: 	 transformer_heads: 8
2022-06-21 03:28:59,832:WARNING: 	 transformer_layers: 12
2022-06-21 03:28:59,832:WARNING: 		 linear_patch: 3d
2022-06-21 03:28:59,832:WARNING: 	 cut_top_layer: 0
2022-06-21 03:29:07,104:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 03:29:17,894:INFO: ***** Running test *****
2022-06-21 03:29:17,894:INFO:   Num examples = 27763
2022-06-21 03:29:17,894:INFO:   Batch size = 16
2022-06-21 03:29:17,894:INFO:   Num steps = 1736
2022-06-21 03:29:17,894:INFO: ***** Running val *****
2022-06-21 03:29:17,894:INFO:   Num examples = 4290
2022-06-21 03:29:20,054:INFO: ***** Running training *****
2022-06-21 03:29:20,054:INFO:   Num examples = 48774
2022-06-21 03:29:20,054:INFO:   Batch size = 128
2022-06-21 03:29:20,054:INFO:   Num steps = 3810
2022-06-21 03:34:32,272:INFO: Effective parameters:
2022-06-21 03:34:32,272:INFO:   <<< batch_size: 128
2022-06-21 03:34:32,273:INFO:   <<< batch_size_val: 16
2022-06-21 03:34:32,273:INFO:   <<< cache_dir: 
2022-06-21 03:34:32,273:INFO:   <<< coef_lr: 0.001
2022-06-21 03:34:32,273:INFO:   <<< cross_model: cross-base
2022-06-21 03:34:32,273:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 03:34:32,273:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 03:34:32,273:INFO:   <<< datatype: msvd
2022-06-21 03:34:32,273:INFO:   <<< do_eval: False
2022-06-21 03:34:32,273:INFO:   <<< do_lower_case: False
2022-06-21 03:34:32,273:INFO:   <<< do_pretrain: False
2022-06-21 03:34:32,273:INFO:   <<< do_train: True
2022-06-21 03:34:32,273:INFO:   <<< epochs: 5
2022-06-21 03:34:32,273:INFO:   <<< eval_frame_order: 0
2022-06-21 03:34:32,273:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 03:34:32,274:INFO:   <<< feature_framerate: 1
2022-06-21 03:34:32,274:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 03:34:32,274:INFO:   <<< fp16: False
2022-06-21 03:34:32,274:INFO:   <<< fp16_opt_level: O1
2022-06-21 03:34:32,274:INFO:   <<< freeze_layer_num: 0
2022-06-21 03:34:32,274:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 03:34:32,274:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 03:34:32,274:INFO:   <<< init_model: None
2022-06-21 03:34:32,274:INFO:   <<< linear_patch: 3d
2022-06-21 03:34:32,274:INFO:   <<< local_rank: 0
2022-06-21 03:34:32,274:INFO:   <<< loose_type: True
2022-06-21 03:34:32,275:INFO:   <<< lr: 0.0001
2022-06-21 03:34:32,275:INFO:   <<< lr_decay: 0.9
2022-06-21 03:34:32,275:INFO:   <<< margin: 0.1
2022-06-21 03:34:32,275:INFO:   <<< max_frames: 16
2022-06-21 03:34:32,275:INFO:   <<< max_words: 32
2022-06-21 03:34:32,275:INFO:   <<< n_display: 50
2022-06-21 03:34:32,275:INFO:   <<< n_gpu: 1
2022-06-21 03:34:32,275:INFO:   <<< n_pair: 1
2022-06-21 03:34:32,275:INFO:   <<< negative_weighting: 1
2022-06-21 03:34:32,275:INFO:   <<< num_thread_reader: 2
2022-06-21 03:34:32,275:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 03:34:32,275:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 03:34:32,275:INFO:   <<< rank: 0
2022-06-21 03:34:32,275:INFO:   <<< resume_model: None
2022-06-21 03:34:32,276:INFO:   <<< sampled_use_mil: False
2022-06-21 03:34:32,276:INFO:   <<< seed: 42
2022-06-21 03:34:32,276:INFO:   <<< sim_header: meanP
2022-06-21 03:34:32,276:INFO:   <<< slice_framepos: 2
2022-06-21 03:34:32,276:INFO:   <<< task_type: retrieval
2022-06-21 03:34:32,276:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 03:34:32,276:INFO:   <<< train_csv: data/.train.csv
2022-06-21 03:34:32,276:INFO:   <<< train_frame_order: 0
2022-06-21 03:34:32,276:INFO:   <<< use_mil: False
2022-06-21 03:34:32,276:INFO:   <<< val_csv: data/.val.csv
2022-06-21 03:34:32,276:INFO:   <<< video_dim: 1024
2022-06-21 03:34:32,276:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 03:34:32,276:INFO:   <<< warmup_proportion: 0.1
2022-06-21 03:34:32,276:INFO:   <<< world_size: 1
2022-06-21 03:34:32,276:INFO: device: cuda:0 n_gpu: 2
2022-06-21 03:34:33,013:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 03:34:33,013:WARNING: Test retrieval by loose type.
2022-06-21 03:34:33,013:WARNING: 	 embed_dim: 512
2022-06-21 03:34:33,013:WARNING: 	 image_resolution: 224
2022-06-21 03:34:33,013:WARNING: 	 vision_layers: 12
2022-06-21 03:34:33,013:WARNING: 	 vision_width: 768
2022-06-21 03:34:33,014:WARNING: 	 vision_patch_size: 32
2022-06-21 03:34:33,014:WARNING: 	 context_length: 77
2022-06-21 03:34:33,014:WARNING: 	 vocab_size: 49408
2022-06-21 03:34:33,014:WARNING: 	 transformer_width: 512
2022-06-21 03:34:33,014:WARNING: 	 transformer_heads: 8
2022-06-21 03:34:33,014:WARNING: 	 transformer_layers: 12
2022-06-21 03:34:33,014:WARNING: 		 linear_patch: 3d
2022-06-21 03:34:33,014:WARNING: 	 cut_top_layer: 0
2022-06-21 03:34:40,414:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 03:34:52,240:INFO: ***** Running test *****
2022-06-21 03:34:52,240:INFO:   Num examples = 27763
2022-06-21 03:34:52,240:INFO:   Batch size = 16
2022-06-21 03:34:52,240:INFO:   Num steps = 1736
2022-06-21 03:34:52,240:INFO: ***** Running val *****
2022-06-21 03:34:52,240:INFO:   Num examples = 4290
2022-06-21 03:34:54,600:INFO: ***** Running training *****
2022-06-21 03:34:54,600:INFO:   Num examples = 48774
2022-06-21 03:34:54,600:INFO:   Batch size = 128
2022-06-21 03:34:54,600:INFO:   Num steps = 3810
2022-06-21 03:36:40,141:INFO: Effective parameters:
2022-06-21 03:36:40,142:INFO:   <<< batch_size: 128
2022-06-21 03:36:40,142:INFO:   <<< batch_size_val: 16
2022-06-21 03:36:40,142:INFO:   <<< cache_dir: 
2022-06-21 03:36:40,142:INFO:   <<< coef_lr: 0.001
2022-06-21 03:36:40,142:INFO:   <<< cross_model: cross-base
2022-06-21 03:36:40,142:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 03:36:40,142:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 03:36:40,142:INFO:   <<< datatype: msvd
2022-06-21 03:36:40,142:INFO:   <<< do_eval: False
2022-06-21 03:36:40,142:INFO:   <<< do_lower_case: False
2022-06-21 03:36:40,142:INFO:   <<< do_pretrain: False
2022-06-21 03:36:40,143:INFO:   <<< do_train: True
2022-06-21 03:36:40,143:INFO:   <<< epochs: 5
2022-06-21 03:36:40,143:INFO:   <<< eval_frame_order: 0
2022-06-21 03:36:40,143:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 03:36:40,143:INFO:   <<< feature_framerate: 1
2022-06-21 03:36:40,143:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 03:36:40,143:INFO:   <<< fp16: False
2022-06-21 03:36:40,143:INFO:   <<< fp16_opt_level: O1
2022-06-21 03:36:40,143:INFO:   <<< freeze_layer_num: 0
2022-06-21 03:36:40,143:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 03:36:40,143:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 03:36:40,143:INFO:   <<< init_model: None
2022-06-21 03:36:40,143:INFO:   <<< linear_patch: 3d
2022-06-21 03:36:40,143:INFO:   <<< local_rank: 0
2022-06-21 03:36:40,143:INFO:   <<< loose_type: True
2022-06-21 03:36:40,144:INFO:   <<< lr: 0.0001
2022-06-21 03:36:40,144:INFO:   <<< lr_decay: 0.9
2022-06-21 03:36:40,144:INFO:   <<< margin: 0.1
2022-06-21 03:36:40,144:INFO:   <<< max_frames: 16
2022-06-21 03:36:40,144:INFO:   <<< max_words: 32
2022-06-21 03:36:40,144:INFO:   <<< n_display: 50
2022-06-21 03:36:40,144:INFO:   <<< n_gpu: 1
2022-06-21 03:36:40,144:INFO:   <<< n_pair: 1
2022-06-21 03:36:40,144:INFO:   <<< negative_weighting: 1
2022-06-21 03:36:40,144:INFO:   <<< num_thread_reader: 2
2022-06-21 03:36:40,144:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 03:36:40,144:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 03:36:40,144:INFO:   <<< rank: 0
2022-06-21 03:36:40,144:INFO:   <<< resume_model: None
2022-06-21 03:36:40,144:INFO:   <<< sampled_use_mil: False
2022-06-21 03:36:40,145:INFO:   <<< seed: 42
2022-06-21 03:36:40,145:INFO:   <<< sim_header: meanP
2022-06-21 03:36:40,145:INFO:   <<< slice_framepos: 2
2022-06-21 03:36:40,145:INFO:   <<< task_type: retrieval
2022-06-21 03:36:40,145:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 03:36:40,145:INFO:   <<< train_csv: data/.train.csv
2022-06-21 03:36:40,145:INFO:   <<< train_frame_order: 0
2022-06-21 03:36:40,145:INFO:   <<< use_mil: False
2022-06-21 03:36:40,145:INFO:   <<< val_csv: data/.val.csv
2022-06-21 03:36:40,145:INFO:   <<< video_dim: 1024
2022-06-21 03:36:40,145:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 03:36:40,145:INFO:   <<< warmup_proportion: 0.1
2022-06-21 03:36:40,145:INFO:   <<< world_size: 1
2022-06-21 03:36:40,145:INFO: device: cuda:0 n_gpu: 2
2022-06-21 03:36:40,857:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 03:36:40,858:WARNING: Test retrieval by loose type.
2022-06-21 03:36:40,858:WARNING: 	 embed_dim: 512
2022-06-21 03:36:40,858:WARNING: 	 image_resolution: 224
2022-06-21 03:36:40,858:WARNING: 	 vision_layers: 12
2022-06-21 03:36:40,858:WARNING: 	 vision_width: 768
2022-06-21 03:36:40,858:WARNING: 	 vision_patch_size: 32
2022-06-21 03:36:40,858:WARNING: 	 context_length: 77
2022-06-21 03:36:40,858:WARNING: 	 vocab_size: 49408
2022-06-21 03:36:40,858:WARNING: 	 transformer_width: 512
2022-06-21 03:36:40,858:WARNING: 	 transformer_heads: 8
2022-06-21 03:36:40,858:WARNING: 	 transformer_layers: 12
2022-06-21 03:36:40,858:WARNING: 		 linear_patch: 3d
2022-06-21 03:36:40,858:WARNING: 	 cut_top_layer: 0
2022-06-21 03:36:48,220:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 03:36:58,532:INFO: ***** Running test *****
2022-06-21 03:36:58,532:INFO:   Num examples = 27763
2022-06-21 03:36:58,532:INFO:   Batch size = 16
2022-06-21 03:36:58,532:INFO:   Num steps = 1736
2022-06-21 03:36:58,532:INFO: ***** Running val *****
2022-06-21 03:36:58,533:INFO:   Num examples = 4290
2022-06-21 03:37:00,664:INFO: ***** Running training *****
2022-06-21 03:37:00,665:INFO:   Num examples = 48774
2022-06-21 03:37:00,665:INFO:   Batch size = 128
2022-06-21 03:37:00,665:INFO:   Num steps = 3810
2022-06-21 03:39:12,728:INFO: Effective parameters:
2022-06-21 03:39:12,728:INFO:   <<< batch_size: 128
2022-06-21 03:39:12,728:INFO:   <<< batch_size_val: 16
2022-06-21 03:39:12,728:INFO:   <<< cache_dir: 
2022-06-21 03:39:12,728:INFO:   <<< coef_lr: 0.001
2022-06-21 03:39:12,728:INFO:   <<< cross_model: cross-base
2022-06-21 03:39:12,728:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 03:39:12,728:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 03:39:12,728:INFO:   <<< datatype: msvd
2022-06-21 03:39:12,728:INFO:   <<< do_eval: False
2022-06-21 03:39:12,728:INFO:   <<< do_lower_case: False
2022-06-21 03:39:12,729:INFO:   <<< do_pretrain: False
2022-06-21 03:39:12,729:INFO:   <<< do_train: True
2022-06-21 03:39:12,729:INFO:   <<< epochs: 5
2022-06-21 03:39:12,729:INFO:   <<< eval_frame_order: 0
2022-06-21 03:39:12,729:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 03:39:12,729:INFO:   <<< feature_framerate: 1
2022-06-21 03:39:12,729:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 03:39:12,729:INFO:   <<< fp16: False
2022-06-21 03:39:12,729:INFO:   <<< fp16_opt_level: O1
2022-06-21 03:39:12,729:INFO:   <<< freeze_layer_num: 0
2022-06-21 03:39:12,729:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 03:39:12,729:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 03:39:12,729:INFO:   <<< init_model: None
2022-06-21 03:39:12,729:INFO:   <<< linear_patch: 3d
2022-06-21 03:39:12,729:INFO:   <<< local_rank: 0
2022-06-21 03:39:12,730:INFO:   <<< loose_type: True
2022-06-21 03:39:12,730:INFO:   <<< lr: 0.0001
2022-06-21 03:39:12,730:INFO:   <<< lr_decay: 0.9
2022-06-21 03:39:12,730:INFO:   <<< margin: 0.1
2022-06-21 03:39:12,730:INFO:   <<< max_frames: 16
2022-06-21 03:39:12,730:INFO:   <<< max_words: 32
2022-06-21 03:39:12,730:INFO:   <<< n_display: 50
2022-06-21 03:39:12,730:INFO:   <<< n_gpu: 1
2022-06-21 03:39:12,730:INFO:   <<< n_pair: 1
2022-06-21 03:39:12,730:INFO:   <<< negative_weighting: 1
2022-06-21 03:39:12,730:INFO:   <<< num_thread_reader: 2
2022-06-21 03:39:12,730:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 03:39:12,730:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 03:39:12,730:INFO:   <<< rank: 0
2022-06-21 03:39:12,731:INFO:   <<< resume_model: None
2022-06-21 03:39:12,731:INFO:   <<< sampled_use_mil: False
2022-06-21 03:39:12,731:INFO:   <<< seed: 42
2022-06-21 03:39:12,731:INFO:   <<< sim_header: meanP
2022-06-21 03:39:12,731:INFO:   <<< slice_framepos: 2
2022-06-21 03:39:12,731:INFO:   <<< task_type: retrieval
2022-06-21 03:39:12,731:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 03:39:12,731:INFO:   <<< train_csv: data/.train.csv
2022-06-21 03:39:12,731:INFO:   <<< train_frame_order: 0
2022-06-21 03:39:12,731:INFO:   <<< use_mil: False
2022-06-21 03:39:12,731:INFO:   <<< val_csv: data/.val.csv
2022-06-21 03:39:12,731:INFO:   <<< video_dim: 1024
2022-06-21 03:39:12,731:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 03:39:12,731:INFO:   <<< warmup_proportion: 0.1
2022-06-21 03:39:12,731:INFO:   <<< world_size: 1
2022-06-21 03:39:12,731:INFO: device: cuda:0 n_gpu: 2
2022-06-21 03:39:13,426:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 03:39:13,427:WARNING: Test retrieval by loose type.
2022-06-21 03:39:13,427:WARNING: 	 embed_dim: 512
2022-06-21 03:39:13,427:WARNING: 	 image_resolution: 224
2022-06-21 03:39:13,427:WARNING: 	 vision_layers: 12
2022-06-21 03:39:13,427:WARNING: 	 vision_width: 768
2022-06-21 03:39:13,427:WARNING: 	 vision_patch_size: 32
2022-06-21 03:39:13,427:WARNING: 	 context_length: 77
2022-06-21 03:39:13,427:WARNING: 	 vocab_size: 49408
2022-06-21 03:39:13,427:WARNING: 	 transformer_width: 512
2022-06-21 03:39:13,427:WARNING: 	 transformer_heads: 8
2022-06-21 03:39:13,427:WARNING: 	 transformer_layers: 12
2022-06-21 03:39:13,428:WARNING: 		 linear_patch: 3d
2022-06-21 03:39:13,428:WARNING: 	 cut_top_layer: 0
2022-06-21 03:39:20,710:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 03:39:30,398:INFO: ***** Running test *****
2022-06-21 03:39:30,399:INFO:   Num examples = 27763
2022-06-21 03:39:30,399:INFO:   Batch size = 16
2022-06-21 03:39:30,399:INFO:   Num steps = 1736
2022-06-21 03:39:30,399:INFO: ***** Running val *****
2022-06-21 03:39:30,399:INFO:   Num examples = 4290
2022-06-21 03:39:31,162:INFO: ***** Running training *****
2022-06-21 03:39:31,162:INFO:   Num examples = 48774
2022-06-21 03:39:31,162:INFO:   Batch size = 128
2022-06-21 03:39:31,162:INFO:   Num steps = 3810
2022-06-21 03:51:23,983:INFO: Effective parameters:
2022-06-21 03:51:23,983:INFO:   <<< batch_size: 128
2022-06-21 03:51:23,983:INFO:   <<< batch_size_val: 16
2022-06-21 03:51:23,984:INFO:   <<< cache_dir: 
2022-06-21 03:51:23,984:INFO:   <<< coef_lr: 0.001
2022-06-21 03:51:23,984:INFO:   <<< cross_model: cross-base
2022-06-21 03:51:23,984:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 03:51:23,984:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 03:51:23,984:INFO:   <<< datatype: msvd
2022-06-21 03:51:23,984:INFO:   <<< do_eval: False
2022-06-21 03:51:23,984:INFO:   <<< do_lower_case: False
2022-06-21 03:51:23,984:INFO:   <<< do_pretrain: False
2022-06-21 03:51:23,984:INFO:   <<< do_train: True
2022-06-21 03:51:23,984:INFO:   <<< epochs: 5
2022-06-21 03:51:23,984:INFO:   <<< eval_frame_order: 0
2022-06-21 03:51:23,984:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 03:51:23,984:INFO:   <<< feature_framerate: 1
2022-06-21 03:51:23,984:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 03:51:23,984:INFO:   <<< fp16: False
2022-06-21 03:51:23,984:INFO:   <<< fp16_opt_level: O1
2022-06-21 03:51:23,984:INFO:   <<< freeze_layer_num: 0
2022-06-21 03:51:23,984:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 03:51:23,984:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 03:51:23,984:INFO:   <<< init_model: None
2022-06-21 03:51:23,984:INFO:   <<< linear_patch: 3d
2022-06-21 03:51:23,984:INFO:   <<< local_rank: 0
2022-06-21 03:51:23,984:INFO:   <<< loose_type: True
2022-06-21 03:51:23,984:INFO:   <<< lr: 0.0001
2022-06-21 03:51:23,984:INFO:   <<< lr_decay: 0.9
2022-06-21 03:51:23,984:INFO:   <<< margin: 0.1
2022-06-21 03:51:23,984:INFO:   <<< max_frames: 16
2022-06-21 03:51:23,984:INFO:   <<< max_words: 32
2022-06-21 03:51:23,984:INFO:   <<< n_display: 50
2022-06-21 03:51:23,985:INFO:   <<< n_gpu: 1
2022-06-21 03:51:23,985:INFO:   <<< n_pair: 1
2022-06-21 03:51:23,985:INFO:   <<< negative_weighting: 1
2022-06-21 03:51:23,985:INFO:   <<< num_thread_reader: 2
2022-06-21 03:51:23,985:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 03:51:23,985:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 03:51:23,985:INFO:   <<< rank: 0
2022-06-21 03:51:23,985:INFO:   <<< resume_model: None
2022-06-21 03:51:23,985:INFO:   <<< sampled_use_mil: False
2022-06-21 03:51:23,985:INFO:   <<< seed: 42
2022-06-21 03:51:23,985:INFO:   <<< sim_header: meanP
2022-06-21 03:51:23,985:INFO:   <<< slice_framepos: 2
2022-06-21 03:51:23,985:INFO:   <<< task_type: retrieval
2022-06-21 03:51:23,985:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 03:51:23,985:INFO:   <<< train_csv: data/.train.csv
2022-06-21 03:51:23,985:INFO:   <<< train_frame_order: 0
2022-06-21 03:51:23,985:INFO:   <<< use_mil: False
2022-06-21 03:51:23,985:INFO:   <<< val_csv: data/.val.csv
2022-06-21 03:51:23,985:INFO:   <<< video_dim: 1024
2022-06-21 03:51:23,985:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 03:51:23,985:INFO:   <<< warmup_proportion: 0.1
2022-06-21 03:51:23,985:INFO:   <<< world_size: 1
2022-06-21 03:51:23,985:INFO: device: cuda:0 n_gpu: 2
2022-06-21 03:51:24,724:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 03:51:24,724:WARNING: Test retrieval by loose type.
2022-06-21 03:51:24,725:WARNING: 	 embed_dim: 512
2022-06-21 03:51:24,725:WARNING: 	 image_resolution: 224
2022-06-21 03:51:24,725:WARNING: 	 vision_layers: 12
2022-06-21 03:51:24,725:WARNING: 	 vision_width: 768
2022-06-21 03:51:24,725:WARNING: 	 vision_patch_size: 32
2022-06-21 03:51:24,725:WARNING: 	 context_length: 77
2022-06-21 03:51:24,725:WARNING: 	 vocab_size: 49408
2022-06-21 03:51:24,725:WARNING: 	 transformer_width: 512
2022-06-21 03:51:24,725:WARNING: 	 transformer_heads: 8
2022-06-21 03:51:24,725:WARNING: 	 transformer_layers: 12
2022-06-21 03:51:24,725:WARNING: 		 linear_patch: 3d
2022-06-21 03:51:24,725:WARNING: 	 cut_top_layer: 0
2022-06-21 03:51:32,013:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 03:51:46,141:INFO: ***** Running test *****
2022-06-21 03:51:46,141:INFO:   Num examples = 27763
2022-06-21 03:51:46,141:INFO:   Batch size = 16
2022-06-21 03:51:46,141:INFO:   Num steps = 1736
2022-06-21 03:51:46,142:INFO: ***** Running val *****
2022-06-21 03:51:46,142:INFO:   Num examples = 4290
2022-06-21 03:51:48,431:INFO: ***** Running training *****
2022-06-21 03:51:48,431:INFO:   Num examples = 48774
2022-06-21 03:51:48,431:INFO:   Batch size = 128
2022-06-21 03:51:48,431:INFO:   Num steps = 3810
2022-06-21 03:54:08,639:INFO: Effective parameters:
2022-06-21 03:54:08,639:INFO:   <<< batch_size: 128
2022-06-21 03:54:08,639:INFO:   <<< batch_size_val: 16
2022-06-21 03:54:08,639:INFO:   <<< cache_dir: 
2022-06-21 03:54:08,639:INFO:   <<< coef_lr: 0.001
2022-06-21 03:54:08,640:INFO:   <<< cross_model: cross-base
2022-06-21 03:54:08,640:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 03:54:08,640:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 03:54:08,640:INFO:   <<< datatype: msvd
2022-06-21 03:54:08,640:INFO:   <<< do_eval: False
2022-06-21 03:54:08,640:INFO:   <<< do_lower_case: False
2022-06-21 03:54:08,640:INFO:   <<< do_pretrain: False
2022-06-21 03:54:08,640:INFO:   <<< do_train: True
2022-06-21 03:54:08,640:INFO:   <<< epochs: 5
2022-06-21 03:54:08,640:INFO:   <<< eval_frame_order: 0
2022-06-21 03:54:08,640:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 03:54:08,640:INFO:   <<< feature_framerate: 1
2022-06-21 03:54:08,640:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 03:54:08,640:INFO:   <<< fp16: False
2022-06-21 03:54:08,640:INFO:   <<< fp16_opt_level: O1
2022-06-21 03:54:08,641:INFO:   <<< freeze_layer_num: 0
2022-06-21 03:54:08,641:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 03:54:08,641:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 03:54:08,641:INFO:   <<< init_model: None
2022-06-21 03:54:08,641:INFO:   <<< linear_patch: 3d
2022-06-21 03:54:08,641:INFO:   <<< local_rank: 0
2022-06-21 03:54:08,641:INFO:   <<< loose_type: True
2022-06-21 03:54:08,641:INFO:   <<< lr: 0.0001
2022-06-21 03:54:08,641:INFO:   <<< lr_decay: 0.9
2022-06-21 03:54:08,641:INFO:   <<< margin: 0.1
2022-06-21 03:54:08,641:INFO:   <<< max_frames: 16
2022-06-21 03:54:08,641:INFO:   <<< max_words: 32
2022-06-21 03:54:08,641:INFO:   <<< n_display: 50
2022-06-21 03:54:08,641:INFO:   <<< n_gpu: 1
2022-06-21 03:54:08,642:INFO:   <<< n_pair: 1
2022-06-21 03:54:08,642:INFO:   <<< negative_weighting: 1
2022-06-21 03:54:08,642:INFO:   <<< num_thread_reader: 2
2022-06-21 03:54:08,642:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 03:54:08,642:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 03:54:08,642:INFO:   <<< rank: 0
2022-06-21 03:54:08,642:INFO:   <<< resume_model: None
2022-06-21 03:54:08,642:INFO:   <<< sampled_use_mil: False
2022-06-21 03:54:08,642:INFO:   <<< seed: 42
2022-06-21 03:54:08,642:INFO:   <<< sim_header: meanP
2022-06-21 03:54:08,642:INFO:   <<< slice_framepos: 2
2022-06-21 03:54:08,642:INFO:   <<< task_type: retrieval
2022-06-21 03:54:08,642:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 03:54:08,642:INFO:   <<< train_csv: data/.train.csv
2022-06-21 03:54:08,642:INFO:   <<< train_frame_order: 0
2022-06-21 03:54:08,642:INFO:   <<< use_mil: False
2022-06-21 03:54:08,643:INFO:   <<< val_csv: data/.val.csv
2022-06-21 03:54:08,643:INFO:   <<< video_dim: 1024
2022-06-21 03:54:08,643:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 03:54:08,643:INFO:   <<< warmup_proportion: 0.1
2022-06-21 03:54:08,643:INFO:   <<< world_size: 1
2022-06-21 03:54:08,643:INFO: device: cuda:0 n_gpu: 2
2022-06-21 03:54:09,362:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 03:54:09,363:WARNING: Test retrieval by loose type.
2022-06-21 03:54:09,363:WARNING: 	 embed_dim: 512
2022-06-21 03:54:09,363:WARNING: 	 image_resolution: 224
2022-06-21 03:54:09,363:WARNING: 	 vision_layers: 12
2022-06-21 03:54:09,363:WARNING: 	 vision_width: 768
2022-06-21 03:54:09,363:WARNING: 	 vision_patch_size: 32
2022-06-21 03:54:09,363:WARNING: 	 context_length: 77
2022-06-21 03:54:09,363:WARNING: 	 vocab_size: 49408
2022-06-21 03:54:09,363:WARNING: 	 transformer_width: 512
2022-06-21 03:54:09,363:WARNING: 	 transformer_heads: 8
2022-06-21 03:54:09,363:WARNING: 	 transformer_layers: 12
2022-06-21 03:54:09,363:WARNING: 		 linear_patch: 3d
2022-06-21 03:54:09,363:WARNING: 	 cut_top_layer: 0
2022-06-21 03:54:16,452:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 03:54:26,456:INFO: ***** Running test *****
2022-06-21 03:54:26,456:INFO:   Num examples = 27763
2022-06-21 03:54:26,456:INFO:   Batch size = 16
2022-06-21 03:54:26,456:INFO:   Num steps = 1736
2022-06-21 03:54:26,457:INFO: ***** Running val *****
2022-06-21 03:54:26,457:INFO:   Num examples = 4290
2022-06-21 03:54:28,395:INFO: ***** Running training *****
2022-06-21 03:54:28,395:INFO:   Num examples = 48774
2022-06-21 03:54:28,395:INFO:   Batch size = 128
2022-06-21 03:54:28,395:INFO:   Num steps = 3810
2022-06-21 03:58:17,407:INFO: Effective parameters:
2022-06-21 03:58:17,407:INFO:   <<< batch_size: 128
2022-06-21 03:58:17,407:INFO:   <<< batch_size_val: 16
2022-06-21 03:58:17,407:INFO:   <<< cache_dir: 
2022-06-21 03:58:17,407:INFO:   <<< coef_lr: 0.001
2022-06-21 03:58:17,407:INFO:   <<< cross_model: cross-base
2022-06-21 03:58:17,407:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 03:58:17,407:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 03:58:17,407:INFO:   <<< datatype: msvd
2022-06-21 03:58:17,407:INFO:   <<< do_eval: False
2022-06-21 03:58:17,407:INFO:   <<< do_lower_case: False
2022-06-21 03:58:17,407:INFO:   <<< do_pretrain: False
2022-06-21 03:58:17,407:INFO:   <<< do_train: True
2022-06-21 03:58:17,407:INFO:   <<< epochs: 5
2022-06-21 03:58:17,407:INFO:   <<< eval_frame_order: 0
2022-06-21 03:58:17,407:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 03:58:17,407:INFO:   <<< feature_framerate: 1
2022-06-21 03:58:17,407:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 03:58:17,407:INFO:   <<< fp16: False
2022-06-21 03:58:17,407:INFO:   <<< fp16_opt_level: O1
2022-06-21 03:58:17,408:INFO:   <<< freeze_layer_num: 0
2022-06-21 03:58:17,408:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 03:58:17,408:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 03:58:17,408:INFO:   <<< init_model: None
2022-06-21 03:58:17,408:INFO:   <<< linear_patch: 3d
2022-06-21 03:58:17,408:INFO:   <<< local_rank: 0
2022-06-21 03:58:17,408:INFO:   <<< loose_type: True
2022-06-21 03:58:17,408:INFO:   <<< lr: 0.0001
2022-06-21 03:58:17,408:INFO:   <<< lr_decay: 0.9
2022-06-21 03:58:17,408:INFO:   <<< margin: 0.1
2022-06-21 03:58:17,408:INFO:   <<< max_frames: 16
2022-06-21 03:58:17,408:INFO:   <<< max_words: 32
2022-06-21 03:58:17,408:INFO:   <<< n_display: 50
2022-06-21 03:58:17,408:INFO:   <<< n_gpu: 1
2022-06-21 03:58:17,408:INFO:   <<< n_pair: 1
2022-06-21 03:58:17,408:INFO:   <<< negative_weighting: 1
2022-06-21 03:58:17,408:INFO:   <<< num_thread_reader: 2
2022-06-21 03:58:17,408:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 03:58:17,408:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 03:58:17,408:INFO:   <<< rank: 0
2022-06-21 03:58:17,408:INFO:   <<< resume_model: None
2022-06-21 03:58:17,408:INFO:   <<< sampled_use_mil: False
2022-06-21 03:58:17,408:INFO:   <<< seed: 42
2022-06-21 03:58:17,408:INFO:   <<< sim_header: meanP
2022-06-21 03:58:17,408:INFO:   <<< slice_framepos: 2
2022-06-21 03:58:17,408:INFO:   <<< task_type: retrieval
2022-06-21 03:58:17,408:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 03:58:17,408:INFO:   <<< train_csv: data/.train.csv
2022-06-21 03:58:17,408:INFO:   <<< train_frame_order: 0
2022-06-21 03:58:17,408:INFO:   <<< use_mil: False
2022-06-21 03:58:17,409:INFO:   <<< val_csv: data/.val.csv
2022-06-21 03:58:17,409:INFO:   <<< video_dim: 1024
2022-06-21 03:58:17,409:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 03:58:17,409:INFO:   <<< warmup_proportion: 0.1
2022-06-21 03:58:17,409:INFO:   <<< world_size: 1
2022-06-21 03:58:17,409:INFO: device: cuda:0 n_gpu: 2
2022-06-21 03:58:18,335:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 03:58:18,336:WARNING: Test retrieval by loose type.
2022-06-21 03:58:18,336:WARNING: 	 embed_dim: 512
2022-06-21 03:58:18,336:WARNING: 	 image_resolution: 224
2022-06-21 03:58:18,336:WARNING: 	 vision_layers: 12
2022-06-21 03:58:18,336:WARNING: 	 vision_width: 768
2022-06-21 03:58:18,336:WARNING: 	 vision_patch_size: 32
2022-06-21 03:58:18,336:WARNING: 	 context_length: 77
2022-06-21 03:58:18,336:WARNING: 	 vocab_size: 49408
2022-06-21 03:58:18,336:WARNING: 	 transformer_width: 512
2022-06-21 03:58:18,336:WARNING: 	 transformer_heads: 8
2022-06-21 03:58:18,336:WARNING: 	 transformer_layers: 12
2022-06-21 03:58:18,337:WARNING: 		 linear_patch: 3d
2022-06-21 03:58:18,337:WARNING: 	 cut_top_layer: 0
2022-06-21 03:58:25,549:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 03:58:39,724:INFO: ***** Running test *****
2022-06-21 03:58:39,724:INFO:   Num examples = 27763
2022-06-21 03:58:39,724:INFO:   Batch size = 16
2022-06-21 03:58:39,724:INFO:   Num steps = 1736
2022-06-21 03:58:39,724:INFO: ***** Running val *****
2022-06-21 03:58:39,724:INFO:   Num examples = 4290
2022-06-21 03:58:40,680:INFO: ***** Running training *****
2022-06-21 03:58:40,681:INFO:   Num examples = 48774
2022-06-21 03:58:40,681:INFO:   Batch size = 128
2022-06-21 03:58:40,681:INFO:   Num steps = 3810
2022-06-21 04:02:21,495:INFO: Effective parameters:
2022-06-21 04:02:21,496:INFO:   <<< batch_size: 128
2022-06-21 04:02:21,496:INFO:   <<< batch_size_val: 16
2022-06-21 04:02:21,496:INFO:   <<< cache_dir: 
2022-06-21 04:02:21,496:INFO:   <<< coef_lr: 0.001
2022-06-21 04:02:21,496:INFO:   <<< cross_model: cross-base
2022-06-21 04:02:21,496:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:02:21,496:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:02:21,496:INFO:   <<< datatype: msvd
2022-06-21 04:02:21,496:INFO:   <<< do_eval: False
2022-06-21 04:02:21,496:INFO:   <<< do_lower_case: False
2022-06-21 04:02:21,496:INFO:   <<< do_pretrain: False
2022-06-21 04:02:21,496:INFO:   <<< do_train: True
2022-06-21 04:02:21,497:INFO:   <<< epochs: 5
2022-06-21 04:02:21,497:INFO:   <<< eval_frame_order: 0
2022-06-21 04:02:21,497:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:02:21,497:INFO:   <<< feature_framerate: 1
2022-06-21 04:02:21,497:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:02:21,497:INFO:   <<< fp16: False
2022-06-21 04:02:21,497:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:02:21,497:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:02:21,497:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:02:21,497:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:02:21,497:INFO:   <<< init_model: None
2022-06-21 04:02:21,497:INFO:   <<< linear_patch: 3d
2022-06-21 04:02:21,497:INFO:   <<< local_rank: 0
2022-06-21 04:02:21,497:INFO:   <<< loose_type: True
2022-06-21 04:02:21,497:INFO:   <<< lr: 0.0001
2022-06-21 04:02:21,497:INFO:   <<< lr_decay: 0.9
2022-06-21 04:02:21,498:INFO:   <<< margin: 0.1
2022-06-21 04:02:21,498:INFO:   <<< max_frames: 16
2022-06-21 04:02:21,498:INFO:   <<< max_words: 32
2022-06-21 04:02:21,498:INFO:   <<< n_display: 50
2022-06-21 04:02:21,498:INFO:   <<< n_gpu: 1
2022-06-21 04:02:21,498:INFO:   <<< n_pair: 1
2022-06-21 04:02:21,498:INFO:   <<< negative_weighting: 1
2022-06-21 04:02:21,498:INFO:   <<< num_thread_reader: 2
2022-06-21 04:02:21,498:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:02:21,498:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:02:21,498:INFO:   <<< rank: 0
2022-06-21 04:02:21,498:INFO:   <<< resume_model: None
2022-06-21 04:02:21,498:INFO:   <<< sampled_use_mil: False
2022-06-21 04:02:21,498:INFO:   <<< seed: 42
2022-06-21 04:02:21,498:INFO:   <<< sim_header: meanP
2022-06-21 04:02:21,498:INFO:   <<< slice_framepos: 2
2022-06-21 04:02:21,498:INFO:   <<< task_type: retrieval
2022-06-21 04:02:21,499:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:02:21,499:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:02:21,499:INFO:   <<< train_frame_order: 0
2022-06-21 04:02:21,499:INFO:   <<< use_mil: False
2022-06-21 04:02:21,499:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:02:21,499:INFO:   <<< video_dim: 1024
2022-06-21 04:02:21,499:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:02:21,499:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:02:21,499:INFO:   <<< world_size: 1
2022-06-21 04:02:21,499:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:02:22,323:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:02:22,323:WARNING: Test retrieval by loose type.
2022-06-21 04:02:22,324:WARNING: 	 embed_dim: 512
2022-06-21 04:02:22,324:WARNING: 	 image_resolution: 224
2022-06-21 04:02:22,324:WARNING: 	 vision_layers: 12
2022-06-21 04:02:22,324:WARNING: 	 vision_width: 768
2022-06-21 04:02:22,324:WARNING: 	 vision_patch_size: 32
2022-06-21 04:02:22,324:WARNING: 	 context_length: 77
2022-06-21 04:02:22,324:WARNING: 	 vocab_size: 49408
2022-06-21 04:02:22,324:WARNING: 	 transformer_width: 512
2022-06-21 04:02:22,324:WARNING: 	 transformer_heads: 8
2022-06-21 04:02:22,324:WARNING: 	 transformer_layers: 12
2022-06-21 04:02:22,324:WARNING: 		 linear_patch: 3d
2022-06-21 04:02:22,324:WARNING: 	 cut_top_layer: 0
2022-06-21 04:02:29,711:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:02:40,584:INFO: ***** Running test *****
2022-06-21 04:02:40,584:INFO:   Num examples = 27763
2022-06-21 04:02:40,584:INFO:   Batch size = 16
2022-06-21 04:02:40,584:INFO:   Num steps = 1736
2022-06-21 04:02:40,584:INFO: ***** Running val *****
2022-06-21 04:02:40,584:INFO:   Num examples = 4290
2022-06-21 04:02:41,374:INFO: ***** Running training *****
2022-06-21 04:02:41,374:INFO:   Num examples = 48774
2022-06-21 04:02:41,374:INFO:   Batch size = 128
2022-06-21 04:02:41,374:INFO:   Num steps = 3810
2022-06-21 04:04:39,393:INFO: Effective parameters:
2022-06-21 04:04:39,393:INFO:   <<< batch_size: 128
2022-06-21 04:04:39,393:INFO:   <<< batch_size_val: 16
2022-06-21 04:04:39,393:INFO:   <<< cache_dir: 
2022-06-21 04:04:39,393:INFO:   <<< coef_lr: 0.001
2022-06-21 04:04:39,393:INFO:   <<< cross_model: cross-base
2022-06-21 04:04:39,394:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:04:39,394:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:04:39,394:INFO:   <<< datatype: msvd
2022-06-21 04:04:39,394:INFO:   <<< do_eval: False
2022-06-21 04:04:39,394:INFO:   <<< do_lower_case: False
2022-06-21 04:04:39,394:INFO:   <<< do_pretrain: False
2022-06-21 04:04:39,394:INFO:   <<< do_train: True
2022-06-21 04:04:39,394:INFO:   <<< epochs: 5
2022-06-21 04:04:39,394:INFO:   <<< eval_frame_order: 0
2022-06-21 04:04:39,394:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:04:39,394:INFO:   <<< feature_framerate: 1
2022-06-21 04:04:39,394:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:04:39,394:INFO:   <<< fp16: False
2022-06-21 04:04:39,394:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:04:39,395:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:04:39,395:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:04:39,395:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:04:39,395:INFO:   <<< init_model: None
2022-06-21 04:04:39,395:INFO:   <<< linear_patch: 3d
2022-06-21 04:04:39,395:INFO:   <<< local_rank: 0
2022-06-21 04:04:39,395:INFO:   <<< loose_type: True
2022-06-21 04:04:39,395:INFO:   <<< lr: 0.0001
2022-06-21 04:04:39,395:INFO:   <<< lr_decay: 0.9
2022-06-21 04:04:39,395:INFO:   <<< margin: 0.1
2022-06-21 04:04:39,395:INFO:   <<< max_frames: 16
2022-06-21 04:04:39,395:INFO:   <<< max_words: 32
2022-06-21 04:04:39,395:INFO:   <<< n_display: 50
2022-06-21 04:04:39,395:INFO:   <<< n_gpu: 1
2022-06-21 04:04:39,396:INFO:   <<< n_pair: 1
2022-06-21 04:04:39,396:INFO:   <<< negative_weighting: 1
2022-06-21 04:04:39,396:INFO:   <<< num_thread_reader: 2
2022-06-21 04:04:39,396:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:04:39,396:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:04:39,396:INFO:   <<< rank: 0
2022-06-21 04:04:39,396:INFO:   <<< resume_model: None
2022-06-21 04:04:39,396:INFO:   <<< sampled_use_mil: False
2022-06-21 04:04:39,396:INFO:   <<< seed: 42
2022-06-21 04:04:39,396:INFO:   <<< sim_header: meanP
2022-06-21 04:04:39,396:INFO:   <<< slice_framepos: 2
2022-06-21 04:04:39,396:INFO:   <<< task_type: retrieval
2022-06-21 04:04:39,396:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:04:39,396:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:04:39,397:INFO:   <<< train_frame_order: 0
2022-06-21 04:04:39,397:INFO:   <<< use_mil: False
2022-06-21 04:04:39,397:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:04:39,397:INFO:   <<< video_dim: 1024
2022-06-21 04:04:39,397:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:04:39,397:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:04:39,397:INFO:   <<< world_size: 1
2022-06-21 04:04:39,397:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:04:40,192:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:04:40,192:WARNING: Test retrieval by loose type.
2022-06-21 04:04:40,193:WARNING: 	 embed_dim: 512
2022-06-21 04:04:40,193:WARNING: 	 image_resolution: 224
2022-06-21 04:04:40,193:WARNING: 	 vision_layers: 12
2022-06-21 04:04:40,193:WARNING: 	 vision_width: 768
2022-06-21 04:04:40,193:WARNING: 	 vision_patch_size: 32
2022-06-21 04:04:40,193:WARNING: 	 context_length: 77
2022-06-21 04:04:40,193:WARNING: 	 vocab_size: 49408
2022-06-21 04:04:40,193:WARNING: 	 transformer_width: 512
2022-06-21 04:04:40,193:WARNING: 	 transformer_heads: 8
2022-06-21 04:04:40,193:WARNING: 	 transformer_layers: 12
2022-06-21 04:04:40,193:WARNING: 		 linear_patch: 3d
2022-06-21 04:04:40,193:WARNING: 	 cut_top_layer: 0
2022-06-21 04:04:47,721:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:05:00,329:INFO: ***** Running test *****
2022-06-21 04:05:00,329:INFO:   Num examples = 27763
2022-06-21 04:05:00,329:INFO:   Batch size = 16
2022-06-21 04:05:00,329:INFO:   Num steps = 1736
2022-06-21 04:05:00,329:INFO: ***** Running val *****
2022-06-21 04:05:00,329:INFO:   Num examples = 4290
2022-06-21 04:05:02,571:INFO: ***** Running training *****
2022-06-21 04:05:02,572:INFO:   Num examples = 48774
2022-06-21 04:05:02,572:INFO:   Batch size = 128
2022-06-21 04:05:02,572:INFO:   Num steps = 3810
2022-06-21 04:06:40,878:INFO: Effective parameters:
2022-06-21 04:06:40,878:INFO:   <<< batch_size: 128
2022-06-21 04:06:40,878:INFO:   <<< batch_size_val: 16
2022-06-21 04:06:40,878:INFO:   <<< cache_dir: 
2022-06-21 04:06:40,878:INFO:   <<< coef_lr: 0.001
2022-06-21 04:06:40,878:INFO:   <<< cross_model: cross-base
2022-06-21 04:06:40,878:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:06:40,878:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:06:40,878:INFO:   <<< datatype: msvd
2022-06-21 04:06:40,878:INFO:   <<< do_eval: False
2022-06-21 04:06:40,878:INFO:   <<< do_lower_case: False
2022-06-21 04:06:40,878:INFO:   <<< do_pretrain: False
2022-06-21 04:06:40,879:INFO:   <<< do_train: True
2022-06-21 04:06:40,879:INFO:   <<< epochs: 5
2022-06-21 04:06:40,879:INFO:   <<< eval_frame_order: 0
2022-06-21 04:06:40,879:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:06:40,879:INFO:   <<< feature_framerate: 1
2022-06-21 04:06:40,879:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:06:40,879:INFO:   <<< fp16: False
2022-06-21 04:06:40,879:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:06:40,879:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:06:40,879:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:06:40,879:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:06:40,879:INFO:   <<< init_model: None
2022-06-21 04:06:40,879:INFO:   <<< linear_patch: 3d
2022-06-21 04:06:40,879:INFO:   <<< local_rank: 0
2022-06-21 04:06:40,879:INFO:   <<< loose_type: True
2022-06-21 04:06:40,879:INFO:   <<< lr: 0.0001
2022-06-21 04:06:40,879:INFO:   <<< lr_decay: 0.9
2022-06-21 04:06:40,879:INFO:   <<< margin: 0.1
2022-06-21 04:06:40,879:INFO:   <<< max_frames: 16
2022-06-21 04:06:40,879:INFO:   <<< max_words: 32
2022-06-21 04:06:40,879:INFO:   <<< n_display: 50
2022-06-21 04:06:40,879:INFO:   <<< n_gpu: 1
2022-06-21 04:06:40,879:INFO:   <<< n_pair: 1
2022-06-21 04:06:40,879:INFO:   <<< negative_weighting: 1
2022-06-21 04:06:40,879:INFO:   <<< num_thread_reader: 2
2022-06-21 04:06:40,879:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:06:40,879:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:06:40,879:INFO:   <<< rank: 0
2022-06-21 04:06:40,880:INFO:   <<< resume_model: None
2022-06-21 04:06:40,880:INFO:   <<< sampled_use_mil: False
2022-06-21 04:06:40,880:INFO:   <<< seed: 42
2022-06-21 04:06:40,880:INFO:   <<< sim_header: meanP
2022-06-21 04:06:40,880:INFO:   <<< slice_framepos: 2
2022-06-21 04:06:40,880:INFO:   <<< task_type: retrieval
2022-06-21 04:06:40,880:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:06:40,880:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:06:40,880:INFO:   <<< train_frame_order: 0
2022-06-21 04:06:40,880:INFO:   <<< use_mil: False
2022-06-21 04:06:40,880:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:06:40,880:INFO:   <<< video_dim: 1024
2022-06-21 04:06:40,880:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:06:40,880:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:06:40,880:INFO:   <<< world_size: 1
2022-06-21 04:06:40,880:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:06:41,568:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:06:41,568:WARNING: Test retrieval by loose type.
2022-06-21 04:06:41,569:WARNING: 	 embed_dim: 512
2022-06-21 04:06:41,569:WARNING: 	 image_resolution: 224
2022-06-21 04:06:41,569:WARNING: 	 vision_layers: 12
2022-06-21 04:06:41,569:WARNING: 	 vision_width: 768
2022-06-21 04:06:41,569:WARNING: 	 vision_patch_size: 32
2022-06-21 04:06:41,569:WARNING: 	 context_length: 77
2022-06-21 04:06:41,569:WARNING: 	 vocab_size: 49408
2022-06-21 04:06:41,569:WARNING: 	 transformer_width: 512
2022-06-21 04:06:41,569:WARNING: 	 transformer_heads: 8
2022-06-21 04:06:41,569:WARNING: 	 transformer_layers: 12
2022-06-21 04:06:41,569:WARNING: 		 linear_patch: 3d
2022-06-21 04:06:41,569:WARNING: 	 cut_top_layer: 0
2022-06-21 04:06:48,986:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:07:00,496:INFO: ***** Running test *****
2022-06-21 04:07:00,496:INFO:   Num examples = 27763
2022-06-21 04:07:00,496:INFO:   Batch size = 16
2022-06-21 04:07:00,496:INFO:   Num steps = 1736
2022-06-21 04:07:00,496:INFO: ***** Running val *****
2022-06-21 04:07:00,496:INFO:   Num examples = 4290
2022-06-21 04:07:01,267:INFO: ***** Running training *****
2022-06-21 04:07:01,267:INFO:   Num examples = 48774
2022-06-21 04:07:01,267:INFO:   Batch size = 128
2022-06-21 04:07:01,267:INFO:   Num steps = 3810
2022-06-21 04:12:21,937:INFO: Effective parameters:
2022-06-21 04:12:21,937:INFO:   <<< batch_size: 128
2022-06-21 04:12:21,937:INFO:   <<< batch_size_val: 16
2022-06-21 04:12:21,937:INFO:   <<< cache_dir: 
2022-06-21 04:12:21,937:INFO:   <<< coef_lr: 0.001
2022-06-21 04:12:21,937:INFO:   <<< cross_model: cross-base
2022-06-21 04:12:21,938:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:12:21,938:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:12:21,938:INFO:   <<< datatype: msvd
2022-06-21 04:12:21,938:INFO:   <<< do_eval: False
2022-06-21 04:12:21,938:INFO:   <<< do_lower_case: False
2022-06-21 04:12:21,938:INFO:   <<< do_pretrain: False
2022-06-21 04:12:21,938:INFO:   <<< do_train: True
2022-06-21 04:12:21,938:INFO:   <<< epochs: 5
2022-06-21 04:12:21,938:INFO:   <<< eval_frame_order: 0
2022-06-21 04:12:21,938:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:12:21,938:INFO:   <<< feature_framerate: 1
2022-06-21 04:12:21,938:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:12:21,938:INFO:   <<< fp16: False
2022-06-21 04:12:21,938:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:12:21,939:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:12:21,939:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:12:21,939:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:12:21,939:INFO:   <<< init_model: None
2022-06-21 04:12:21,939:INFO:   <<< linear_patch: 3d
2022-06-21 04:12:21,939:INFO:   <<< local_rank: 0
2022-06-21 04:12:21,939:INFO:   <<< loose_type: True
2022-06-21 04:12:21,939:INFO:   <<< lr: 0.0001
2022-06-21 04:12:21,939:INFO:   <<< lr_decay: 0.9
2022-06-21 04:12:21,939:INFO:   <<< margin: 0.1
2022-06-21 04:12:21,939:INFO:   <<< max_frames: 16
2022-06-21 04:12:21,939:INFO:   <<< max_words: 32
2022-06-21 04:12:21,939:INFO:   <<< n_display: 50
2022-06-21 04:12:21,939:INFO:   <<< n_gpu: 1
2022-06-21 04:12:21,939:INFO:   <<< n_pair: 1
2022-06-21 04:12:21,939:INFO:   <<< negative_weighting: 1
2022-06-21 04:12:21,939:INFO:   <<< num_thread_reader: 2
2022-06-21 04:12:21,939:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:12:21,939:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:12:21,939:INFO:   <<< rank: 0
2022-06-21 04:12:21,940:INFO:   <<< resume_model: None
2022-06-21 04:12:21,940:INFO:   <<< sampled_use_mil: False
2022-06-21 04:12:21,940:INFO:   <<< seed: 42
2022-06-21 04:12:21,940:INFO:   <<< sim_header: meanP
2022-06-21 04:12:21,940:INFO:   <<< slice_framepos: 2
2022-06-21 04:12:21,940:INFO:   <<< task_type: retrieval
2022-06-21 04:12:21,940:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:12:21,940:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:12:21,940:INFO:   <<< train_frame_order: 0
2022-06-21 04:12:21,940:INFO:   <<< use_mil: False
2022-06-21 04:12:21,940:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:12:21,940:INFO:   <<< video_dim: 1024
2022-06-21 04:12:21,940:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:12:21,940:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:12:21,940:INFO:   <<< world_size: 1
2022-06-21 04:12:21,940:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:12:22,641:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:12:22,641:WARNING: Test retrieval by loose type.
2022-06-21 04:12:22,641:WARNING: 	 embed_dim: 512
2022-06-21 04:12:22,641:WARNING: 	 image_resolution: 224
2022-06-21 04:12:22,642:WARNING: 	 vision_layers: 12
2022-06-21 04:12:22,642:WARNING: 	 vision_width: 768
2022-06-21 04:12:22,642:WARNING: 	 vision_patch_size: 32
2022-06-21 04:12:22,642:WARNING: 	 context_length: 77
2022-06-21 04:12:22,642:WARNING: 	 vocab_size: 49408
2022-06-21 04:12:22,642:WARNING: 	 transformer_width: 512
2022-06-21 04:12:22,642:WARNING: 	 transformer_heads: 8
2022-06-21 04:12:22,642:WARNING: 	 transformer_layers: 12
2022-06-21 04:12:22,642:WARNING: 		 linear_patch: 3d
2022-06-21 04:12:22,642:WARNING: 	 cut_top_layer: 0
2022-06-21 04:12:29,791:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:12:40,422:INFO: ***** Running test *****
2022-06-21 04:12:40,422:INFO:   Num examples = 27763
2022-06-21 04:12:40,422:INFO:   Batch size = 16
2022-06-21 04:12:40,422:INFO:   Num steps = 1736
2022-06-21 04:12:40,422:INFO: ***** Running val *****
2022-06-21 04:12:40,422:INFO:   Num examples = 4290
2022-06-21 04:12:41,510:INFO: ***** Running training *****
2022-06-21 04:12:41,510:INFO:   Num examples = 48774
2022-06-21 04:12:41,510:INFO:   Batch size = 128
2022-06-21 04:12:41,510:INFO:   Num steps = 3810
2022-06-21 04:14:18,976:INFO: Effective parameters:
2022-06-21 04:14:18,976:INFO:   <<< batch_size: 128
2022-06-21 04:14:18,976:INFO:   <<< batch_size_val: 16
2022-06-21 04:14:18,976:INFO:   <<< cache_dir: 
2022-06-21 04:14:18,977:INFO:   <<< coef_lr: 0.001
2022-06-21 04:14:18,977:INFO:   <<< cross_model: cross-base
2022-06-21 04:14:18,977:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:14:18,977:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:14:18,977:INFO:   <<< datatype: msvd
2022-06-21 04:14:18,977:INFO:   <<< do_eval: False
2022-06-21 04:14:18,977:INFO:   <<< do_lower_case: False
2022-06-21 04:14:18,977:INFO:   <<< do_pretrain: False
2022-06-21 04:14:18,977:INFO:   <<< do_train: True
2022-06-21 04:14:18,977:INFO:   <<< epochs: 5
2022-06-21 04:14:18,977:INFO:   <<< eval_frame_order: 0
2022-06-21 04:14:18,977:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:14:18,977:INFO:   <<< feature_framerate: 1
2022-06-21 04:14:18,977:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:14:18,977:INFO:   <<< fp16: False
2022-06-21 04:14:18,977:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:14:18,977:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:14:18,977:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:14:18,977:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:14:18,977:INFO:   <<< init_model: None
2022-06-21 04:14:18,977:INFO:   <<< linear_patch: 3d
2022-06-21 04:14:18,977:INFO:   <<< local_rank: 0
2022-06-21 04:14:18,977:INFO:   <<< loose_type: True
2022-06-21 04:14:18,977:INFO:   <<< lr: 0.0001
2022-06-21 04:14:18,977:INFO:   <<< lr_decay: 0.9
2022-06-21 04:14:18,978:INFO:   <<< margin: 0.1
2022-06-21 04:14:18,978:INFO:   <<< max_frames: 16
2022-06-21 04:14:18,978:INFO:   <<< max_words: 32
2022-06-21 04:14:18,978:INFO:   <<< n_display: 50
2022-06-21 04:14:18,978:INFO:   <<< n_gpu: 1
2022-06-21 04:14:18,978:INFO:   <<< n_pair: 1
2022-06-21 04:14:18,978:INFO:   <<< negative_weighting: 1
2022-06-21 04:14:18,978:INFO:   <<< num_thread_reader: 2
2022-06-21 04:14:18,978:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:14:18,978:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:14:18,978:INFO:   <<< rank: 0
2022-06-21 04:14:18,978:INFO:   <<< resume_model: None
2022-06-21 04:14:18,978:INFO:   <<< sampled_use_mil: False
2022-06-21 04:14:18,978:INFO:   <<< seed: 42
2022-06-21 04:14:18,978:INFO:   <<< sim_header: meanP
2022-06-21 04:14:18,978:INFO:   <<< slice_framepos: 2
2022-06-21 04:14:18,978:INFO:   <<< task_type: retrieval
2022-06-21 04:14:18,978:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:14:18,978:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:14:18,978:INFO:   <<< train_frame_order: 0
2022-06-21 04:14:18,978:INFO:   <<< use_mil: False
2022-06-21 04:14:18,978:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:14:18,978:INFO:   <<< video_dim: 1024
2022-06-21 04:14:18,978:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:14:18,978:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:14:18,978:INFO:   <<< world_size: 1
2022-06-21 04:14:18,979:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:14:19,714:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:14:19,715:WARNING: Test retrieval by loose type.
2022-06-21 04:14:19,715:WARNING: 	 embed_dim: 512
2022-06-21 04:14:19,715:WARNING: 	 image_resolution: 224
2022-06-21 04:14:19,715:WARNING: 	 vision_layers: 12
2022-06-21 04:14:19,715:WARNING: 	 vision_width: 768
2022-06-21 04:14:19,715:WARNING: 	 vision_patch_size: 32
2022-06-21 04:14:19,715:WARNING: 	 context_length: 77
2022-06-21 04:14:19,715:WARNING: 	 vocab_size: 49408
2022-06-21 04:14:19,715:WARNING: 	 transformer_width: 512
2022-06-21 04:14:19,715:WARNING: 	 transformer_heads: 8
2022-06-21 04:14:19,715:WARNING: 	 transformer_layers: 12
2022-06-21 04:14:19,715:WARNING: 		 linear_patch: 3d
2022-06-21 04:14:19,715:WARNING: 	 cut_top_layer: 0
2022-06-21 04:14:27,295:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:14:36,367:INFO: ***** Running test *****
2022-06-21 04:14:36,367:INFO:   Num examples = 27763
2022-06-21 04:14:36,367:INFO:   Batch size = 16
2022-06-21 04:14:36,367:INFO:   Num steps = 1736
2022-06-21 04:14:36,367:INFO: ***** Running val *****
2022-06-21 04:14:36,367:INFO:   Num examples = 4290
2022-06-21 04:14:38,558:INFO: ***** Running training *****
2022-06-21 04:14:38,558:INFO:   Num examples = 48774
2022-06-21 04:14:38,558:INFO:   Batch size = 128
2022-06-21 04:14:38,558:INFO:   Num steps = 3810
2022-06-21 04:17:46,325:INFO: Effective parameters:
2022-06-21 04:17:46,325:INFO:   <<< batch_size: 128
2022-06-21 04:17:46,325:INFO:   <<< batch_size_val: 16
2022-06-21 04:17:46,326:INFO:   <<< cache_dir: 
2022-06-21 04:17:46,326:INFO:   <<< coef_lr: 0.001
2022-06-21 04:17:46,326:INFO:   <<< cross_model: cross-base
2022-06-21 04:17:46,326:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:17:46,326:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:17:46,326:INFO:   <<< datatype: msvd
2022-06-21 04:17:46,326:INFO:   <<< do_eval: False
2022-06-21 04:17:46,326:INFO:   <<< do_lower_case: False
2022-06-21 04:17:46,326:INFO:   <<< do_pretrain: False
2022-06-21 04:17:46,326:INFO:   <<< do_train: True
2022-06-21 04:17:46,326:INFO:   <<< epochs: 5
2022-06-21 04:17:46,326:INFO:   <<< eval_frame_order: 0
2022-06-21 04:17:46,326:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:17:46,326:INFO:   <<< feature_framerate: 1
2022-06-21 04:17:46,326:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:17:46,326:INFO:   <<< fp16: False
2022-06-21 04:17:46,326:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:17:46,326:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:17:46,326:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:17:46,327:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:17:46,327:INFO:   <<< init_model: None
2022-06-21 04:17:46,327:INFO:   <<< linear_patch: 3d
2022-06-21 04:17:46,327:INFO:   <<< local_rank: 0
2022-06-21 04:17:46,327:INFO:   <<< loose_type: True
2022-06-21 04:17:46,327:INFO:   <<< lr: 0.0001
2022-06-21 04:17:46,327:INFO:   <<< lr_decay: 0.9
2022-06-21 04:17:46,327:INFO:   <<< margin: 0.1
2022-06-21 04:17:46,327:INFO:   <<< max_frames: 16
2022-06-21 04:17:46,327:INFO:   <<< max_words: 32
2022-06-21 04:17:46,327:INFO:   <<< n_display: 50
2022-06-21 04:17:46,327:INFO:   <<< n_gpu: 1
2022-06-21 04:17:46,327:INFO:   <<< n_pair: 1
2022-06-21 04:17:46,327:INFO:   <<< negative_weighting: 1
2022-06-21 04:17:46,327:INFO:   <<< num_thread_reader: 2
2022-06-21 04:17:46,327:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:17:46,327:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:17:46,327:INFO:   <<< rank: 0
2022-06-21 04:17:46,327:INFO:   <<< resume_model: None
2022-06-21 04:17:46,327:INFO:   <<< sampled_use_mil: False
2022-06-21 04:17:46,328:INFO:   <<< seed: 42
2022-06-21 04:17:46,328:INFO:   <<< sim_header: meanP
2022-06-21 04:17:46,328:INFO:   <<< slice_framepos: 2
2022-06-21 04:17:46,328:INFO:   <<< task_type: retrieval
2022-06-21 04:17:46,328:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:17:46,328:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:17:46,328:INFO:   <<< train_frame_order: 0
2022-06-21 04:17:46,328:INFO:   <<< use_mil: False
2022-06-21 04:17:46,328:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:17:46,328:INFO:   <<< video_dim: 1024
2022-06-21 04:17:46,328:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:17:46,328:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:17:46,328:INFO:   <<< world_size: 1
2022-06-21 04:17:46,328:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:17:47,058:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:17:47,059:WARNING: Test retrieval by loose type.
2022-06-21 04:17:47,059:WARNING: 	 embed_dim: 512
2022-06-21 04:17:47,059:WARNING: 	 image_resolution: 224
2022-06-21 04:17:47,059:WARNING: 	 vision_layers: 12
2022-06-21 04:17:47,059:WARNING: 	 vision_width: 768
2022-06-21 04:17:47,059:WARNING: 	 vision_patch_size: 32
2022-06-21 04:17:47,059:WARNING: 	 context_length: 77
2022-06-21 04:17:47,059:WARNING: 	 vocab_size: 49408
2022-06-21 04:17:47,059:WARNING: 	 transformer_width: 512
2022-06-21 04:17:47,059:WARNING: 	 transformer_heads: 8
2022-06-21 04:17:47,059:WARNING: 	 transformer_layers: 12
2022-06-21 04:17:47,059:WARNING: 		 linear_patch: 3d
2022-06-21 04:17:47,059:WARNING: 	 cut_top_layer: 0
2022-06-21 04:17:54,141:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:18:05,988:INFO: ***** Running test *****
2022-06-21 04:18:05,988:INFO:   Num examples = 27763
2022-06-21 04:18:05,988:INFO:   Batch size = 16
2022-06-21 04:18:05,989:INFO:   Num steps = 1736
2022-06-21 04:18:05,989:INFO: ***** Running val *****
2022-06-21 04:18:05,989:INFO:   Num examples = 4290
2022-06-21 04:18:08,113:INFO: ***** Running training *****
2022-06-21 04:18:08,113:INFO:   Num examples = 48774
2022-06-21 04:18:08,113:INFO:   Batch size = 128
2022-06-21 04:18:08,113:INFO:   Num steps = 3810
2022-06-21 04:21:47,443:INFO: Effective parameters:
2022-06-21 04:21:47,443:INFO:   <<< batch_size: 128
2022-06-21 04:21:47,443:INFO:   <<< batch_size_val: 16
2022-06-21 04:21:47,443:INFO:   <<< cache_dir: 
2022-06-21 04:21:47,443:INFO:   <<< coef_lr: 0.001
2022-06-21 04:21:47,443:INFO:   <<< cross_model: cross-base
2022-06-21 04:21:47,443:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:21:47,444:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:21:47,444:INFO:   <<< datatype: msvd
2022-06-21 04:21:47,444:INFO:   <<< do_eval: False
2022-06-21 04:21:47,444:INFO:   <<< do_lower_case: False
2022-06-21 04:21:47,444:INFO:   <<< do_pretrain: False
2022-06-21 04:21:47,444:INFO:   <<< do_train: True
2022-06-21 04:21:47,444:INFO:   <<< epochs: 5
2022-06-21 04:21:47,444:INFO:   <<< eval_frame_order: 0
2022-06-21 04:21:47,444:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:21:47,444:INFO:   <<< feature_framerate: 1
2022-06-21 04:21:47,444:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:21:47,444:INFO:   <<< fp16: False
2022-06-21 04:21:47,444:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:21:47,444:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:21:47,444:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:21:47,444:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:21:47,444:INFO:   <<< init_model: None
2022-06-21 04:21:47,444:INFO:   <<< linear_patch: 3d
2022-06-21 04:21:47,444:INFO:   <<< local_rank: 0
2022-06-21 04:21:47,444:INFO:   <<< loose_type: True
2022-06-21 04:21:47,444:INFO:   <<< lr: 0.0001
2022-06-21 04:21:47,444:INFO:   <<< lr_decay: 0.9
2022-06-21 04:21:47,444:INFO:   <<< margin: 0.1
2022-06-21 04:21:47,444:INFO:   <<< max_frames: 16
2022-06-21 04:21:47,444:INFO:   <<< max_words: 32
2022-06-21 04:21:47,444:INFO:   <<< n_display: 50
2022-06-21 04:21:47,444:INFO:   <<< n_gpu: 1
2022-06-21 04:21:47,444:INFO:   <<< n_pair: 1
2022-06-21 04:21:47,444:INFO:   <<< negative_weighting: 1
2022-06-21 04:21:47,445:INFO:   <<< num_thread_reader: 2
2022-06-21 04:21:47,445:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:21:47,445:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:21:47,445:INFO:   <<< rank: 0
2022-06-21 04:21:47,445:INFO:   <<< resume_model: None
2022-06-21 04:21:47,445:INFO:   <<< sampled_use_mil: False
2022-06-21 04:21:47,445:INFO:   <<< seed: 42
2022-06-21 04:21:47,445:INFO:   <<< sim_header: meanP
2022-06-21 04:21:47,445:INFO:   <<< slice_framepos: 2
2022-06-21 04:21:47,445:INFO:   <<< task_type: retrieval
2022-06-21 04:21:47,445:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:21:47,445:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:21:47,445:INFO:   <<< train_frame_order: 0
2022-06-21 04:21:47,445:INFO:   <<< use_mil: False
2022-06-21 04:21:47,445:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:21:47,445:INFO:   <<< video_dim: 1024
2022-06-21 04:21:47,445:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:21:47,445:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:21:47,445:INFO:   <<< world_size: 1
2022-06-21 04:21:47,445:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:21:48,185:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:21:48,186:WARNING: Test retrieval by loose type.
2022-06-21 04:21:48,187:WARNING: 	 embed_dim: 512
2022-06-21 04:21:48,187:WARNING: 	 image_resolution: 224
2022-06-21 04:21:48,187:WARNING: 	 vision_layers: 12
2022-06-21 04:21:48,187:WARNING: 	 vision_width: 768
2022-06-21 04:21:48,187:WARNING: 	 vision_patch_size: 32
2022-06-21 04:21:48,187:WARNING: 	 context_length: 77
2022-06-21 04:21:48,187:WARNING: 	 vocab_size: 49408
2022-06-21 04:21:48,187:WARNING: 	 transformer_width: 512
2022-06-21 04:21:48,187:WARNING: 	 transformer_heads: 8
2022-06-21 04:21:48,187:WARNING: 	 transformer_layers: 12
2022-06-21 04:21:48,187:WARNING: 		 linear_patch: 3d
2022-06-21 04:21:48,187:WARNING: 	 cut_top_layer: 0
2022-06-21 04:21:55,696:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:22:08,034:INFO: ***** Running test *****
2022-06-21 04:22:08,035:INFO:   Num examples = 27763
2022-06-21 04:22:08,035:INFO:   Batch size = 16
2022-06-21 04:22:08,035:INFO:   Num steps = 1736
2022-06-21 04:22:08,035:INFO: ***** Running val *****
2022-06-21 04:22:08,035:INFO:   Num examples = 4290
2022-06-21 04:22:10,289:INFO: ***** Running training *****
2022-06-21 04:22:10,290:INFO:   Num examples = 48774
2022-06-21 04:22:10,290:INFO:   Batch size = 128
2022-06-21 04:22:10,290:INFO:   Num steps = 3810
2022-06-21 04:25:03,489:INFO: Effective parameters:
2022-06-21 04:25:03,490:INFO:   <<< batch_size: 128
2022-06-21 04:25:03,490:INFO:   <<< batch_size_val: 16
2022-06-21 04:25:03,490:INFO:   <<< cache_dir: 
2022-06-21 04:25:03,490:INFO:   <<< coef_lr: 0.001
2022-06-21 04:25:03,491:INFO:   <<< cross_model: cross-base
2022-06-21 04:25:03,491:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:25:03,491:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:25:03,491:INFO:   <<< datatype: msvd
2022-06-21 04:25:03,491:INFO:   <<< do_eval: False
2022-06-21 04:25:03,491:INFO:   <<< do_lower_case: False
2022-06-21 04:25:03,491:INFO:   <<< do_pretrain: False
2022-06-21 04:25:03,491:INFO:   <<< do_train: True
2022-06-21 04:25:03,491:INFO:   <<< epochs: 5
2022-06-21 04:25:03,491:INFO:   <<< eval_frame_order: 0
2022-06-21 04:25:03,491:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:25:03,491:INFO:   <<< feature_framerate: 1
2022-06-21 04:25:03,491:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:25:03,492:INFO:   <<< fp16: False
2022-06-21 04:25:03,492:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:25:03,492:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:25:03,492:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:25:03,492:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:25:03,492:INFO:   <<< init_model: None
2022-06-21 04:25:03,492:INFO:   <<< linear_patch: 3d
2022-06-21 04:25:03,492:INFO:   <<< local_rank: 0
2022-06-21 04:25:03,492:INFO:   <<< loose_type: True
2022-06-21 04:25:03,492:INFO:   <<< lr: 0.0001
2022-06-21 04:25:03,492:INFO:   <<< lr_decay: 0.9
2022-06-21 04:25:03,492:INFO:   <<< margin: 0.1
2022-06-21 04:25:03,492:INFO:   <<< max_frames: 16
2022-06-21 04:25:03,493:INFO:   <<< max_words: 32
2022-06-21 04:25:03,493:INFO:   <<< n_display: 50
2022-06-21 04:25:03,493:INFO:   <<< n_gpu: 1
2022-06-21 04:25:03,493:INFO:   <<< n_pair: 1
2022-06-21 04:25:03,493:INFO:   <<< negative_weighting: 1
2022-06-21 04:25:03,493:INFO:   <<< num_thread_reader: 2
2022-06-21 04:25:03,493:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:25:03,493:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:25:03,493:INFO:   <<< rank: 0
2022-06-21 04:25:03,493:INFO:   <<< resume_model: None
2022-06-21 04:25:03,493:INFO:   <<< sampled_use_mil: False
2022-06-21 04:25:03,493:INFO:   <<< seed: 42
2022-06-21 04:25:03,493:INFO:   <<< sim_header: meanP
2022-06-21 04:25:03,494:INFO:   <<< slice_framepos: 2
2022-06-21 04:25:03,494:INFO:   <<< task_type: retrieval
2022-06-21 04:25:03,494:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:25:03,494:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:25:03,494:INFO:   <<< train_frame_order: 0
2022-06-21 04:25:03,494:INFO:   <<< use_mil: False
2022-06-21 04:25:03,494:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:25:03,494:INFO:   <<< video_dim: 1024
2022-06-21 04:25:03,494:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:25:03,494:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:25:03,494:INFO:   <<< world_size: 1
2022-06-21 04:25:03,495:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:25:04,232:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:25:04,233:WARNING: Test retrieval by loose type.
2022-06-21 04:25:04,234:WARNING: 	 embed_dim: 512
2022-06-21 04:25:04,234:WARNING: 	 image_resolution: 224
2022-06-21 04:25:04,235:WARNING: 	 vision_layers: 12
2022-06-21 04:25:04,235:WARNING: 	 vision_width: 768
2022-06-21 04:25:04,235:WARNING: 	 vision_patch_size: 32
2022-06-21 04:25:04,235:WARNING: 	 context_length: 77
2022-06-21 04:25:04,235:WARNING: 	 vocab_size: 49408
2022-06-21 04:25:04,235:WARNING: 	 transformer_width: 512
2022-06-21 04:25:04,235:WARNING: 	 transformer_heads: 8
2022-06-21 04:25:04,235:WARNING: 	 transformer_layers: 12
2022-06-21 04:25:04,235:WARNING: 		 linear_patch: 3d
2022-06-21 04:25:04,235:WARNING: 	 cut_top_layer: 0
2022-06-21 04:25:12,098:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:25:23,132:INFO: ***** Running test *****
2022-06-21 04:25:23,132:INFO:   Num examples = 27763
2022-06-21 04:25:23,132:INFO:   Batch size = 16
2022-06-21 04:25:23,132:INFO:   Num steps = 1736
2022-06-21 04:25:23,132:INFO: ***** Running val *****
2022-06-21 04:25:23,132:INFO:   Num examples = 4290
2022-06-21 04:25:25,436:INFO: ***** Running training *****
2022-06-21 04:25:25,436:INFO:   Num examples = 48774
2022-06-21 04:25:25,437:INFO:   Batch size = 128
2022-06-21 04:25:25,437:INFO:   Num steps = 3810
2022-06-21 04:27:17,005:INFO: Effective parameters:
2022-06-21 04:27:17,005:INFO:   <<< batch_size: 128
2022-06-21 04:27:17,005:INFO:   <<< batch_size_val: 16
2022-06-21 04:27:17,005:INFO:   <<< cache_dir: 
2022-06-21 04:27:17,005:INFO:   <<< coef_lr: 0.001
2022-06-21 04:27:17,005:INFO:   <<< cross_model: cross-base
2022-06-21 04:27:17,005:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:27:17,005:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:27:17,005:INFO:   <<< datatype: msvd
2022-06-21 04:27:17,005:INFO:   <<< do_eval: False
2022-06-21 04:27:17,005:INFO:   <<< do_lower_case: False
2022-06-21 04:27:17,005:INFO:   <<< do_pretrain: False
2022-06-21 04:27:17,005:INFO:   <<< do_train: True
2022-06-21 04:27:17,005:INFO:   <<< epochs: 5
2022-06-21 04:27:17,005:INFO:   <<< eval_frame_order: 0
2022-06-21 04:27:17,005:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:27:17,005:INFO:   <<< feature_framerate: 1
2022-06-21 04:27:17,006:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:27:17,006:INFO:   <<< fp16: False
2022-06-21 04:27:17,006:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:27:17,006:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:27:17,006:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:27:17,006:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:27:17,006:INFO:   <<< init_model: None
2022-06-21 04:27:17,006:INFO:   <<< linear_patch: 3d
2022-06-21 04:27:17,006:INFO:   <<< local_rank: 0
2022-06-21 04:27:17,006:INFO:   <<< loose_type: True
2022-06-21 04:27:17,006:INFO:   <<< lr: 0.0001
2022-06-21 04:27:17,006:INFO:   <<< lr_decay: 0.9
2022-06-21 04:27:17,006:INFO:   <<< margin: 0.1
2022-06-21 04:27:17,006:INFO:   <<< max_frames: 16
2022-06-21 04:27:17,006:INFO:   <<< max_words: 32
2022-06-21 04:27:17,006:INFO:   <<< n_display: 50
2022-06-21 04:27:17,006:INFO:   <<< n_gpu: 1
2022-06-21 04:27:17,006:INFO:   <<< n_pair: 1
2022-06-21 04:27:17,006:INFO:   <<< negative_weighting: 1
2022-06-21 04:27:17,006:INFO:   <<< num_thread_reader: 2
2022-06-21 04:27:17,006:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:27:17,006:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:27:17,006:INFO:   <<< rank: 0
2022-06-21 04:27:17,006:INFO:   <<< resume_model: None
2022-06-21 04:27:17,006:INFO:   <<< sampled_use_mil: False
2022-06-21 04:27:17,006:INFO:   <<< seed: 42
2022-06-21 04:27:17,006:INFO:   <<< sim_header: meanP
2022-06-21 04:27:17,006:INFO:   <<< slice_framepos: 2
2022-06-21 04:27:17,006:INFO:   <<< task_type: retrieval
2022-06-21 04:27:17,006:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:27:17,007:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:27:17,007:INFO:   <<< train_frame_order: 0
2022-06-21 04:27:17,007:INFO:   <<< use_mil: False
2022-06-21 04:27:17,007:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:27:17,007:INFO:   <<< video_dim: 1024
2022-06-21 04:27:17,007:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:27:17,007:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:27:17,007:INFO:   <<< world_size: 1
2022-06-21 04:27:17,007:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:27:17,991:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:27:17,992:WARNING: Test retrieval by loose type.
2022-06-21 04:27:17,992:WARNING: 	 embed_dim: 512
2022-06-21 04:27:17,992:WARNING: 	 image_resolution: 224
2022-06-21 04:27:17,992:WARNING: 	 vision_layers: 12
2022-06-21 04:27:17,992:WARNING: 	 vision_width: 768
2022-06-21 04:27:17,992:WARNING: 	 vision_patch_size: 32
2022-06-21 04:27:17,992:WARNING: 	 context_length: 77
2022-06-21 04:27:17,992:WARNING: 	 vocab_size: 49408
2022-06-21 04:27:17,992:WARNING: 	 transformer_width: 512
2022-06-21 04:27:17,992:WARNING: 	 transformer_heads: 8
2022-06-21 04:27:17,993:WARNING: 	 transformer_layers: 12
2022-06-21 04:27:17,993:WARNING: 		 linear_patch: 3d
2022-06-21 04:27:17,993:WARNING: 	 cut_top_layer: 0
2022-06-21 04:27:25,597:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:27:35,524:INFO: ***** Running test *****
2022-06-21 04:27:35,524:INFO:   Num examples = 27763
2022-06-21 04:27:35,524:INFO:   Batch size = 16
2022-06-21 04:27:35,524:INFO:   Num steps = 1736
2022-06-21 04:27:35,524:INFO: ***** Running val *****
2022-06-21 04:27:35,524:INFO:   Num examples = 4290
2022-06-21 04:27:37,375:INFO: ***** Running training *****
2022-06-21 04:27:37,375:INFO:   Num examples = 48774
2022-06-21 04:27:37,376:INFO:   Batch size = 128
2022-06-21 04:27:37,376:INFO:   Num steps = 3810
2022-06-21 04:29:24,569:INFO: Effective parameters:
2022-06-21 04:29:24,569:INFO:   <<< batch_size: 128
2022-06-21 04:29:24,569:INFO:   <<< batch_size_val: 16
2022-06-21 04:29:24,569:INFO:   <<< cache_dir: 
2022-06-21 04:29:24,570:INFO:   <<< coef_lr: 0.001
2022-06-21 04:29:24,570:INFO:   <<< cross_model: cross-base
2022-06-21 04:29:24,570:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:29:24,570:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:29:24,570:INFO:   <<< datatype: msvd
2022-06-21 04:29:24,570:INFO:   <<< do_eval: False
2022-06-21 04:29:24,570:INFO:   <<< do_lower_case: False
2022-06-21 04:29:24,570:INFO:   <<< do_pretrain: False
2022-06-21 04:29:24,570:INFO:   <<< do_train: True
2022-06-21 04:29:24,570:INFO:   <<< epochs: 5
2022-06-21 04:29:24,570:INFO:   <<< eval_frame_order: 0
2022-06-21 04:29:24,570:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:29:24,570:INFO:   <<< feature_framerate: 1
2022-06-21 04:29:24,570:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:29:24,570:INFO:   <<< fp16: False
2022-06-21 04:29:24,570:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:29:24,571:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:29:24,571:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:29:24,571:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:29:24,571:INFO:   <<< init_model: None
2022-06-21 04:29:24,571:INFO:   <<< linear_patch: 3d
2022-06-21 04:29:24,571:INFO:   <<< local_rank: 0
2022-06-21 04:29:24,571:INFO:   <<< loose_type: True
2022-06-21 04:29:24,571:INFO:   <<< lr: 0.0001
2022-06-21 04:29:24,571:INFO:   <<< lr_decay: 0.9
2022-06-21 04:29:24,571:INFO:   <<< margin: 0.1
2022-06-21 04:29:24,571:INFO:   <<< max_frames: 16
2022-06-21 04:29:24,571:INFO:   <<< max_words: 32
2022-06-21 04:29:24,571:INFO:   <<< n_display: 50
2022-06-21 04:29:24,571:INFO:   <<< n_gpu: 1
2022-06-21 04:29:24,571:INFO:   <<< n_pair: 1
2022-06-21 04:29:24,571:INFO:   <<< negative_weighting: 1
2022-06-21 04:29:24,572:INFO:   <<< num_thread_reader: 2
2022-06-21 04:29:24,572:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:29:24,572:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:29:24,572:INFO:   <<< rank: 0
2022-06-21 04:29:24,572:INFO:   <<< resume_model: None
2022-06-21 04:29:24,572:INFO:   <<< sampled_use_mil: False
2022-06-21 04:29:24,572:INFO:   <<< seed: 42
2022-06-21 04:29:24,572:INFO:   <<< sim_header: meanP
2022-06-21 04:29:24,572:INFO:   <<< slice_framepos: 2
2022-06-21 04:29:24,572:INFO:   <<< task_type: retrieval
2022-06-21 04:29:24,572:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:29:24,572:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:29:24,572:INFO:   <<< train_frame_order: 0
2022-06-21 04:29:24,572:INFO:   <<< use_mil: False
2022-06-21 04:29:24,572:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:29:24,572:INFO:   <<< video_dim: 1024
2022-06-21 04:29:24,572:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:29:24,573:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:29:24,573:INFO:   <<< world_size: 1
2022-06-21 04:29:24,573:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:29:25,269:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:29:25,270:WARNING: Test retrieval by loose type.
2022-06-21 04:29:25,270:WARNING: 	 embed_dim: 512
2022-06-21 04:29:25,270:WARNING: 	 image_resolution: 224
2022-06-21 04:29:25,270:WARNING: 	 vision_layers: 12
2022-06-21 04:29:25,276:WARNING: 	 vision_width: 768
2022-06-21 04:29:25,276:WARNING: 	 vision_patch_size: 32
2022-06-21 04:29:25,276:WARNING: 	 context_length: 77
2022-06-21 04:29:25,276:WARNING: 	 vocab_size: 49408
2022-06-21 04:29:25,276:WARNING: 	 transformer_width: 512
2022-06-21 04:29:25,276:WARNING: 	 transformer_heads: 8
2022-06-21 04:29:25,276:WARNING: 	 transformer_layers: 12
2022-06-21 04:29:25,276:WARNING: 		 linear_patch: 3d
2022-06-21 04:29:25,276:WARNING: 	 cut_top_layer: 0
2022-06-21 04:29:32,740:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:29:46,997:INFO: ***** Running test *****
2022-06-21 04:29:46,997:INFO:   Num examples = 27763
2022-06-21 04:29:46,997:INFO:   Batch size = 16
2022-06-21 04:29:46,997:INFO:   Num steps = 1736
2022-06-21 04:29:46,997:INFO: ***** Running val *****
2022-06-21 04:29:46,997:INFO:   Num examples = 4290
2022-06-21 04:29:48,075:INFO: ***** Running training *****
2022-06-21 04:29:48,075:INFO:   Num examples = 48774
2022-06-21 04:29:48,075:INFO:   Batch size = 128
2022-06-21 04:29:48,075:INFO:   Num steps = 3810
2022-06-21 04:32:11,740:INFO: Effective parameters:
2022-06-21 04:32:11,740:INFO:   <<< batch_size: 128
2022-06-21 04:32:11,741:INFO:   <<< batch_size_val: 16
2022-06-21 04:32:11,741:INFO:   <<< cache_dir: 
2022-06-21 04:32:11,741:INFO:   <<< coef_lr: 0.001
2022-06-21 04:32:11,741:INFO:   <<< cross_model: cross-base
2022-06-21 04:32:11,741:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:32:11,741:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:32:11,741:INFO:   <<< datatype: msvd
2022-06-21 04:32:11,741:INFO:   <<< do_eval: False
2022-06-21 04:32:11,741:INFO:   <<< do_lower_case: False
2022-06-21 04:32:11,741:INFO:   <<< do_pretrain: False
2022-06-21 04:32:11,741:INFO:   <<< do_train: True
2022-06-21 04:32:11,741:INFO:   <<< epochs: 5
2022-06-21 04:32:11,741:INFO:   <<< eval_frame_order: 0
2022-06-21 04:32:11,742:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:32:11,742:INFO:   <<< feature_framerate: 1
2022-06-21 04:32:11,742:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:32:11,742:INFO:   <<< fp16: False
2022-06-21 04:32:11,742:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:32:11,742:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:32:11,742:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:32:11,742:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:32:11,742:INFO:   <<< init_model: None
2022-06-21 04:32:11,742:INFO:   <<< linear_patch: 3d
2022-06-21 04:32:11,742:INFO:   <<< local_rank: 0
2022-06-21 04:32:11,742:INFO:   <<< loose_type: True
2022-06-21 04:32:11,743:INFO:   <<< lr: 0.0001
2022-06-21 04:32:11,743:INFO:   <<< lr_decay: 0.9
2022-06-21 04:32:11,743:INFO:   <<< margin: 0.1
2022-06-21 04:32:11,743:INFO:   <<< max_frames: 16
2022-06-21 04:32:11,743:INFO:   <<< max_words: 32
2022-06-21 04:32:11,743:INFO:   <<< n_display: 50
2022-06-21 04:32:11,743:INFO:   <<< n_gpu: 1
2022-06-21 04:32:11,743:INFO:   <<< n_pair: 1
2022-06-21 04:32:11,743:INFO:   <<< negative_weighting: 1
2022-06-21 04:32:11,743:INFO:   <<< num_thread_reader: 2
2022-06-21 04:32:11,743:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:32:11,743:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:32:11,743:INFO:   <<< rank: 0
2022-06-21 04:32:11,743:INFO:   <<< resume_model: None
2022-06-21 04:32:11,743:INFO:   <<< sampled_use_mil: False
2022-06-21 04:32:11,743:INFO:   <<< seed: 42
2022-06-21 04:32:11,743:INFO:   <<< sim_header: meanP
2022-06-21 04:32:11,743:INFO:   <<< slice_framepos: 2
2022-06-21 04:32:11,743:INFO:   <<< task_type: retrieval
2022-06-21 04:32:11,743:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:32:11,743:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:32:11,743:INFO:   <<< train_frame_order: 0
2022-06-21 04:32:11,743:INFO:   <<< use_mil: False
2022-06-21 04:32:11,743:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:32:11,743:INFO:   <<< video_dim: 1024
2022-06-21 04:32:11,743:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:32:11,744:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:32:11,744:INFO:   <<< world_size: 1
2022-06-21 04:32:11,744:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:32:12,482:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:32:12,482:WARNING: Test retrieval by loose type.
2022-06-21 04:32:12,483:WARNING: 	 embed_dim: 512
2022-06-21 04:32:12,483:WARNING: 	 image_resolution: 224
2022-06-21 04:32:12,483:WARNING: 	 vision_layers: 12
2022-06-21 04:32:12,483:WARNING: 	 vision_width: 768
2022-06-21 04:32:12,483:WARNING: 	 vision_patch_size: 32
2022-06-21 04:32:12,483:WARNING: 	 context_length: 77
2022-06-21 04:32:12,483:WARNING: 	 vocab_size: 49408
2022-06-21 04:32:12,483:WARNING: 	 transformer_width: 512
2022-06-21 04:32:12,483:WARNING: 	 transformer_heads: 8
2022-06-21 04:32:12,483:WARNING: 	 transformer_layers: 12
2022-06-21 04:32:12,483:WARNING: 		 linear_patch: 3d
2022-06-21 04:32:12,483:WARNING: 	 cut_top_layer: 0
2022-06-21 04:32:19,727:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:32:31,154:INFO: ***** Running test *****
2022-06-21 04:32:31,154:INFO:   Num examples = 27763
2022-06-21 04:32:31,154:INFO:   Batch size = 16
2022-06-21 04:32:31,154:INFO:   Num steps = 1736
2022-06-21 04:32:31,154:INFO: ***** Running val *****
2022-06-21 04:32:31,155:INFO:   Num examples = 4290
2022-06-21 04:32:32,161:INFO: ***** Running training *****
2022-06-21 04:32:32,161:INFO:   Num examples = 48774
2022-06-21 04:32:32,161:INFO:   Batch size = 128
2022-06-21 04:32:32,161:INFO:   Num steps = 3810
2022-06-21 04:35:00,693:INFO: Effective parameters:
2022-06-21 04:35:00,694:INFO:   <<< batch_size: 128
2022-06-21 04:35:00,694:INFO:   <<< batch_size_val: 16
2022-06-21 04:35:00,694:INFO:   <<< cache_dir: 
2022-06-21 04:35:00,694:INFO:   <<< coef_lr: 0.001
2022-06-21 04:35:00,694:INFO:   <<< cross_model: cross-base
2022-06-21 04:35:00,694:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:35:00,694:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:35:00,694:INFO:   <<< datatype: msvd
2022-06-21 04:35:00,694:INFO:   <<< do_eval: False
2022-06-21 04:35:00,694:INFO:   <<< do_lower_case: False
2022-06-21 04:35:00,694:INFO:   <<< do_pretrain: False
2022-06-21 04:35:00,694:INFO:   <<< do_train: True
2022-06-21 04:35:00,695:INFO:   <<< epochs: 5
2022-06-21 04:35:00,695:INFO:   <<< eval_frame_order: 0
2022-06-21 04:35:00,695:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:35:00,695:INFO:   <<< feature_framerate: 1
2022-06-21 04:35:00,695:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:35:00,695:INFO:   <<< fp16: False
2022-06-21 04:35:00,695:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:35:00,695:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:35:00,695:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:35:00,695:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:35:00,695:INFO:   <<< init_model: None
2022-06-21 04:35:00,695:INFO:   <<< linear_patch: 3d
2022-06-21 04:35:00,695:INFO:   <<< local_rank: 0
2022-06-21 04:35:00,695:INFO:   <<< loose_type: True
2022-06-21 04:35:00,695:INFO:   <<< lr: 0.0001
2022-06-21 04:35:00,695:INFO:   <<< lr_decay: 0.9
2022-06-21 04:35:00,695:INFO:   <<< margin: 0.1
2022-06-21 04:35:00,695:INFO:   <<< max_frames: 16
2022-06-21 04:35:00,696:INFO:   <<< max_words: 32
2022-06-21 04:35:00,696:INFO:   <<< n_display: 50
2022-06-21 04:35:00,696:INFO:   <<< n_gpu: 1
2022-06-21 04:35:00,696:INFO:   <<< n_pair: 1
2022-06-21 04:35:00,696:INFO:   <<< negative_weighting: 1
2022-06-21 04:35:00,696:INFO:   <<< num_thread_reader: 2
2022-06-21 04:35:00,696:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:35:00,696:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:35:00,696:INFO:   <<< rank: 0
2022-06-21 04:35:00,696:INFO:   <<< resume_model: None
2022-06-21 04:35:00,696:INFO:   <<< sampled_use_mil: False
2022-06-21 04:35:00,696:INFO:   <<< seed: 42
2022-06-21 04:35:00,696:INFO:   <<< sim_header: meanP
2022-06-21 04:35:00,696:INFO:   <<< slice_framepos: 2
2022-06-21 04:35:00,696:INFO:   <<< task_type: retrieval
2022-06-21 04:35:00,696:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:35:00,696:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:35:00,697:INFO:   <<< train_frame_order: 0
2022-06-21 04:35:00,697:INFO:   <<< use_mil: False
2022-06-21 04:35:00,697:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:35:00,697:INFO:   <<< video_dim: 1024
2022-06-21 04:35:00,697:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:35:00,697:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:35:00,697:INFO:   <<< world_size: 1
2022-06-21 04:35:00,697:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:35:01,449:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:35:01,449:WARNING: Test retrieval by loose type.
2022-06-21 04:35:01,449:WARNING: 	 embed_dim: 512
2022-06-21 04:35:01,449:WARNING: 	 image_resolution: 224
2022-06-21 04:35:01,449:WARNING: 	 vision_layers: 12
2022-06-21 04:35:01,449:WARNING: 	 vision_width: 768
2022-06-21 04:35:01,449:WARNING: 	 vision_patch_size: 32
2022-06-21 04:35:01,450:WARNING: 	 context_length: 77
2022-06-21 04:35:01,450:WARNING: 	 vocab_size: 49408
2022-06-21 04:35:01,450:WARNING: 	 transformer_width: 512
2022-06-21 04:35:01,450:WARNING: 	 transformer_heads: 8
2022-06-21 04:35:01,450:WARNING: 	 transformer_layers: 12
2022-06-21 04:35:01,450:WARNING: 		 linear_patch: 3d
2022-06-21 04:35:01,450:WARNING: 	 cut_top_layer: 0
2022-06-21 04:35:08,754:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:35:20,226:INFO: ***** Running test *****
2022-06-21 04:35:20,226:INFO:   Num examples = 27763
2022-06-21 04:35:20,226:INFO:   Batch size = 16
2022-06-21 04:35:20,226:INFO:   Num steps = 1736
2022-06-21 04:35:20,226:INFO: ***** Running val *****
2022-06-21 04:35:20,226:INFO:   Num examples = 4290
2022-06-21 04:35:21,029:INFO: ***** Running training *****
2022-06-21 04:35:21,029:INFO:   Num examples = 48774
2022-06-21 04:35:21,029:INFO:   Batch size = 128
2022-06-21 04:35:21,029:INFO:   Num steps = 3810
2022-06-21 04:36:56,549:INFO: Effective parameters:
2022-06-21 04:36:56,549:INFO:   <<< batch_size: 128
2022-06-21 04:36:56,549:INFO:   <<< batch_size_val: 16
2022-06-21 04:36:56,549:INFO:   <<< cache_dir: 
2022-06-21 04:36:56,549:INFO:   <<< coef_lr: 0.001
2022-06-21 04:36:56,549:INFO:   <<< cross_model: cross-base
2022-06-21 04:36:56,549:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:36:56,550:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:36:56,550:INFO:   <<< datatype: msvd
2022-06-21 04:36:56,550:INFO:   <<< do_eval: False
2022-06-21 04:36:56,550:INFO:   <<< do_lower_case: False
2022-06-21 04:36:56,550:INFO:   <<< do_pretrain: False
2022-06-21 04:36:56,550:INFO:   <<< do_train: True
2022-06-21 04:36:56,550:INFO:   <<< epochs: 5
2022-06-21 04:36:56,550:INFO:   <<< eval_frame_order: 0
2022-06-21 04:36:56,550:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:36:56,550:INFO:   <<< feature_framerate: 1
2022-06-21 04:36:56,550:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:36:56,550:INFO:   <<< fp16: False
2022-06-21 04:36:56,550:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:36:56,550:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:36:56,550:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:36:56,550:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:36:56,550:INFO:   <<< init_model: None
2022-06-21 04:36:56,551:INFO:   <<< linear_patch: 3d
2022-06-21 04:36:56,551:INFO:   <<< local_rank: 0
2022-06-21 04:36:56,551:INFO:   <<< loose_type: True
2022-06-21 04:36:56,551:INFO:   <<< lr: 0.0001
2022-06-21 04:36:56,551:INFO:   <<< lr_decay: 0.9
2022-06-21 04:36:56,551:INFO:   <<< margin: 0.1
2022-06-21 04:36:56,551:INFO:   <<< max_frames: 16
2022-06-21 04:36:56,551:INFO:   <<< max_words: 32
2022-06-21 04:36:56,551:INFO:   <<< n_display: 50
2022-06-21 04:36:56,551:INFO:   <<< n_gpu: 1
2022-06-21 04:36:56,551:INFO:   <<< n_pair: 1
2022-06-21 04:36:56,551:INFO:   <<< negative_weighting: 1
2022-06-21 04:36:56,551:INFO:   <<< num_thread_reader: 2
2022-06-21 04:36:56,551:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:36:56,551:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:36:56,551:INFO:   <<< rank: 0
2022-06-21 04:36:56,551:INFO:   <<< resume_model: None
2022-06-21 04:36:56,551:INFO:   <<< sampled_use_mil: False
2022-06-21 04:36:56,551:INFO:   <<< seed: 42
2022-06-21 04:36:56,551:INFO:   <<< sim_header: meanP
2022-06-21 04:36:56,551:INFO:   <<< slice_framepos: 2
2022-06-21 04:36:56,552:INFO:   <<< task_type: retrieval
2022-06-21 04:36:56,552:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:36:56,552:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:36:56,552:INFO:   <<< train_frame_order: 0
2022-06-21 04:36:56,552:INFO:   <<< use_mil: False
2022-06-21 04:36:56,552:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:36:56,552:INFO:   <<< video_dim: 1024
2022-06-21 04:36:56,552:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:36:56,552:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:36:56,552:INFO:   <<< world_size: 1
2022-06-21 04:36:56,552:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:36:57,262:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:36:57,262:WARNING: Test retrieval by loose type.
2022-06-21 04:36:57,263:WARNING: 	 embed_dim: 512
2022-06-21 04:36:57,263:WARNING: 	 image_resolution: 224
2022-06-21 04:36:57,263:WARNING: 	 vision_layers: 12
2022-06-21 04:36:57,263:WARNING: 	 vision_width: 768
2022-06-21 04:36:57,263:WARNING: 	 vision_patch_size: 32
2022-06-21 04:36:57,263:WARNING: 	 context_length: 77
2022-06-21 04:36:57,263:WARNING: 	 vocab_size: 49408
2022-06-21 04:36:57,263:WARNING: 	 transformer_width: 512
2022-06-21 04:36:57,263:WARNING: 	 transformer_heads: 8
2022-06-21 04:36:57,263:WARNING: 	 transformer_layers: 12
2022-06-21 04:36:57,263:WARNING: 		 linear_patch: 3d
2022-06-21 04:36:57,263:WARNING: 	 cut_top_layer: 0
2022-06-21 04:37:04,725:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:37:16,203:INFO: ***** Running test *****
2022-06-21 04:37:16,203:INFO:   Num examples = 27763
2022-06-21 04:37:16,203:INFO:   Batch size = 16
2022-06-21 04:37:16,203:INFO:   Num steps = 1736
2022-06-21 04:37:16,203:INFO: ***** Running val *****
2022-06-21 04:37:16,203:INFO:   Num examples = 4290
2022-06-21 04:37:16,810:INFO: ***** Running training *****
2022-06-21 04:37:16,810:INFO:   Num examples = 48774
2022-06-21 04:37:16,810:INFO:   Batch size = 128
2022-06-21 04:37:16,810:INFO:   Num steps = 3810
2022-06-21 04:38:26,038:INFO: Effective parameters:
2022-06-21 04:38:26,038:INFO:   <<< batch_size: 128
2022-06-21 04:38:26,038:INFO:   <<< batch_size_val: 16
2022-06-21 04:38:26,038:INFO:   <<< cache_dir: 
2022-06-21 04:38:26,038:INFO:   <<< coef_lr: 0.001
2022-06-21 04:38:26,038:INFO:   <<< cross_model: cross-base
2022-06-21 04:38:26,039:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:38:26,039:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:38:26,039:INFO:   <<< datatype: msvd
2022-06-21 04:38:26,039:INFO:   <<< do_eval: False
2022-06-21 04:38:26,039:INFO:   <<< do_lower_case: False
2022-06-21 04:38:26,039:INFO:   <<< do_pretrain: False
2022-06-21 04:38:26,039:INFO:   <<< do_train: True
2022-06-21 04:38:26,039:INFO:   <<< epochs: 5
2022-06-21 04:38:26,039:INFO:   <<< eval_frame_order: 0
2022-06-21 04:38:26,039:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:38:26,039:INFO:   <<< feature_framerate: 1
2022-06-21 04:38:26,039:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:38:26,039:INFO:   <<< fp16: False
2022-06-21 04:38:26,039:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:38:26,039:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:38:26,039:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:38:26,039:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:38:26,039:INFO:   <<< init_model: None
2022-06-21 04:38:26,039:INFO:   <<< linear_patch: 3d
2022-06-21 04:38:26,039:INFO:   <<< local_rank: 0
2022-06-21 04:38:26,039:INFO:   <<< loose_type: True
2022-06-21 04:38:26,039:INFO:   <<< lr: 0.0001
2022-06-21 04:38:26,039:INFO:   <<< lr_decay: 0.9
2022-06-21 04:38:26,039:INFO:   <<< margin: 0.1
2022-06-21 04:38:26,039:INFO:   <<< max_frames: 16
2022-06-21 04:38:26,039:INFO:   <<< max_words: 32
2022-06-21 04:38:26,039:INFO:   <<< n_display: 50
2022-06-21 04:38:26,039:INFO:   <<< n_gpu: 1
2022-06-21 04:38:26,039:INFO:   <<< n_pair: 1
2022-06-21 04:38:26,039:INFO:   <<< negative_weighting: 1
2022-06-21 04:38:26,040:INFO:   <<< num_thread_reader: 2
2022-06-21 04:38:26,040:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:38:26,040:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:38:26,040:INFO:   <<< rank: 0
2022-06-21 04:38:26,040:INFO:   <<< resume_model: None
2022-06-21 04:38:26,040:INFO:   <<< sampled_use_mil: False
2022-06-21 04:38:26,040:INFO:   <<< seed: 42
2022-06-21 04:38:26,040:INFO:   <<< sim_header: meanP
2022-06-21 04:38:26,040:INFO:   <<< slice_framepos: 2
2022-06-21 04:38:26,040:INFO:   <<< task_type: retrieval
2022-06-21 04:38:26,040:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:38:26,040:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:38:26,040:INFO:   <<< train_frame_order: 0
2022-06-21 04:38:26,040:INFO:   <<< use_mil: False
2022-06-21 04:38:26,040:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:38:26,040:INFO:   <<< video_dim: 1024
2022-06-21 04:38:26,040:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:38:26,040:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:38:26,040:INFO:   <<< world_size: 1
2022-06-21 04:38:26,040:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:38:26,769:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:38:26,770:WARNING: Test retrieval by loose type.
2022-06-21 04:38:26,770:WARNING: 	 embed_dim: 512
2022-06-21 04:38:26,770:WARNING: 	 image_resolution: 224
2022-06-21 04:38:26,770:WARNING: 	 vision_layers: 12
2022-06-21 04:38:26,770:WARNING: 	 vision_width: 768
2022-06-21 04:38:26,770:WARNING: 	 vision_patch_size: 32
2022-06-21 04:38:26,770:WARNING: 	 context_length: 77
2022-06-21 04:38:26,770:WARNING: 	 vocab_size: 49408
2022-06-21 04:38:26,770:WARNING: 	 transformer_width: 512
2022-06-21 04:38:26,770:WARNING: 	 transformer_heads: 8
2022-06-21 04:38:26,770:WARNING: 	 transformer_layers: 12
2022-06-21 04:38:26,770:WARNING: 		 linear_patch: 3d
2022-06-21 04:38:26,770:WARNING: 	 cut_top_layer: 0
2022-06-21 04:38:34,069:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:38:44,437:INFO: ***** Running test *****
2022-06-21 04:38:44,437:INFO:   Num examples = 27763
2022-06-21 04:38:44,437:INFO:   Batch size = 16
2022-06-21 04:38:44,437:INFO:   Num steps = 1736
2022-06-21 04:38:44,437:INFO: ***** Running val *****
2022-06-21 04:38:44,437:INFO:   Num examples = 4290
2022-06-21 04:38:46,836:INFO: ***** Running training *****
2022-06-21 04:38:46,836:INFO:   Num examples = 48774
2022-06-21 04:38:46,836:INFO:   Batch size = 128
2022-06-21 04:38:46,836:INFO:   Num steps = 3810
2022-06-21 04:39:55,052:INFO: Effective parameters:
2022-06-21 04:39:55,053:INFO:   <<< batch_size: 128
2022-06-21 04:39:55,053:INFO:   <<< batch_size_val: 16
2022-06-21 04:39:55,053:INFO:   <<< cache_dir: 
2022-06-21 04:39:55,053:INFO:   <<< coef_lr: 0.001
2022-06-21 04:39:55,053:INFO:   <<< cross_model: cross-base
2022-06-21 04:39:55,053:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:39:55,053:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:39:55,053:INFO:   <<< datatype: msvd
2022-06-21 04:39:55,053:INFO:   <<< do_eval: False
2022-06-21 04:39:55,053:INFO:   <<< do_lower_case: False
2022-06-21 04:39:55,053:INFO:   <<< do_pretrain: False
2022-06-21 04:39:55,053:INFO:   <<< do_train: True
2022-06-21 04:39:55,053:INFO:   <<< epochs: 5
2022-06-21 04:39:55,053:INFO:   <<< eval_frame_order: 0
2022-06-21 04:39:55,053:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:39:55,053:INFO:   <<< feature_framerate: 1
2022-06-21 04:39:55,053:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:39:55,053:INFO:   <<< fp16: False
2022-06-21 04:39:55,053:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:39:55,053:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:39:55,053:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:39:55,053:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:39:55,053:INFO:   <<< init_model: None
2022-06-21 04:39:55,053:INFO:   <<< linear_patch: 3d
2022-06-21 04:39:55,054:INFO:   <<< local_rank: 0
2022-06-21 04:39:55,054:INFO:   <<< loose_type: True
2022-06-21 04:39:55,054:INFO:   <<< lr: 0.0001
2022-06-21 04:39:55,054:INFO:   <<< lr_decay: 0.9
2022-06-21 04:39:55,054:INFO:   <<< margin: 0.1
2022-06-21 04:39:55,054:INFO:   <<< max_frames: 16
2022-06-21 04:39:55,054:INFO:   <<< max_words: 32
2022-06-21 04:39:55,054:INFO:   <<< n_display: 50
2022-06-21 04:39:55,054:INFO:   <<< n_gpu: 1
2022-06-21 04:39:55,054:INFO:   <<< n_pair: 1
2022-06-21 04:39:55,054:INFO:   <<< negative_weighting: 1
2022-06-21 04:39:55,054:INFO:   <<< num_thread_reader: 2
2022-06-21 04:39:55,054:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:39:55,054:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:39:55,054:INFO:   <<< rank: 0
2022-06-21 04:39:55,054:INFO:   <<< resume_model: None
2022-06-21 04:39:55,054:INFO:   <<< sampled_use_mil: False
2022-06-21 04:39:55,054:INFO:   <<< seed: 42
2022-06-21 04:39:55,054:INFO:   <<< sim_header: meanP
2022-06-21 04:39:55,054:INFO:   <<< slice_framepos: 2
2022-06-21 04:39:55,054:INFO:   <<< task_type: retrieval
2022-06-21 04:39:55,054:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:39:55,054:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:39:55,054:INFO:   <<< train_frame_order: 0
2022-06-21 04:39:55,054:INFO:   <<< use_mil: False
2022-06-21 04:39:55,054:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:39:55,054:INFO:   <<< video_dim: 1024
2022-06-21 04:39:55,054:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:39:55,054:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:39:55,055:INFO:   <<< world_size: 1
2022-06-21 04:39:55,055:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:39:55,809:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:39:55,809:WARNING: Test retrieval by loose type.
2022-06-21 04:39:55,809:WARNING: 	 embed_dim: 512
2022-06-21 04:39:55,809:WARNING: 	 image_resolution: 224
2022-06-21 04:39:55,809:WARNING: 	 vision_layers: 12
2022-06-21 04:39:55,809:WARNING: 	 vision_width: 768
2022-06-21 04:39:55,809:WARNING: 	 vision_patch_size: 32
2022-06-21 04:39:55,810:WARNING: 	 context_length: 77
2022-06-21 04:39:55,810:WARNING: 	 vocab_size: 49408
2022-06-21 04:39:55,810:WARNING: 	 transformer_width: 512
2022-06-21 04:39:55,810:WARNING: 	 transformer_heads: 8
2022-06-21 04:39:55,810:WARNING: 	 transformer_layers: 12
2022-06-21 04:39:55,810:WARNING: 		 linear_patch: 3d
2022-06-21 04:39:55,810:WARNING: 	 cut_top_layer: 0
2022-06-21 04:40:02,969:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:40:14,637:INFO: ***** Running test *****
2022-06-21 04:40:14,637:INFO:   Num examples = 27763
2022-06-21 04:40:14,637:INFO:   Batch size = 16
2022-06-21 04:40:14,637:INFO:   Num steps = 1736
2022-06-21 04:40:14,637:INFO: ***** Running val *****
2022-06-21 04:40:14,637:INFO:   Num examples = 4290
2022-06-21 04:40:15,467:INFO: ***** Running training *****
2022-06-21 04:40:15,467:INFO:   Num examples = 48774
2022-06-21 04:40:15,467:INFO:   Batch size = 128
2022-06-21 04:40:15,467:INFO:   Num steps = 3810
2022-06-21 04:42:59,135:INFO: Effective parameters:
2022-06-21 04:42:59,135:INFO:   <<< batch_size: 128
2022-06-21 04:42:59,135:INFO:   <<< batch_size_val: 16
2022-06-21 04:42:59,135:INFO:   <<< cache_dir: 
2022-06-21 04:42:59,135:INFO:   <<< coef_lr: 0.001
2022-06-21 04:42:59,135:INFO:   <<< cross_model: cross-base
2022-06-21 04:42:59,136:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:42:59,136:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:42:59,136:INFO:   <<< datatype: msvd
2022-06-21 04:42:59,136:INFO:   <<< do_eval: False
2022-06-21 04:42:59,136:INFO:   <<< do_lower_case: False
2022-06-21 04:42:59,136:INFO:   <<< do_pretrain: False
2022-06-21 04:42:59,136:INFO:   <<< do_train: True
2022-06-21 04:42:59,136:INFO:   <<< epochs: 5
2022-06-21 04:42:59,136:INFO:   <<< eval_frame_order: 0
2022-06-21 04:42:59,136:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:42:59,136:INFO:   <<< feature_framerate: 1
2022-06-21 04:42:59,136:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:42:59,136:INFO:   <<< fp16: False
2022-06-21 04:42:59,136:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:42:59,136:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:42:59,136:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:42:59,136:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:42:59,136:INFO:   <<< init_model: None
2022-06-21 04:42:59,136:INFO:   <<< linear_patch: 3d
2022-06-21 04:42:59,136:INFO:   <<< local_rank: 0
2022-06-21 04:42:59,136:INFO:   <<< loose_type: True
2022-06-21 04:42:59,136:INFO:   <<< lr: 0.0001
2022-06-21 04:42:59,136:INFO:   <<< lr_decay: 0.9
2022-06-21 04:42:59,136:INFO:   <<< margin: 0.1
2022-06-21 04:42:59,136:INFO:   <<< max_frames: 16
2022-06-21 04:42:59,136:INFO:   <<< max_words: 32
2022-06-21 04:42:59,136:INFO:   <<< n_display: 50
2022-06-21 04:42:59,136:INFO:   <<< n_gpu: 1
2022-06-21 04:42:59,136:INFO:   <<< n_pair: 1
2022-06-21 04:42:59,137:INFO:   <<< negative_weighting: 1
2022-06-21 04:42:59,137:INFO:   <<< num_thread_reader: 2
2022-06-21 04:42:59,137:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:42:59,137:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:42:59,137:INFO:   <<< rank: 0
2022-06-21 04:42:59,137:INFO:   <<< resume_model: None
2022-06-21 04:42:59,137:INFO:   <<< sampled_use_mil: False
2022-06-21 04:42:59,137:INFO:   <<< seed: 42
2022-06-21 04:42:59,137:INFO:   <<< sim_header: meanP
2022-06-21 04:42:59,137:INFO:   <<< slice_framepos: 2
2022-06-21 04:42:59,137:INFO:   <<< task_type: retrieval
2022-06-21 04:42:59,137:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:42:59,137:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:42:59,137:INFO:   <<< train_frame_order: 0
2022-06-21 04:42:59,137:INFO:   <<< use_mil: False
2022-06-21 04:42:59,137:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:42:59,137:INFO:   <<< video_dim: 1024
2022-06-21 04:42:59,137:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:42:59,137:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:42:59,137:INFO:   <<< world_size: 1
2022-06-21 04:42:59,137:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:42:59,846:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:42:59,847:WARNING: Test retrieval by loose type.
2022-06-21 04:42:59,847:WARNING: 	 embed_dim: 512
2022-06-21 04:42:59,847:WARNING: 	 image_resolution: 224
2022-06-21 04:42:59,847:WARNING: 	 vision_layers: 12
2022-06-21 04:42:59,847:WARNING: 	 vision_width: 768
2022-06-21 04:42:59,847:WARNING: 	 vision_patch_size: 32
2022-06-21 04:42:59,847:WARNING: 	 context_length: 77
2022-06-21 04:42:59,847:WARNING: 	 vocab_size: 49408
2022-06-21 04:42:59,847:WARNING: 	 transformer_width: 512
2022-06-21 04:42:59,847:WARNING: 	 transformer_heads: 8
2022-06-21 04:42:59,848:WARNING: 	 transformer_layers: 12
2022-06-21 04:42:59,848:WARNING: 		 linear_patch: 3d
2022-06-21 04:42:59,848:WARNING: 	 cut_top_layer: 0
2022-06-21 04:43:07,144:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:43:21,301:INFO: ***** Running test *****
2022-06-21 04:43:21,302:INFO:   Num examples = 27763
2022-06-21 04:43:21,302:INFO:   Batch size = 16
2022-06-21 04:43:21,302:INFO:   Num steps = 1736
2022-06-21 04:43:21,302:INFO: ***** Running val *****
2022-06-21 04:43:21,302:INFO:   Num examples = 4290
2022-06-21 04:43:22,144:INFO: ***** Running training *****
2022-06-21 04:43:22,145:INFO:   Num examples = 48774
2022-06-21 04:43:22,145:INFO:   Batch size = 128
2022-06-21 04:43:22,145:INFO:   Num steps = 3810
2022-06-21 04:45:36,598:INFO: Effective parameters:
2022-06-21 04:45:36,598:INFO:   <<< batch_size: 128
2022-06-21 04:45:36,598:INFO:   <<< batch_size_val: 16
2022-06-21 04:45:36,598:INFO:   <<< cache_dir: 
2022-06-21 04:45:36,598:INFO:   <<< coef_lr: 0.001
2022-06-21 04:45:36,598:INFO:   <<< cross_model: cross-base
2022-06-21 04:45:36,598:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:45:36,598:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:45:36,598:INFO:   <<< datatype: msvd
2022-06-21 04:45:36,599:INFO:   <<< do_eval: False
2022-06-21 04:45:36,599:INFO:   <<< do_lower_case: False
2022-06-21 04:45:36,599:INFO:   <<< do_pretrain: False
2022-06-21 04:45:36,599:INFO:   <<< do_train: True
2022-06-21 04:45:36,599:INFO:   <<< epochs: 5
2022-06-21 04:45:36,599:INFO:   <<< eval_frame_order: 0
2022-06-21 04:45:36,599:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:45:36,599:INFO:   <<< feature_framerate: 1
2022-06-21 04:45:36,599:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:45:36,599:INFO:   <<< fp16: False
2022-06-21 04:45:36,599:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:45:36,599:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:45:36,599:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:45:36,599:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:45:36,599:INFO:   <<< init_model: None
2022-06-21 04:45:36,600:INFO:   <<< linear_patch: 3d
2022-06-21 04:45:36,600:INFO:   <<< local_rank: 0
2022-06-21 04:45:36,600:INFO:   <<< loose_type: True
2022-06-21 04:45:36,600:INFO:   <<< lr: 0.0001
2022-06-21 04:45:36,600:INFO:   <<< lr_decay: 0.9
2022-06-21 04:45:36,600:INFO:   <<< margin: 0.1
2022-06-21 04:45:36,600:INFO:   <<< max_frames: 16
2022-06-21 04:45:36,600:INFO:   <<< max_words: 32
2022-06-21 04:45:36,600:INFO:   <<< n_display: 50
2022-06-21 04:45:36,600:INFO:   <<< n_gpu: 1
2022-06-21 04:45:36,600:INFO:   <<< n_pair: 1
2022-06-21 04:45:36,600:INFO:   <<< negative_weighting: 1
2022-06-21 04:45:36,600:INFO:   <<< num_thread_reader: 2
2022-06-21 04:45:36,600:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:45:36,600:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:45:36,601:INFO:   <<< rank: 0
2022-06-21 04:45:36,601:INFO:   <<< resume_model: None
2022-06-21 04:45:36,601:INFO:   <<< sampled_use_mil: False
2022-06-21 04:45:36,601:INFO:   <<< seed: 42
2022-06-21 04:45:36,601:INFO:   <<< sim_header: meanP
2022-06-21 04:45:36,601:INFO:   <<< slice_framepos: 2
2022-06-21 04:45:36,601:INFO:   <<< task_type: retrieval
2022-06-21 04:45:36,601:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:45:36,601:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:45:36,601:INFO:   <<< train_frame_order: 0
2022-06-21 04:45:36,601:INFO:   <<< use_mil: False
2022-06-21 04:45:36,601:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:45:36,601:INFO:   <<< video_dim: 1024
2022-06-21 04:45:36,601:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:45:36,601:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:45:36,601:INFO:   <<< world_size: 1
2022-06-21 04:45:36,602:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:45:37,369:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:45:37,370:WARNING: Test retrieval by loose type.
2022-06-21 04:45:37,370:WARNING: 	 embed_dim: 512
2022-06-21 04:45:37,370:WARNING: 	 image_resolution: 224
2022-06-21 04:45:37,370:WARNING: 	 vision_layers: 12
2022-06-21 04:45:37,370:WARNING: 	 vision_width: 768
2022-06-21 04:45:37,370:WARNING: 	 vision_patch_size: 32
2022-06-21 04:45:37,370:WARNING: 	 context_length: 77
2022-06-21 04:45:37,370:WARNING: 	 vocab_size: 49408
2022-06-21 04:45:37,370:WARNING: 	 transformer_width: 512
2022-06-21 04:45:37,370:WARNING: 	 transformer_heads: 8
2022-06-21 04:45:37,370:WARNING: 	 transformer_layers: 12
2022-06-21 04:45:37,370:WARNING: 		 linear_patch: 3d
2022-06-21 04:45:37,370:WARNING: 	 cut_top_layer: 0
2022-06-21 04:45:45,112:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:45:57,707:INFO: ***** Running test *****
2022-06-21 04:45:57,707:INFO:   Num examples = 27763
2022-06-21 04:45:57,707:INFO:   Batch size = 16
2022-06-21 04:45:57,707:INFO:   Num steps = 1736
2022-06-21 04:45:57,707:INFO: ***** Running val *****
2022-06-21 04:45:57,707:INFO:   Num examples = 4290
2022-06-21 04:45:59,557:INFO: ***** Running training *****
2022-06-21 04:45:59,557:INFO:   Num examples = 48774
2022-06-21 04:45:59,557:INFO:   Batch size = 128
2022-06-21 04:45:59,557:INFO:   Num steps = 3810
2022-06-21 04:48:26,888:INFO: Effective parameters:
2022-06-21 04:48:26,889:INFO:   <<< batch_size: 128
2022-06-21 04:48:26,889:INFO:   <<< batch_size_val: 16
2022-06-21 04:48:26,889:INFO:   <<< cache_dir: 
2022-06-21 04:48:26,889:INFO:   <<< coef_lr: 0.001
2022-06-21 04:48:26,889:INFO:   <<< cross_model: cross-base
2022-06-21 04:48:26,889:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:48:26,889:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:48:26,889:INFO:   <<< datatype: msvd
2022-06-21 04:48:26,889:INFO:   <<< do_eval: False
2022-06-21 04:48:26,889:INFO:   <<< do_lower_case: False
2022-06-21 04:48:26,889:INFO:   <<< do_pretrain: False
2022-06-21 04:48:26,890:INFO:   <<< do_train: True
2022-06-21 04:48:26,890:INFO:   <<< epochs: 5
2022-06-21 04:48:26,890:INFO:   <<< eval_frame_order: 0
2022-06-21 04:48:26,890:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:48:26,890:INFO:   <<< feature_framerate: 1
2022-06-21 04:48:26,890:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:48:26,890:INFO:   <<< fp16: False
2022-06-21 04:48:26,890:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:48:26,890:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:48:26,890:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:48:26,890:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:48:26,890:INFO:   <<< init_model: None
2022-06-21 04:48:26,890:INFO:   <<< linear_patch: 3d
2022-06-21 04:48:26,891:INFO:   <<< local_rank: 0
2022-06-21 04:48:26,891:INFO:   <<< loose_type: True
2022-06-21 04:48:26,891:INFO:   <<< lr: 0.0001
2022-06-21 04:48:26,891:INFO:   <<< lr_decay: 0.9
2022-06-21 04:48:26,891:INFO:   <<< margin: 0.1
2022-06-21 04:48:26,891:INFO:   <<< max_frames: 16
2022-06-21 04:48:26,891:INFO:   <<< max_words: 32
2022-06-21 04:48:26,891:INFO:   <<< n_display: 50
2022-06-21 04:48:26,891:INFO:   <<< n_gpu: 1
2022-06-21 04:48:26,891:INFO:   <<< n_pair: 1
2022-06-21 04:48:26,891:INFO:   <<< negative_weighting: 1
2022-06-21 04:48:26,891:INFO:   <<< num_thread_reader: 2
2022-06-21 04:48:26,891:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:48:26,891:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:48:26,891:INFO:   <<< rank: 0
2022-06-21 04:48:26,892:INFO:   <<< resume_model: None
2022-06-21 04:48:26,892:INFO:   <<< sampled_use_mil: False
2022-06-21 04:48:26,892:INFO:   <<< seed: 42
2022-06-21 04:48:26,892:INFO:   <<< sim_header: meanP
2022-06-21 04:48:26,892:INFO:   <<< slice_framepos: 2
2022-06-21 04:48:26,892:INFO:   <<< task_type: retrieval
2022-06-21 04:48:26,892:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:48:26,892:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:48:26,892:INFO:   <<< train_frame_order: 0
2022-06-21 04:48:26,892:INFO:   <<< use_mil: False
2022-06-21 04:48:26,892:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:48:26,892:INFO:   <<< video_dim: 1024
2022-06-21 04:48:26,892:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:48:26,892:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:48:26,892:INFO:   <<< world_size: 1
2022-06-21 04:48:26,893:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:48:27,855:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:48:27,855:WARNING: Test retrieval by loose type.
2022-06-21 04:48:27,855:WARNING: 	 embed_dim: 512
2022-06-21 04:48:27,856:WARNING: 	 image_resolution: 224
2022-06-21 04:48:27,856:WARNING: 	 vision_layers: 12
2022-06-21 04:48:27,856:WARNING: 	 vision_width: 768
2022-06-21 04:48:27,856:WARNING: 	 vision_patch_size: 32
2022-06-21 04:48:27,856:WARNING: 	 context_length: 77
2022-06-21 04:48:27,856:WARNING: 	 vocab_size: 49408
2022-06-21 04:48:27,856:WARNING: 	 transformer_width: 512
2022-06-21 04:48:27,856:WARNING: 	 transformer_heads: 8
2022-06-21 04:48:27,856:WARNING: 	 transformer_layers: 12
2022-06-21 04:48:27,856:WARNING: 		 linear_patch: 3d
2022-06-21 04:48:27,856:WARNING: 	 cut_top_layer: 0
2022-06-21 04:48:34,967:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:48:47,656:INFO: ***** Running test *****
2022-06-21 04:48:47,657:INFO:   Num examples = 27763
2022-06-21 04:48:47,657:INFO:   Batch size = 16
2022-06-21 04:48:47,657:INFO:   Num steps = 1736
2022-06-21 04:48:47,657:INFO: ***** Running val *****
2022-06-21 04:48:47,657:INFO:   Num examples = 4290
2022-06-21 04:48:48,497:INFO: ***** Running training *****
2022-06-21 04:48:48,497:INFO:   Num examples = 48774
2022-06-21 04:48:48,497:INFO:   Batch size = 128
2022-06-21 04:48:48,497:INFO:   Num steps = 3810
2022-06-21 04:51:01,687:INFO: Effective parameters:
2022-06-21 04:51:01,687:INFO:   <<< batch_size: 128
2022-06-21 04:51:01,687:INFO:   <<< batch_size_val: 16
2022-06-21 04:51:01,687:INFO:   <<< cache_dir: 
2022-06-21 04:51:01,687:INFO:   <<< coef_lr: 0.001
2022-06-21 04:51:01,687:INFO:   <<< cross_model: cross-base
2022-06-21 04:51:01,687:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:51:01,687:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:51:01,687:INFO:   <<< datatype: msvd
2022-06-21 04:51:01,687:INFO:   <<< do_eval: False
2022-06-21 04:51:01,687:INFO:   <<< do_lower_case: False
2022-06-21 04:51:01,687:INFO:   <<< do_pretrain: False
2022-06-21 04:51:01,687:INFO:   <<< do_train: True
2022-06-21 04:51:01,687:INFO:   <<< epochs: 5
2022-06-21 04:51:01,687:INFO:   <<< eval_frame_order: 0
2022-06-21 04:51:01,687:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:51:01,687:INFO:   <<< feature_framerate: 1
2022-06-21 04:51:01,687:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:51:01,687:INFO:   <<< fp16: False
2022-06-21 04:51:01,687:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:51:01,688:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:51:01,688:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:51:01,688:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:51:01,688:INFO:   <<< init_model: None
2022-06-21 04:51:01,688:INFO:   <<< linear_patch: 3d
2022-06-21 04:51:01,688:INFO:   <<< local_rank: 0
2022-06-21 04:51:01,688:INFO:   <<< loose_type: True
2022-06-21 04:51:01,688:INFO:   <<< lr: 0.0001
2022-06-21 04:51:01,688:INFO:   <<< lr_decay: 0.9
2022-06-21 04:51:01,688:INFO:   <<< margin: 0.1
2022-06-21 04:51:01,688:INFO:   <<< max_frames: 16
2022-06-21 04:51:01,688:INFO:   <<< max_words: 32
2022-06-21 04:51:01,688:INFO:   <<< n_display: 50
2022-06-21 04:51:01,688:INFO:   <<< n_gpu: 1
2022-06-21 04:51:01,688:INFO:   <<< n_pair: 1
2022-06-21 04:51:01,688:INFO:   <<< negative_weighting: 1
2022-06-21 04:51:01,688:INFO:   <<< num_thread_reader: 2
2022-06-21 04:51:01,688:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:51:01,688:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:51:01,688:INFO:   <<< rank: 0
2022-06-21 04:51:01,688:INFO:   <<< resume_model: None
2022-06-21 04:51:01,688:INFO:   <<< sampled_use_mil: False
2022-06-21 04:51:01,688:INFO:   <<< seed: 42
2022-06-21 04:51:01,688:INFO:   <<< sim_header: meanP
2022-06-21 04:51:01,688:INFO:   <<< slice_framepos: 2
2022-06-21 04:51:01,688:INFO:   <<< task_type: retrieval
2022-06-21 04:51:01,688:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:51:01,688:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:51:01,688:INFO:   <<< train_frame_order: 0
2022-06-21 04:51:01,688:INFO:   <<< use_mil: False
2022-06-21 04:51:01,689:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:51:01,689:INFO:   <<< video_dim: 1024
2022-06-21 04:51:01,689:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:51:01,689:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:51:01,689:INFO:   <<< world_size: 1
2022-06-21 04:51:01,689:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:51:02,692:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:51:02,693:WARNING: Test retrieval by loose type.
2022-06-21 04:51:02,693:WARNING: 	 embed_dim: 512
2022-06-21 04:51:02,693:WARNING: 	 image_resolution: 224
2022-06-21 04:51:02,693:WARNING: 	 vision_layers: 12
2022-06-21 04:51:02,693:WARNING: 	 vision_width: 768
2022-06-21 04:51:02,693:WARNING: 	 vision_patch_size: 32
2022-06-21 04:51:02,693:WARNING: 	 context_length: 77
2022-06-21 04:51:02,694:WARNING: 	 vocab_size: 49408
2022-06-21 04:51:02,694:WARNING: 	 transformer_width: 512
2022-06-21 04:51:02,694:WARNING: 	 transformer_heads: 8
2022-06-21 04:51:02,694:WARNING: 	 transformer_layers: 12
2022-06-21 04:51:02,694:WARNING: 		 linear_patch: 3d
2022-06-21 04:51:02,694:WARNING: 	 cut_top_layer: 0
2022-06-21 04:51:09,939:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:51:22,183:INFO: ***** Running test *****
2022-06-21 04:51:22,184:INFO:   Num examples = 27763
2022-06-21 04:51:22,184:INFO:   Batch size = 16
2022-06-21 04:51:22,184:INFO:   Num steps = 1736
2022-06-21 04:51:22,184:INFO: ***** Running val *****
2022-06-21 04:51:22,184:INFO:   Num examples = 4290
2022-06-21 04:51:23,871:INFO: ***** Running training *****
2022-06-21 04:51:23,872:INFO:   Num examples = 48774
2022-06-21 04:51:23,872:INFO:   Batch size = 128
2022-06-21 04:51:23,872:INFO:   Num steps = 3810
2022-06-21 04:52:45,061:INFO: Effective parameters:
2022-06-21 04:52:45,062:INFO:   <<< batch_size: 128
2022-06-21 04:52:45,062:INFO:   <<< batch_size_val: 16
2022-06-21 04:52:45,062:INFO:   <<< cache_dir: 
2022-06-21 04:52:45,062:INFO:   <<< coef_lr: 0.001
2022-06-21 04:52:45,062:INFO:   <<< cross_model: cross-base
2022-06-21 04:52:45,062:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:52:45,062:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:52:45,062:INFO:   <<< datatype: msvd
2022-06-21 04:52:45,062:INFO:   <<< do_eval: False
2022-06-21 04:52:45,062:INFO:   <<< do_lower_case: False
2022-06-21 04:52:45,062:INFO:   <<< do_pretrain: False
2022-06-21 04:52:45,062:INFO:   <<< do_train: True
2022-06-21 04:52:45,062:INFO:   <<< epochs: 5
2022-06-21 04:52:45,062:INFO:   <<< eval_frame_order: 0
2022-06-21 04:52:45,062:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:52:45,062:INFO:   <<< feature_framerate: 1
2022-06-21 04:52:45,062:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:52:45,062:INFO:   <<< fp16: False
2022-06-21 04:52:45,062:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:52:45,062:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:52:45,062:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:52:45,062:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:52:45,062:INFO:   <<< init_model: None
2022-06-21 04:52:45,062:INFO:   <<< linear_patch: 3d
2022-06-21 04:52:45,062:INFO:   <<< local_rank: 0
2022-06-21 04:52:45,063:INFO:   <<< loose_type: True
2022-06-21 04:52:45,063:INFO:   <<< lr: 0.0001
2022-06-21 04:52:45,063:INFO:   <<< lr_decay: 0.9
2022-06-21 04:52:45,063:INFO:   <<< margin: 0.1
2022-06-21 04:52:45,063:INFO:   <<< max_frames: 16
2022-06-21 04:52:45,063:INFO:   <<< max_words: 32
2022-06-21 04:52:45,063:INFO:   <<< n_display: 50
2022-06-21 04:52:45,063:INFO:   <<< n_gpu: 1
2022-06-21 04:52:45,063:INFO:   <<< n_pair: 1
2022-06-21 04:52:45,063:INFO:   <<< negative_weighting: 1
2022-06-21 04:52:45,063:INFO:   <<< num_thread_reader: 2
2022-06-21 04:52:45,063:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:52:45,063:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:52:45,063:INFO:   <<< rank: 0
2022-06-21 04:52:45,063:INFO:   <<< resume_model: None
2022-06-21 04:52:45,063:INFO:   <<< sampled_use_mil: False
2022-06-21 04:52:45,063:INFO:   <<< seed: 42
2022-06-21 04:52:45,063:INFO:   <<< sim_header: meanP
2022-06-21 04:52:45,063:INFO:   <<< slice_framepos: 2
2022-06-21 04:52:45,063:INFO:   <<< task_type: retrieval
2022-06-21 04:52:45,063:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:52:45,063:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:52:45,063:INFO:   <<< train_frame_order: 0
2022-06-21 04:52:45,063:INFO:   <<< use_mil: False
2022-06-21 04:52:45,063:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:52:45,063:INFO:   <<< video_dim: 1024
2022-06-21 04:52:45,063:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:52:45,063:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:52:45,063:INFO:   <<< world_size: 1
2022-06-21 04:52:45,063:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:52:45,771:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:52:45,771:WARNING: Test retrieval by loose type.
2022-06-21 04:52:45,771:WARNING: 	 embed_dim: 512
2022-06-21 04:52:45,772:WARNING: 	 image_resolution: 224
2022-06-21 04:52:45,772:WARNING: 	 vision_layers: 12
2022-06-21 04:52:45,772:WARNING: 	 vision_width: 768
2022-06-21 04:52:45,772:WARNING: 	 vision_patch_size: 32
2022-06-21 04:52:45,772:WARNING: 	 context_length: 77
2022-06-21 04:52:45,772:WARNING: 	 vocab_size: 49408
2022-06-21 04:52:45,772:WARNING: 	 transformer_width: 512
2022-06-21 04:52:45,772:WARNING: 	 transformer_heads: 8
2022-06-21 04:52:45,772:WARNING: 	 transformer_layers: 12
2022-06-21 04:52:45,772:WARNING: 		 linear_patch: 3d
2022-06-21 04:52:45,772:WARNING: 	 cut_top_layer: 0
2022-06-21 04:52:53,405:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:53:07,311:INFO: ***** Running test *****
2022-06-21 04:53:07,311:INFO:   Num examples = 27763
2022-06-21 04:53:07,311:INFO:   Batch size = 16
2022-06-21 04:53:07,311:INFO:   Num steps = 1736
2022-06-21 04:53:07,311:INFO: ***** Running val *****
2022-06-21 04:53:07,311:INFO:   Num examples = 4290
2022-06-21 04:53:08,989:INFO: ***** Running training *****
2022-06-21 04:53:08,989:INFO:   Num examples = 48774
2022-06-21 04:53:08,990:INFO:   Batch size = 128
2022-06-21 04:53:08,990:INFO:   Num steps = 3810
2022-06-21 04:54:39,616:INFO: Effective parameters:
2022-06-21 04:54:39,616:INFO:   <<< batch_size: 128
2022-06-21 04:54:39,616:INFO:   <<< batch_size_val: 16
2022-06-21 04:54:39,616:INFO:   <<< cache_dir: 
2022-06-21 04:54:39,616:INFO:   <<< coef_lr: 0.001
2022-06-21 04:54:39,616:INFO:   <<< cross_model: cross-base
2022-06-21 04:54:39,616:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:54:39,616:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:54:39,616:INFO:   <<< datatype: msvd
2022-06-21 04:54:39,616:INFO:   <<< do_eval: False
2022-06-21 04:54:39,616:INFO:   <<< do_lower_case: False
2022-06-21 04:54:39,617:INFO:   <<< do_pretrain: False
2022-06-21 04:54:39,617:INFO:   <<< do_train: True
2022-06-21 04:54:39,617:INFO:   <<< epochs: 5
2022-06-21 04:54:39,617:INFO:   <<< eval_frame_order: 0
2022-06-21 04:54:39,617:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:54:39,617:INFO:   <<< feature_framerate: 1
2022-06-21 04:54:39,617:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:54:39,617:INFO:   <<< fp16: False
2022-06-21 04:54:39,617:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:54:39,617:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:54:39,617:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:54:39,617:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:54:39,617:INFO:   <<< init_model: None
2022-06-21 04:54:39,617:INFO:   <<< linear_patch: 3d
2022-06-21 04:54:39,617:INFO:   <<< local_rank: 0
2022-06-21 04:54:39,617:INFO:   <<< loose_type: True
2022-06-21 04:54:39,617:INFO:   <<< lr: 0.0001
2022-06-21 04:54:39,617:INFO:   <<< lr_decay: 0.9
2022-06-21 04:54:39,617:INFO:   <<< margin: 0.1
2022-06-21 04:54:39,617:INFO:   <<< max_frames: 16
2022-06-21 04:54:39,618:INFO:   <<< max_words: 32
2022-06-21 04:54:39,618:INFO:   <<< n_display: 50
2022-06-21 04:54:39,618:INFO:   <<< n_gpu: 1
2022-06-21 04:54:39,618:INFO:   <<< n_pair: 1
2022-06-21 04:54:39,618:INFO:   <<< negative_weighting: 1
2022-06-21 04:54:39,618:INFO:   <<< num_thread_reader: 2
2022-06-21 04:54:39,618:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:54:39,618:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:54:39,618:INFO:   <<< rank: 0
2022-06-21 04:54:39,618:INFO:   <<< resume_model: None
2022-06-21 04:54:39,618:INFO:   <<< sampled_use_mil: False
2022-06-21 04:54:39,618:INFO:   <<< seed: 42
2022-06-21 04:54:39,618:INFO:   <<< sim_header: meanP
2022-06-21 04:54:39,618:INFO:   <<< slice_framepos: 2
2022-06-21 04:54:39,618:INFO:   <<< task_type: retrieval
2022-06-21 04:54:39,618:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:54:39,618:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:54:39,618:INFO:   <<< train_frame_order: 0
2022-06-21 04:54:39,618:INFO:   <<< use_mil: False
2022-06-21 04:54:39,618:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:54:39,619:INFO:   <<< video_dim: 1024
2022-06-21 04:54:39,619:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:54:39,619:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:54:39,619:INFO:   <<< world_size: 1
2022-06-21 04:54:39,619:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:54:40,309:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:54:40,310:WARNING: Test retrieval by loose type.
2022-06-21 04:54:40,310:WARNING: 	 embed_dim: 512
2022-06-21 04:54:40,310:WARNING: 	 image_resolution: 224
2022-06-21 04:54:40,310:WARNING: 	 vision_layers: 12
2022-06-21 04:54:40,310:WARNING: 	 vision_width: 768
2022-06-21 04:54:40,310:WARNING: 	 vision_patch_size: 32
2022-06-21 04:54:40,310:WARNING: 	 context_length: 77
2022-06-21 04:54:40,310:WARNING: 	 vocab_size: 49408
2022-06-21 04:54:40,310:WARNING: 	 transformer_width: 512
2022-06-21 04:54:40,310:WARNING: 	 transformer_heads: 8
2022-06-21 04:54:40,310:WARNING: 	 transformer_layers: 12
2022-06-21 04:54:40,310:WARNING: 		 linear_patch: 3d
2022-06-21 04:54:40,310:WARNING: 	 cut_top_layer: 0
2022-06-21 04:54:47,761:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:55:04,368:INFO: ***** Running test *****
2022-06-21 04:55:04,368:INFO:   Num examples = 27763
2022-06-21 04:55:04,368:INFO:   Batch size = 16
2022-06-21 04:55:04,368:INFO:   Num steps = 1736
2022-06-21 04:55:04,368:INFO: ***** Running val *****
2022-06-21 04:55:04,369:INFO:   Num examples = 4290
2022-06-21 04:55:06,541:INFO: ***** Running training *****
2022-06-21 04:55:06,541:INFO:   Num examples = 48774
2022-06-21 04:55:06,541:INFO:   Batch size = 128
2022-06-21 04:55:06,541:INFO:   Num steps = 3810
2022-06-21 04:57:22,345:INFO: Effective parameters:
2022-06-21 04:57:22,345:INFO:   <<< batch_size: 128
2022-06-21 04:57:22,345:INFO:   <<< batch_size_val: 16
2022-06-21 04:57:22,345:INFO:   <<< cache_dir: 
2022-06-21 04:57:22,345:INFO:   <<< coef_lr: 0.001
2022-06-21 04:57:22,346:INFO:   <<< cross_model: cross-base
2022-06-21 04:57:22,346:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 04:57:22,346:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 04:57:22,346:INFO:   <<< datatype: msvd
2022-06-21 04:57:22,346:INFO:   <<< do_eval: False
2022-06-21 04:57:22,346:INFO:   <<< do_lower_case: False
2022-06-21 04:57:22,346:INFO:   <<< do_pretrain: False
2022-06-21 04:57:22,346:INFO:   <<< do_train: True
2022-06-21 04:57:22,346:INFO:   <<< epochs: 5
2022-06-21 04:57:22,346:INFO:   <<< eval_frame_order: 0
2022-06-21 04:57:22,346:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 04:57:22,346:INFO:   <<< feature_framerate: 1
2022-06-21 04:57:22,346:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 04:57:22,346:INFO:   <<< fp16: False
2022-06-21 04:57:22,346:INFO:   <<< fp16_opt_level: O1
2022-06-21 04:57:22,346:INFO:   <<< freeze_layer_num: 0
2022-06-21 04:57:22,347:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 04:57:22,347:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 04:57:22,347:INFO:   <<< init_model: None
2022-06-21 04:57:22,347:INFO:   <<< linear_patch: 3d
2022-06-21 04:57:22,347:INFO:   <<< local_rank: 0
2022-06-21 04:57:22,347:INFO:   <<< loose_type: True
2022-06-21 04:57:22,347:INFO:   <<< lr: 0.0001
2022-06-21 04:57:22,347:INFO:   <<< lr_decay: 0.9
2022-06-21 04:57:22,347:INFO:   <<< margin: 0.1
2022-06-21 04:57:22,347:INFO:   <<< max_frames: 16
2022-06-21 04:57:22,347:INFO:   <<< max_words: 32
2022-06-21 04:57:22,347:INFO:   <<< n_display: 50
2022-06-21 04:57:22,347:INFO:   <<< n_gpu: 1
2022-06-21 04:57:22,347:INFO:   <<< n_pair: 1
2022-06-21 04:57:22,347:INFO:   <<< negative_weighting: 1
2022-06-21 04:57:22,347:INFO:   <<< num_thread_reader: 2
2022-06-21 04:57:22,347:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 04:57:22,347:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 04:57:22,347:INFO:   <<< rank: 0
2022-06-21 04:57:22,347:INFO:   <<< resume_model: None
2022-06-21 04:57:22,348:INFO:   <<< sampled_use_mil: False
2022-06-21 04:57:22,348:INFO:   <<< seed: 42
2022-06-21 04:57:22,348:INFO:   <<< sim_header: meanP
2022-06-21 04:57:22,348:INFO:   <<< slice_framepos: 2
2022-06-21 04:57:22,348:INFO:   <<< task_type: retrieval
2022-06-21 04:57:22,348:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 04:57:22,348:INFO:   <<< train_csv: data/.train.csv
2022-06-21 04:57:22,348:INFO:   <<< train_frame_order: 0
2022-06-21 04:57:22,348:INFO:   <<< use_mil: False
2022-06-21 04:57:22,348:INFO:   <<< val_csv: data/.val.csv
2022-06-21 04:57:22,348:INFO:   <<< video_dim: 1024
2022-06-21 04:57:22,348:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 04:57:22,348:INFO:   <<< warmup_proportion: 0.1
2022-06-21 04:57:22,348:INFO:   <<< world_size: 1
2022-06-21 04:57:22,348:INFO: device: cuda:0 n_gpu: 2
2022-06-21 04:57:23,087:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 04:57:23,087:WARNING: Test retrieval by loose type.
2022-06-21 04:57:23,088:WARNING: 	 embed_dim: 512
2022-06-21 04:57:23,088:WARNING: 	 image_resolution: 224
2022-06-21 04:57:23,088:WARNING: 	 vision_layers: 12
2022-06-21 04:57:23,088:WARNING: 	 vision_width: 768
2022-06-21 04:57:23,088:WARNING: 	 vision_patch_size: 32
2022-06-21 04:57:23,088:WARNING: 	 context_length: 77
2022-06-21 04:57:23,088:WARNING: 	 vocab_size: 49408
2022-06-21 04:57:23,088:WARNING: 	 transformer_width: 512
2022-06-21 04:57:23,088:WARNING: 	 transformer_heads: 8
2022-06-21 04:57:23,088:WARNING: 	 transformer_layers: 12
2022-06-21 04:57:23,088:WARNING: 		 linear_patch: 3d
2022-06-21 04:57:23,088:WARNING: 	 cut_top_layer: 0
2022-06-21 04:57:30,190:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 04:57:43,434:INFO: ***** Running test *****
2022-06-21 04:57:43,435:INFO:   Num examples = 27763
2022-06-21 04:57:43,435:INFO:   Batch size = 16
2022-06-21 04:57:43,435:INFO:   Num steps = 1736
2022-06-21 04:57:43,435:INFO: ***** Running val *****
2022-06-21 04:57:43,435:INFO:   Num examples = 4290
2022-06-21 04:57:45,556:INFO: ***** Running training *****
2022-06-21 04:57:45,556:INFO:   Num examples = 48774
2022-06-21 04:57:45,556:INFO:   Batch size = 128
2022-06-21 04:57:45,556:INFO:   Num steps = 3810
2022-06-21 05:01:18,541:INFO: Effective parameters:
2022-06-21 05:01:18,542:INFO:   <<< batch_size: 128
2022-06-21 05:01:18,542:INFO:   <<< batch_size_val: 16
2022-06-21 05:01:18,542:INFO:   <<< cache_dir: 
2022-06-21 05:01:18,542:INFO:   <<< coef_lr: 0.001
2022-06-21 05:01:18,542:INFO:   <<< cross_model: cross-base
2022-06-21 05:01:18,542:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 05:01:18,542:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 05:01:18,542:INFO:   <<< datatype: msvd
2022-06-21 05:01:18,542:INFO:   <<< do_eval: False
2022-06-21 05:01:18,542:INFO:   <<< do_lower_case: False
2022-06-21 05:01:18,542:INFO:   <<< do_pretrain: False
2022-06-21 05:01:18,542:INFO:   <<< do_train: True
2022-06-21 05:01:18,542:INFO:   <<< epochs: 5
2022-06-21 05:01:18,542:INFO:   <<< eval_frame_order: 0
2022-06-21 05:01:18,542:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 05:01:18,543:INFO:   <<< feature_framerate: 1
2022-06-21 05:01:18,543:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 05:01:18,543:INFO:   <<< fp16: False
2022-06-21 05:01:18,543:INFO:   <<< fp16_opt_level: O1
2022-06-21 05:01:18,543:INFO:   <<< freeze_layer_num: 0
2022-06-21 05:01:18,543:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 05:01:18,543:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 05:01:18,543:INFO:   <<< init_model: None
2022-06-21 05:01:18,543:INFO:   <<< linear_patch: 3d
2022-06-21 05:01:18,543:INFO:   <<< local_rank: 0
2022-06-21 05:01:18,543:INFO:   <<< loose_type: True
2022-06-21 05:01:18,543:INFO:   <<< lr: 0.0001
2022-06-21 05:01:18,543:INFO:   <<< lr_decay: 0.9
2022-06-21 05:01:18,543:INFO:   <<< margin: 0.1
2022-06-21 05:01:18,543:INFO:   <<< max_frames: 16
2022-06-21 05:01:18,543:INFO:   <<< max_words: 32
2022-06-21 05:01:18,543:INFO:   <<< n_display: 50
2022-06-21 05:01:18,543:INFO:   <<< n_gpu: 1
2022-06-21 05:01:18,543:INFO:   <<< n_pair: 1
2022-06-21 05:01:18,543:INFO:   <<< negative_weighting: 1
2022-06-21 05:01:18,543:INFO:   <<< num_thread_reader: 2
2022-06-21 05:01:18,544:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 05:01:18,544:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 05:01:18,544:INFO:   <<< rank: 0
2022-06-21 05:01:18,544:INFO:   <<< resume_model: None
2022-06-21 05:01:18,544:INFO:   <<< sampled_use_mil: False
2022-06-21 05:01:18,544:INFO:   <<< seed: 42
2022-06-21 05:01:18,544:INFO:   <<< sim_header: meanP
2022-06-21 05:01:18,544:INFO:   <<< slice_framepos: 2
2022-06-21 05:01:18,544:INFO:   <<< task_type: retrieval
2022-06-21 05:01:18,544:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 05:01:18,544:INFO:   <<< train_csv: data/.train.csv
2022-06-21 05:01:18,544:INFO:   <<< train_frame_order: 0
2022-06-21 05:01:18,544:INFO:   <<< use_mil: False
2022-06-21 05:01:18,544:INFO:   <<< val_csv: data/.val.csv
2022-06-21 05:01:18,544:INFO:   <<< video_dim: 1024
2022-06-21 05:01:18,544:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 05:01:18,544:INFO:   <<< warmup_proportion: 0.1
2022-06-21 05:01:18,544:INFO:   <<< world_size: 1
2022-06-21 05:01:18,544:INFO: device: cuda:0 n_gpu: 2
2022-06-21 05:01:19,275:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 05:01:19,276:WARNING: Test retrieval by loose type.
2022-06-21 05:01:19,276:WARNING: 	 embed_dim: 512
2022-06-21 05:01:19,276:WARNING: 	 image_resolution: 224
2022-06-21 05:01:19,276:WARNING: 	 vision_layers: 12
2022-06-21 05:01:19,276:WARNING: 	 vision_width: 768
2022-06-21 05:01:19,276:WARNING: 	 vision_patch_size: 32
2022-06-21 05:01:19,276:WARNING: 	 context_length: 77
2022-06-21 05:01:19,276:WARNING: 	 vocab_size: 49408
2022-06-21 05:01:19,276:WARNING: 	 transformer_width: 512
2022-06-21 05:01:19,276:WARNING: 	 transformer_heads: 8
2022-06-21 05:01:19,276:WARNING: 	 transformer_layers: 12
2022-06-21 05:01:19,276:WARNING: 		 linear_patch: 3d
2022-06-21 05:01:19,276:WARNING: 	 cut_top_layer: 0
2022-06-21 05:01:27,076:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 05:01:40,529:INFO: ***** Running test *****
2022-06-21 05:01:40,530:INFO:   Num examples = 27763
2022-06-21 05:01:40,530:INFO:   Batch size = 16
2022-06-21 05:01:40,530:INFO:   Num steps = 1736
2022-06-21 05:01:40,530:INFO: ***** Running val *****
2022-06-21 05:01:40,530:INFO:   Num examples = 4290
2022-06-21 05:01:42,685:INFO: ***** Running training *****
2022-06-21 05:01:42,686:INFO:   Num examples = 48774
2022-06-21 05:01:42,686:INFO:   Batch size = 128
2022-06-21 05:01:42,686:INFO:   Num steps = 3810
2022-06-21 05:05:14,853:INFO: Effective parameters:
2022-06-21 05:05:14,853:INFO:   <<< batch_size: 128
2022-06-21 05:05:14,854:INFO:   <<< batch_size_val: 16
2022-06-21 05:05:14,854:INFO:   <<< cache_dir: 
2022-06-21 05:05:14,854:INFO:   <<< coef_lr: 0.001
2022-06-21 05:05:14,854:INFO:   <<< cross_model: cross-base
2022-06-21 05:05:14,854:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 05:05:14,854:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 05:05:14,854:INFO:   <<< datatype: msvd
2022-06-21 05:05:14,854:INFO:   <<< do_eval: False
2022-06-21 05:05:14,854:INFO:   <<< do_lower_case: False
2022-06-21 05:05:14,854:INFO:   <<< do_pretrain: False
2022-06-21 05:05:14,854:INFO:   <<< do_train: True
2022-06-21 05:05:14,854:INFO:   <<< epochs: 5
2022-06-21 05:05:14,855:INFO:   <<< eval_frame_order: 0
2022-06-21 05:05:14,855:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 05:05:14,855:INFO:   <<< feature_framerate: 1
2022-06-21 05:05:14,855:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 05:05:14,855:INFO:   <<< fp16: False
2022-06-21 05:05:14,855:INFO:   <<< fp16_opt_level: O1
2022-06-21 05:05:14,855:INFO:   <<< freeze_layer_num: 0
2022-06-21 05:05:14,855:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 05:05:14,855:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 05:05:14,855:INFO:   <<< init_model: None
2022-06-21 05:05:14,855:INFO:   <<< linear_patch: 3d
2022-06-21 05:05:14,855:INFO:   <<< local_rank: 0
2022-06-21 05:05:14,855:INFO:   <<< loose_type: True
2022-06-21 05:05:14,855:INFO:   <<< lr: 0.0001
2022-06-21 05:05:14,855:INFO:   <<< lr_decay: 0.9
2022-06-21 05:05:14,856:INFO:   <<< margin: 0.1
2022-06-21 05:05:14,856:INFO:   <<< max_frames: 16
2022-06-21 05:05:14,856:INFO:   <<< max_words: 32
2022-06-21 05:05:14,856:INFO:   <<< n_display: 50
2022-06-21 05:05:14,856:INFO:   <<< n_gpu: 1
2022-06-21 05:05:14,856:INFO:   <<< n_pair: 1
2022-06-21 05:05:14,856:INFO:   <<< negative_weighting: 1
2022-06-21 05:05:14,856:INFO:   <<< num_thread_reader: 2
2022-06-21 05:05:14,856:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 05:05:14,856:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 05:05:14,856:INFO:   <<< rank: 0
2022-06-21 05:05:14,856:INFO:   <<< resume_model: None
2022-06-21 05:05:14,856:INFO:   <<< sampled_use_mil: False
2022-06-21 05:05:14,856:INFO:   <<< seed: 42
2022-06-21 05:05:14,856:INFO:   <<< sim_header: meanP
2022-06-21 05:05:14,857:INFO:   <<< slice_framepos: 2
2022-06-21 05:05:14,857:INFO:   <<< task_type: retrieval
2022-06-21 05:05:14,857:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 05:05:14,857:INFO:   <<< train_csv: data/.train.csv
2022-06-21 05:05:14,857:INFO:   <<< train_frame_order: 0
2022-06-21 05:05:14,857:INFO:   <<< use_mil: False
2022-06-21 05:05:14,857:INFO:   <<< val_csv: data/.val.csv
2022-06-21 05:05:14,857:INFO:   <<< video_dim: 1024
2022-06-21 05:05:14,857:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 05:05:14,857:INFO:   <<< warmup_proportion: 0.1
2022-06-21 05:05:14,857:INFO:   <<< world_size: 1
2022-06-21 05:05:14,857:INFO: device: cuda:0 n_gpu: 2
2022-06-21 05:05:15,665:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 05:05:15,666:WARNING: Test retrieval by loose type.
2022-06-21 05:05:15,666:WARNING: 	 embed_dim: 512
2022-06-21 05:05:15,666:WARNING: 	 image_resolution: 224
2022-06-21 05:05:15,667:WARNING: 	 vision_layers: 12
2022-06-21 05:05:15,667:WARNING: 	 vision_width: 768
2022-06-21 05:05:15,667:WARNING: 	 vision_patch_size: 32
2022-06-21 05:05:15,667:WARNING: 	 context_length: 77
2022-06-21 05:05:15,667:WARNING: 	 vocab_size: 49408
2022-06-21 05:05:15,667:WARNING: 	 transformer_width: 512
2022-06-21 05:05:15,667:WARNING: 	 transformer_heads: 8
2022-06-21 05:05:15,667:WARNING: 	 transformer_layers: 12
2022-06-21 05:05:15,667:WARNING: 		 linear_patch: 3d
2022-06-21 05:05:15,667:WARNING: 	 cut_top_layer: 0
2022-06-21 05:05:22,773:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 05:05:36,014:INFO: ***** Running test *****
2022-06-21 05:05:36,014:INFO:   Num examples = 27763
2022-06-21 05:05:36,014:INFO:   Batch size = 16
2022-06-21 05:05:36,014:INFO:   Num steps = 1736
2022-06-21 05:05:36,014:INFO: ***** Running val *****
2022-06-21 05:05:36,014:INFO:   Num examples = 4290
2022-06-21 05:05:38,039:INFO: ***** Running training *****
2022-06-21 05:05:38,039:INFO:   Num examples = 48774
2022-06-21 05:05:38,039:INFO:   Batch size = 128
2022-06-21 05:05:38,039:INFO:   Num steps = 3810
2022-06-21 05:11:10,951:INFO: Effective parameters:
2022-06-21 05:11:10,952:INFO:   <<< batch_size: 128
2022-06-21 05:11:10,952:INFO:   <<< batch_size_val: 16
2022-06-21 05:11:10,952:INFO:   <<< cache_dir: 
2022-06-21 05:11:10,952:INFO:   <<< coef_lr: 0.001
2022-06-21 05:11:10,952:INFO:   <<< cross_model: cross-base
2022-06-21 05:11:10,952:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 05:11:10,952:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 05:11:10,952:INFO:   <<< datatype: msvd
2022-06-21 05:11:10,952:INFO:   <<< do_eval: False
2022-06-21 05:11:10,953:INFO:   <<< do_lower_case: False
2022-06-21 05:11:10,953:INFO:   <<< do_pretrain: False
2022-06-21 05:11:10,953:INFO:   <<< do_train: True
2022-06-21 05:11:10,953:INFO:   <<< epochs: 5
2022-06-21 05:11:10,953:INFO:   <<< eval_frame_order: 0
2022-06-21 05:11:10,953:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 05:11:10,953:INFO:   <<< feature_framerate: 1
2022-06-21 05:11:10,953:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 05:11:10,953:INFO:   <<< fp16: False
2022-06-21 05:11:10,953:INFO:   <<< fp16_opt_level: O1
2022-06-21 05:11:10,954:INFO:   <<< freeze_layer_num: 0
2022-06-21 05:11:10,954:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 05:11:10,954:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 05:11:10,954:INFO:   <<< init_model: None
2022-06-21 05:11:10,954:INFO:   <<< linear_patch: 3d
2022-06-21 05:11:10,954:INFO:   <<< local_rank: 0
2022-06-21 05:11:10,954:INFO:   <<< loose_type: True
2022-06-21 05:11:10,954:INFO:   <<< lr: 0.0001
2022-06-21 05:11:10,954:INFO:   <<< lr_decay: 0.9
2022-06-21 05:11:10,954:INFO:   <<< margin: 0.1
2022-06-21 05:11:10,955:INFO:   <<< max_frames: 16
2022-06-21 05:11:10,955:INFO:   <<< max_words: 32
2022-06-21 05:11:10,955:INFO:   <<< n_display: 50
2022-06-21 05:11:10,955:INFO:   <<< n_gpu: 1
2022-06-21 05:11:10,955:INFO:   <<< n_pair: 1
2022-06-21 05:11:10,955:INFO:   <<< negative_weighting: 1
2022-06-21 05:11:10,955:INFO:   <<< num_thread_reader: 2
2022-06-21 05:11:10,955:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 05:11:10,955:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 05:11:10,955:INFO:   <<< rank: 0
2022-06-21 05:11:10,955:INFO:   <<< resume_model: None
2022-06-21 05:11:10,956:INFO:   <<< sampled_use_mil: False
2022-06-21 05:11:10,956:INFO:   <<< seed: 42
2022-06-21 05:11:10,956:INFO:   <<< sim_header: meanP
2022-06-21 05:11:10,956:INFO:   <<< slice_framepos: 2
2022-06-21 05:11:10,956:INFO:   <<< task_type: retrieval
2022-06-21 05:11:10,956:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 05:11:10,956:INFO:   <<< train_csv: data/.train.csv
2022-06-21 05:11:10,956:INFO:   <<< train_frame_order: 0
2022-06-21 05:11:10,956:INFO:   <<< use_mil: False
2022-06-21 05:11:10,956:INFO:   <<< val_csv: data/.val.csv
2022-06-21 05:11:10,956:INFO:   <<< video_dim: 1024
2022-06-21 05:11:10,957:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 05:11:10,957:INFO:   <<< warmup_proportion: 0.1
2022-06-21 05:11:10,957:INFO:   <<< world_size: 1
2022-06-21 05:11:10,957:INFO: device: cuda:0 n_gpu: 2
2022-06-21 05:11:11,663:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 05:11:11,663:WARNING: Test retrieval by loose type.
2022-06-21 05:11:11,664:WARNING: 	 embed_dim: 512
2022-06-21 05:11:11,664:WARNING: 	 image_resolution: 224
2022-06-21 05:11:11,664:WARNING: 	 vision_layers: 12
2022-06-21 05:11:11,664:WARNING: 	 vision_width: 768
2022-06-21 05:11:11,664:WARNING: 	 vision_patch_size: 32
2022-06-21 05:11:11,664:WARNING: 	 context_length: 77
2022-06-21 05:11:11,664:WARNING: 	 vocab_size: 49408
2022-06-21 05:11:11,664:WARNING: 	 transformer_width: 512
2022-06-21 05:11:11,664:WARNING: 	 transformer_heads: 8
2022-06-21 05:11:11,664:WARNING: 	 transformer_layers: 12
2022-06-21 05:11:11,664:WARNING: 		 linear_patch: 3d
2022-06-21 05:11:11,664:WARNING: 	 cut_top_layer: 0
2022-06-21 05:11:18,821:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 05:11:32,559:INFO: ***** Running test *****
2022-06-21 05:11:32,560:INFO:   Num examples = 27763
2022-06-21 05:11:32,560:INFO:   Batch size = 16
2022-06-21 05:11:32,560:INFO:   Num steps = 1736
2022-06-21 05:11:32,560:INFO: ***** Running val *****
2022-06-21 05:11:32,560:INFO:   Num examples = 4290
2022-06-21 05:11:34,809:INFO: ***** Running training *****
2022-06-21 05:11:34,810:INFO:   Num examples = 48774
2022-06-21 05:11:34,810:INFO:   Batch size = 128
2022-06-21 05:11:34,810:INFO:   Num steps = 3810
2022-06-21 05:13:14,391:INFO: Effective parameters:
2022-06-21 05:13:14,391:INFO:   <<< batch_size: 128
2022-06-21 05:13:14,391:INFO:   <<< batch_size_val: 16
2022-06-21 05:13:14,391:INFO:   <<< cache_dir: 
2022-06-21 05:13:14,392:INFO:   <<< coef_lr: 0.001
2022-06-21 05:13:14,392:INFO:   <<< cross_model: cross-base
2022-06-21 05:13:14,392:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 05:13:14,392:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 05:13:14,392:INFO:   <<< datatype: msvd
2022-06-21 05:13:14,392:INFO:   <<< do_eval: False
2022-06-21 05:13:14,392:INFO:   <<< do_lower_case: False
2022-06-21 05:13:14,392:INFO:   <<< do_pretrain: False
2022-06-21 05:13:14,392:INFO:   <<< do_train: True
2022-06-21 05:13:14,392:INFO:   <<< epochs: 5
2022-06-21 05:13:14,392:INFO:   <<< eval_frame_order: 0
2022-06-21 05:13:14,392:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 05:13:14,392:INFO:   <<< feature_framerate: 1
2022-06-21 05:13:14,392:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 05:13:14,393:INFO:   <<< fp16: False
2022-06-21 05:13:14,393:INFO:   <<< fp16_opt_level: O1
2022-06-21 05:13:14,393:INFO:   <<< freeze_layer_num: 0
2022-06-21 05:13:14,393:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 05:13:14,393:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 05:13:14,393:INFO:   <<< init_model: None
2022-06-21 05:13:14,393:INFO:   <<< linear_patch: 3d
2022-06-21 05:13:14,393:INFO:   <<< local_rank: 0
2022-06-21 05:13:14,393:INFO:   <<< loose_type: True
2022-06-21 05:13:14,393:INFO:   <<< lr: 0.0001
2022-06-21 05:13:14,393:INFO:   <<< lr_decay: 0.9
2022-06-21 05:13:14,393:INFO:   <<< margin: 0.1
2022-06-21 05:13:14,393:INFO:   <<< max_frames: 16
2022-06-21 05:13:14,393:INFO:   <<< max_words: 32
2022-06-21 05:13:14,393:INFO:   <<< n_display: 50
2022-06-21 05:13:14,394:INFO:   <<< n_gpu: 1
2022-06-21 05:13:14,394:INFO:   <<< n_pair: 1
2022-06-21 05:13:14,394:INFO:   <<< negative_weighting: 1
2022-06-21 05:13:14,394:INFO:   <<< num_thread_reader: 2
2022-06-21 05:13:14,394:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 05:13:14,394:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 05:13:14,394:INFO:   <<< rank: 0
2022-06-21 05:13:14,394:INFO:   <<< resume_model: None
2022-06-21 05:13:14,394:INFO:   <<< sampled_use_mil: False
2022-06-21 05:13:14,394:INFO:   <<< seed: 42
2022-06-21 05:13:14,394:INFO:   <<< sim_header: meanP
2022-06-21 05:13:14,394:INFO:   <<< slice_framepos: 2
2022-06-21 05:13:14,394:INFO:   <<< task_type: retrieval
2022-06-21 05:13:14,394:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 05:13:14,395:INFO:   <<< train_csv: data/.train.csv
2022-06-21 05:13:14,395:INFO:   <<< train_frame_order: 0
2022-06-21 05:13:14,395:INFO:   <<< use_mil: False
2022-06-21 05:13:14,395:INFO:   <<< val_csv: data/.val.csv
2022-06-21 05:13:14,395:INFO:   <<< video_dim: 1024
2022-06-21 05:13:14,395:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 05:13:14,395:INFO:   <<< warmup_proportion: 0.1
2022-06-21 05:13:14,395:INFO:   <<< world_size: 1
2022-06-21 05:13:14,395:INFO: device: cuda:0 n_gpu: 2
2022-06-21 05:13:15,109:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 05:13:15,110:WARNING: Test retrieval by loose type.
2022-06-21 05:13:15,110:WARNING: 	 embed_dim: 512
2022-06-21 05:13:15,110:WARNING: 	 image_resolution: 224
2022-06-21 05:13:15,111:WARNING: 	 vision_layers: 12
2022-06-21 05:13:15,111:WARNING: 	 vision_width: 768
2022-06-21 05:13:15,111:WARNING: 	 vision_patch_size: 32
2022-06-21 05:13:15,111:WARNING: 	 context_length: 77
2022-06-21 05:13:15,111:WARNING: 	 vocab_size: 49408
2022-06-21 05:13:15,112:WARNING: 	 transformer_width: 512
2022-06-21 05:13:15,112:WARNING: 	 transformer_heads: 8
2022-06-21 05:13:15,112:WARNING: 	 transformer_layers: 12
2022-06-21 05:13:15,112:WARNING: 		 linear_patch: 3d
2022-06-21 05:13:15,112:WARNING: 	 cut_top_layer: 0
2022-06-21 05:13:22,454:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 05:13:34,626:INFO: ***** Running test *****
2022-06-21 05:13:34,626:INFO:   Num examples = 27763
2022-06-21 05:13:34,626:INFO:   Batch size = 16
2022-06-21 05:13:34,626:INFO:   Num steps = 1736
2022-06-21 05:13:34,626:INFO: ***** Running val *****
2022-06-21 05:13:34,626:INFO:   Num examples = 4290
2022-06-21 05:13:36,491:INFO: ***** Running training *****
2022-06-21 05:13:36,491:INFO:   Num examples = 48774
2022-06-21 05:13:36,491:INFO:   Batch size = 128
2022-06-21 05:13:36,491:INFO:   Num steps = 3810
2022-06-21 05:16:24,963:INFO: Effective parameters:
2022-06-21 05:16:24,963:INFO:   <<< batch_size: 128
2022-06-21 05:16:24,963:INFO:   <<< batch_size_val: 16
2022-06-21 05:16:24,963:INFO:   <<< cache_dir: 
2022-06-21 05:16:24,963:INFO:   <<< coef_lr: 0.001
2022-06-21 05:16:24,963:INFO:   <<< cross_model: cross-base
2022-06-21 05:16:24,963:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 05:16:24,963:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 05:16:24,963:INFO:   <<< datatype: msvd
2022-06-21 05:16:24,963:INFO:   <<< do_eval: False
2022-06-21 05:16:24,963:INFO:   <<< do_lower_case: False
2022-06-21 05:16:24,964:INFO:   <<< do_pretrain: False
2022-06-21 05:16:24,964:INFO:   <<< do_train: True
2022-06-21 05:16:24,964:INFO:   <<< epochs: 5
2022-06-21 05:16:24,964:INFO:   <<< eval_frame_order: 0
2022-06-21 05:16:24,964:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 05:16:24,964:INFO:   <<< feature_framerate: 1
2022-06-21 05:16:24,964:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 05:16:24,964:INFO:   <<< fp16: False
2022-06-21 05:16:24,964:INFO:   <<< fp16_opt_level: O1
2022-06-21 05:16:24,964:INFO:   <<< freeze_layer_num: 0
2022-06-21 05:16:24,964:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 05:16:24,964:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 05:16:24,964:INFO:   <<< init_model: None
2022-06-21 05:16:24,964:INFO:   <<< linear_patch: 3d
2022-06-21 05:16:24,964:INFO:   <<< local_rank: 0
2022-06-21 05:16:24,964:INFO:   <<< loose_type: True
2022-06-21 05:16:24,964:INFO:   <<< lr: 0.0001
2022-06-21 05:16:24,964:INFO:   <<< lr_decay: 0.9
2022-06-21 05:16:24,964:INFO:   <<< margin: 0.1
2022-06-21 05:16:24,964:INFO:   <<< max_frames: 16
2022-06-21 05:16:24,964:INFO:   <<< max_words: 32
2022-06-21 05:16:24,964:INFO:   <<< n_display: 50
2022-06-21 05:16:24,964:INFO:   <<< n_gpu: 1
2022-06-21 05:16:24,964:INFO:   <<< n_pair: 1
2022-06-21 05:16:24,964:INFO:   <<< negative_weighting: 1
2022-06-21 05:16:24,964:INFO:   <<< num_thread_reader: 2
2022-06-21 05:16:24,965:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 05:16:24,965:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 05:16:24,965:INFO:   <<< rank: 0
2022-06-21 05:16:24,965:INFO:   <<< resume_model: None
2022-06-21 05:16:24,965:INFO:   <<< sampled_use_mil: False
2022-06-21 05:16:24,965:INFO:   <<< seed: 42
2022-06-21 05:16:24,965:INFO:   <<< sim_header: meanP
2022-06-21 05:16:24,965:INFO:   <<< slice_framepos: 2
2022-06-21 05:16:24,965:INFO:   <<< task_type: retrieval
2022-06-21 05:16:24,965:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 05:16:24,965:INFO:   <<< train_csv: data/.train.csv
2022-06-21 05:16:24,965:INFO:   <<< train_frame_order: 0
2022-06-21 05:16:24,965:INFO:   <<< use_mil: False
2022-06-21 05:16:24,965:INFO:   <<< val_csv: data/.val.csv
2022-06-21 05:16:24,965:INFO:   <<< video_dim: 1024
2022-06-21 05:16:24,965:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 05:16:24,965:INFO:   <<< warmup_proportion: 0.1
2022-06-21 05:16:24,965:INFO:   <<< world_size: 1
2022-06-21 05:16:24,965:INFO: device: cuda:0 n_gpu: 2
2022-06-21 05:16:25,668:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 05:16:25,668:WARNING: Test retrieval by loose type.
2022-06-21 05:16:25,668:WARNING: 	 embed_dim: 512
2022-06-21 05:16:25,668:WARNING: 	 image_resolution: 224
2022-06-21 05:16:25,668:WARNING: 	 vision_layers: 12
2022-06-21 05:16:25,668:WARNING: 	 vision_width: 768
2022-06-21 05:16:25,669:WARNING: 	 vision_patch_size: 32
2022-06-21 05:16:25,669:WARNING: 	 context_length: 77
2022-06-21 05:16:25,669:WARNING: 	 vocab_size: 49408
2022-06-21 05:16:25,669:WARNING: 	 transformer_width: 512
2022-06-21 05:16:25,669:WARNING: 	 transformer_heads: 8
2022-06-21 05:16:25,669:WARNING: 	 transformer_layers: 12
2022-06-21 05:16:25,669:WARNING: 		 linear_patch: 3d
2022-06-21 05:16:25,669:WARNING: 	 cut_top_layer: 0
2022-06-21 05:16:33,286:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 05:16:46,592:INFO: ***** Running test *****
2022-06-21 05:16:46,593:INFO:   Num examples = 27763
2022-06-21 05:16:46,593:INFO:   Batch size = 16
2022-06-21 05:16:46,593:INFO:   Num steps = 1736
2022-06-21 05:16:46,593:INFO: ***** Running val *****
2022-06-21 05:16:46,593:INFO:   Num examples = 4290
2022-06-21 05:16:47,239:INFO: ***** Running training *****
2022-06-21 05:16:47,239:INFO:   Num examples = 48774
2022-06-21 05:16:47,239:INFO:   Batch size = 128
2022-06-21 05:16:47,239:INFO:   Num steps = 3810
2022-06-21 19:29:06,920:INFO: Effective parameters:
2022-06-21 19:29:06,920:INFO:   <<< batch_size: 128
2022-06-21 19:29:06,920:INFO:   <<< batch_size_val: 16
2022-06-21 19:29:06,920:INFO:   <<< cache_dir: 
2022-06-21 19:29:06,920:INFO:   <<< coef_lr: 0.001
2022-06-21 19:29:06,920:INFO:   <<< cross_model: cross-base
2022-06-21 19:29:06,920:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:29:06,920:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:29:06,920:INFO:   <<< datatype: msvd
2022-06-21 19:29:06,921:INFO:   <<< do_eval: False
2022-06-21 19:29:06,921:INFO:   <<< do_lower_case: False
2022-06-21 19:29:06,921:INFO:   <<< do_pretrain: False
2022-06-21 19:29:06,921:INFO:   <<< do_train: True
2022-06-21 19:29:06,921:INFO:   <<< epochs: 5
2022-06-21 19:29:06,921:INFO:   <<< eval_frame_order: 0
2022-06-21 19:29:06,921:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:29:06,921:INFO:   <<< feature_framerate: 1
2022-06-21 19:29:06,921:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos/MSVD_Videos
2022-06-21 19:29:06,921:INFO:   <<< fp16: False
2022-06-21 19:29:06,921:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:29:06,921:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:29:06,921:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:29:06,921:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:29:06,921:INFO:   <<< init_model: None
2022-06-21 19:29:06,921:INFO:   <<< linear_patch: 2d
2022-06-21 19:29:06,921:INFO:   <<< local_rank: 0
2022-06-21 19:29:06,921:INFO:   <<< loose_type: True
2022-06-21 19:29:06,921:INFO:   <<< lr: 0.0001
2022-06-21 19:29:06,921:INFO:   <<< lr_decay: 0.9
2022-06-21 19:29:06,921:INFO:   <<< margin: 0.1
2022-06-21 19:29:06,921:INFO:   <<< max_frames: 12
2022-06-21 19:29:06,921:INFO:   <<< max_words: 32
2022-06-21 19:29:06,921:INFO:   <<< n_display: 50
2022-06-21 19:29:06,921:INFO:   <<< n_gpu: 1
2022-06-21 19:29:06,921:INFO:   <<< n_pair: 1
2022-06-21 19:29:06,921:INFO:   <<< negative_weighting: 1
2022-06-21 19:29:06,921:INFO:   <<< num_thread_reader: 2
2022-06-21 19:29:06,921:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:29:06,921:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:29:06,921:INFO:   <<< rank: 0
2022-06-21 19:29:06,921:INFO:   <<< resume_model: None
2022-06-21 19:29:06,922:INFO:   <<< sampled_use_mil: False
2022-06-21 19:29:06,922:INFO:   <<< seed: 42
2022-06-21 19:29:06,922:INFO:   <<< sim_header: meanP
2022-06-21 19:29:06,922:INFO:   <<< slice_framepos: 2
2022-06-21 19:29:06,922:INFO:   <<< task_type: retrieval
2022-06-21 19:29:06,922:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:29:06,922:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:29:06,922:INFO:   <<< train_frame_order: 0
2022-06-21 19:29:06,922:INFO:   <<< use_mil: False
2022-06-21 19:29:06,922:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:29:06,922:INFO:   <<< video_dim: 1024
2022-06-21 19:29:06,922:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:29:06,922:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:29:06,922:INFO:   <<< world_size: 1
2022-06-21 19:29:06,922:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:29:07,598:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:29:07,599:WARNING: Test retrieval by loose type.
2022-06-21 19:29:07,599:WARNING: 	 embed_dim: 512
2022-06-21 19:29:07,599:WARNING: 	 image_resolution: 224
2022-06-21 19:29:07,599:WARNING: 	 vision_layers: 12
2022-06-21 19:29:07,599:WARNING: 	 vision_width: 768
2022-06-21 19:29:07,599:WARNING: 	 vision_patch_size: 32
2022-06-21 19:29:07,599:WARNING: 	 context_length: 77
2022-06-21 19:29:07,599:WARNING: 	 vocab_size: 49408
2022-06-21 19:29:07,599:WARNING: 	 transformer_width: 512
2022-06-21 19:29:07,599:WARNING: 	 transformer_heads: 8
2022-06-21 19:29:07,599:WARNING: 	 transformer_layers: 12
2022-06-21 19:29:07,599:WARNING: 		 linear_patch: 2d
2022-06-21 19:29:07,599:WARNING: 	 cut_top_layer: 0
2022-06-21 19:29:14,786:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:29:47,273:INFO: Effective parameters:
2022-06-21 19:29:47,274:INFO:   <<< batch_size: 128
2022-06-21 19:29:47,274:INFO:   <<< batch_size_val: 16
2022-06-21 19:29:47,274:INFO:   <<< cache_dir: 
2022-06-21 19:29:47,274:INFO:   <<< coef_lr: 0.001
2022-06-21 19:29:47,274:INFO:   <<< cross_model: cross-base
2022-06-21 19:29:47,274:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:29:47,274:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:29:47,274:INFO:   <<< datatype: msvd
2022-06-21 19:29:47,274:INFO:   <<< do_eval: False
2022-06-21 19:29:47,274:INFO:   <<< do_lower_case: False
2022-06-21 19:29:47,274:INFO:   <<< do_pretrain: False
2022-06-21 19:29:47,274:INFO:   <<< do_train: True
2022-06-21 19:29:47,274:INFO:   <<< epochs: 5
2022-06-21 19:29:47,274:INFO:   <<< eval_frame_order: 0
2022-06-21 19:29:47,274:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:29:47,274:INFO:   <<< feature_framerate: 1
2022-06-21 19:29:47,274:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:29:47,274:INFO:   <<< fp16: False
2022-06-21 19:29:47,274:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:29:47,274:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:29:47,274:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:29:47,275:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:29:47,275:INFO:   <<< init_model: None
2022-06-21 19:29:47,275:INFO:   <<< linear_patch: 2d
2022-06-21 19:29:47,275:INFO:   <<< local_rank: 0
2022-06-21 19:29:47,275:INFO:   <<< loose_type: True
2022-06-21 19:29:47,275:INFO:   <<< lr: 0.0001
2022-06-21 19:29:47,275:INFO:   <<< lr_decay: 0.9
2022-06-21 19:29:47,275:INFO:   <<< margin: 0.1
2022-06-21 19:29:47,275:INFO:   <<< max_frames: 12
2022-06-21 19:29:47,275:INFO:   <<< max_words: 32
2022-06-21 19:29:47,275:INFO:   <<< n_display: 50
2022-06-21 19:29:47,275:INFO:   <<< n_gpu: 1
2022-06-21 19:29:47,275:INFO:   <<< n_pair: 1
2022-06-21 19:29:47,275:INFO:   <<< negative_weighting: 1
2022-06-21 19:29:47,275:INFO:   <<< num_thread_reader: 2
2022-06-21 19:29:47,275:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:29:47,275:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:29:47,275:INFO:   <<< rank: 0
2022-06-21 19:29:47,275:INFO:   <<< resume_model: None
2022-06-21 19:29:47,275:INFO:   <<< sampled_use_mil: False
2022-06-21 19:29:47,275:INFO:   <<< seed: 42
2022-06-21 19:29:47,275:INFO:   <<< sim_header: meanP
2022-06-21 19:29:47,275:INFO:   <<< slice_framepos: 2
2022-06-21 19:29:47,275:INFO:   <<< task_type: retrieval
2022-06-21 19:29:47,275:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:29:47,275:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:29:47,275:INFO:   <<< train_frame_order: 0
2022-06-21 19:29:47,275:INFO:   <<< use_mil: False
2022-06-21 19:29:47,275:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:29:47,275:INFO:   <<< video_dim: 1024
2022-06-21 19:29:47,276:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:29:47,276:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:29:47,276:INFO:   <<< world_size: 1
2022-06-21 19:29:47,276:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:29:47,895:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:29:47,895:WARNING: Test retrieval by loose type.
2022-06-21 19:29:47,895:WARNING: 	 embed_dim: 512
2022-06-21 19:29:47,895:WARNING: 	 image_resolution: 224
2022-06-21 19:29:47,895:WARNING: 	 vision_layers: 12
2022-06-21 19:29:47,895:WARNING: 	 vision_width: 768
2022-06-21 19:29:47,895:WARNING: 	 vision_patch_size: 32
2022-06-21 19:29:47,895:WARNING: 	 context_length: 77
2022-06-21 19:29:47,895:WARNING: 	 vocab_size: 49408
2022-06-21 19:29:47,896:WARNING: 	 transformer_width: 512
2022-06-21 19:29:47,896:WARNING: 	 transformer_heads: 8
2022-06-21 19:29:47,896:WARNING: 	 transformer_layers: 12
2022-06-21 19:29:47,896:WARNING: 		 linear_patch: 2d
2022-06-21 19:29:47,896:WARNING: 	 cut_top_layer: 0
2022-06-21 19:29:55,586:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:30:10,598:INFO: ***** Running test *****
2022-06-21 19:30:10,599:INFO:   Num examples = 27763
2022-06-21 19:30:10,599:INFO:   Batch size = 16
2022-06-21 19:30:10,599:INFO:   Num steps = 1736
2022-06-21 19:30:10,599:INFO: ***** Running val *****
2022-06-21 19:30:10,599:INFO:   Num examples = 4290
2022-06-21 19:30:11,410:INFO: ***** Running training *****
2022-06-21 19:30:11,410:INFO:   Num examples = 48774
2022-06-21 19:30:11,410:INFO:   Batch size = 128
2022-06-21 19:30:11,411:INFO:   Num steps = 3810
2022-06-21 19:32:25,241:INFO: Effective parameters:
2022-06-21 19:32:25,241:INFO:   <<< batch_size: 128
2022-06-21 19:32:25,241:INFO:   <<< batch_size_val: 16
2022-06-21 19:32:25,241:INFO:   <<< cache_dir: 
2022-06-21 19:32:25,241:INFO:   <<< coef_lr: 0.001
2022-06-21 19:32:25,241:INFO:   <<< cross_model: cross-base
2022-06-21 19:32:25,241:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:32:25,241:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:32:25,241:INFO:   <<< datatype: msvd
2022-06-21 19:32:25,241:INFO:   <<< do_eval: False
2022-06-21 19:32:25,241:INFO:   <<< do_lower_case: False
2022-06-21 19:32:25,241:INFO:   <<< do_pretrain: False
2022-06-21 19:32:25,241:INFO:   <<< do_train: True
2022-06-21 19:32:25,241:INFO:   <<< epochs: 5
2022-06-21 19:32:25,241:INFO:   <<< eval_frame_order: 0
2022-06-21 19:32:25,241:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:32:25,241:INFO:   <<< feature_framerate: 1
2022-06-21 19:32:25,241:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:32:25,241:INFO:   <<< fp16: False
2022-06-21 19:32:25,241:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:32:25,242:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:32:25,242:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:32:25,242:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:32:25,242:INFO:   <<< init_model: None
2022-06-21 19:32:25,242:INFO:   <<< linear_patch: 2d
2022-06-21 19:32:25,242:INFO:   <<< local_rank: 0
2022-06-21 19:32:25,242:INFO:   <<< loose_type: True
2022-06-21 19:32:25,242:INFO:   <<< lr: 0.0001
2022-06-21 19:32:25,242:INFO:   <<< lr_decay: 0.9
2022-06-21 19:32:25,242:INFO:   <<< margin: 0.1
2022-06-21 19:32:25,242:INFO:   <<< max_frames: 16
2022-06-21 19:32:25,242:INFO:   <<< max_words: 32
2022-06-21 19:32:25,242:INFO:   <<< n_display: 50
2022-06-21 19:32:25,242:INFO:   <<< n_gpu: 1
2022-06-21 19:32:25,242:INFO:   <<< n_pair: 1
2022-06-21 19:32:25,242:INFO:   <<< negative_weighting: 1
2022-06-21 19:32:25,242:INFO:   <<< num_thread_reader: 2
2022-06-21 19:32:25,242:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:32:25,242:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:32:25,242:INFO:   <<< rank: 0
2022-06-21 19:32:25,242:INFO:   <<< resume_model: None
2022-06-21 19:32:25,242:INFO:   <<< sampled_use_mil: False
2022-06-21 19:32:25,242:INFO:   <<< seed: 42
2022-06-21 19:32:25,242:INFO:   <<< sim_header: meanP
2022-06-21 19:32:25,242:INFO:   <<< slice_framepos: 2
2022-06-21 19:32:25,242:INFO:   <<< task_type: retrieval
2022-06-21 19:32:25,242:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:32:25,242:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:32:25,242:INFO:   <<< train_frame_order: 0
2022-06-21 19:32:25,242:INFO:   <<< use_mil: False
2022-06-21 19:32:25,243:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:32:25,243:INFO:   <<< video_dim: 1024
2022-06-21 19:32:25,243:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:32:25,243:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:32:25,243:INFO:   <<< world_size: 1
2022-06-21 19:32:25,243:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:32:25,960:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:32:25,960:WARNING: Test retrieval by loose type.
2022-06-21 19:32:25,961:WARNING: 	 embed_dim: 512
2022-06-21 19:32:25,961:WARNING: 	 image_resolution: 224
2022-06-21 19:32:25,961:WARNING: 	 vision_layers: 12
2022-06-21 19:32:25,961:WARNING: 	 vision_width: 768
2022-06-21 19:32:25,961:WARNING: 	 vision_patch_size: 32
2022-06-21 19:32:25,961:WARNING: 	 context_length: 77
2022-06-21 19:32:25,961:WARNING: 	 vocab_size: 49408
2022-06-21 19:32:25,961:WARNING: 	 transformer_width: 512
2022-06-21 19:32:25,961:WARNING: 	 transformer_heads: 8
2022-06-21 19:32:25,961:WARNING: 	 transformer_layers: 12
2022-06-21 19:32:25,961:WARNING: 		 linear_patch: 2d
2022-06-21 19:32:25,961:WARNING: 	 cut_top_layer: 0
2022-06-21 19:32:33,126:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:32:45,562:INFO: ***** Running test *****
2022-06-21 19:32:45,562:INFO:   Num examples = 27763
2022-06-21 19:32:45,562:INFO:   Batch size = 16
2022-06-21 19:32:45,562:INFO:   Num steps = 1736
2022-06-21 19:32:45,563:INFO: ***** Running val *****
2022-06-21 19:32:45,563:INFO:   Num examples = 4290
2022-06-21 19:32:46,537:INFO: ***** Running training *****
2022-06-21 19:32:46,537:INFO:   Num examples = 48774
2022-06-21 19:32:46,537:INFO:   Batch size = 128
2022-06-21 19:32:46,537:INFO:   Num steps = 3810
2022-06-21 19:35:06,301:INFO: Effective parameters:
2022-06-21 19:35:06,302:INFO:   <<< batch_size: 128
2022-06-21 19:35:06,302:INFO:   <<< batch_size_val: 16
2022-06-21 19:35:06,302:INFO:   <<< cache_dir: 
2022-06-21 19:35:06,302:INFO:   <<< coef_lr: 0.001
2022-06-21 19:35:06,302:INFO:   <<< cross_model: cross-base
2022-06-21 19:35:06,302:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:35:06,302:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:35:06,302:INFO:   <<< datatype: msvd
2022-06-21 19:35:06,302:INFO:   <<< do_eval: False
2022-06-21 19:35:06,302:INFO:   <<< do_lower_case: False
2022-06-21 19:35:06,302:INFO:   <<< do_pretrain: False
2022-06-21 19:35:06,302:INFO:   <<< do_train: True
2022-06-21 19:35:06,302:INFO:   <<< epochs: 5
2022-06-21 19:35:06,302:INFO:   <<< eval_frame_order: 0
2022-06-21 19:35:06,302:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:35:06,302:INFO:   <<< feature_framerate: 1
2022-06-21 19:35:06,302:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:35:06,302:INFO:   <<< fp16: False
2022-06-21 19:35:06,302:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:35:06,302:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:35:06,302:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:35:06,302:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:35:06,302:INFO:   <<< init_model: None
2022-06-21 19:35:06,302:INFO:   <<< linear_patch: 3d
2022-06-21 19:35:06,302:INFO:   <<< local_rank: 0
2022-06-21 19:35:06,302:INFO:   <<< loose_type: True
2022-06-21 19:35:06,302:INFO:   <<< lr: 0.0001
2022-06-21 19:35:06,303:INFO:   <<< lr_decay: 0.9
2022-06-21 19:35:06,303:INFO:   <<< margin: 0.1
2022-06-21 19:35:06,303:INFO:   <<< max_frames: 16
2022-06-21 19:35:06,303:INFO:   <<< max_words: 32
2022-06-21 19:35:06,303:INFO:   <<< n_display: 50
2022-06-21 19:35:06,303:INFO:   <<< n_gpu: 1
2022-06-21 19:35:06,303:INFO:   <<< n_pair: 1
2022-06-21 19:35:06,303:INFO:   <<< negative_weighting: 1
2022-06-21 19:35:06,303:INFO:   <<< num_thread_reader: 2
2022-06-21 19:35:06,303:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:35:06,303:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:35:06,303:INFO:   <<< rank: 0
2022-06-21 19:35:06,303:INFO:   <<< resume_model: None
2022-06-21 19:35:06,303:INFO:   <<< sampled_use_mil: False
2022-06-21 19:35:06,303:INFO:   <<< seed: 42
2022-06-21 19:35:06,303:INFO:   <<< sim_header: meanP
2022-06-21 19:35:06,303:INFO:   <<< slice_framepos: 2
2022-06-21 19:35:06,303:INFO:   <<< task_type: retrieval
2022-06-21 19:35:06,303:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:35:06,303:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:35:06,303:INFO:   <<< train_frame_order: 0
2022-06-21 19:35:06,303:INFO:   <<< use_mil: False
2022-06-21 19:35:06,303:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:35:06,303:INFO:   <<< video_dim: 1024
2022-06-21 19:35:06,303:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:35:06,303:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:35:06,303:INFO:   <<< world_size: 1
2022-06-21 19:35:06,303:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:35:06,986:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:35:06,987:WARNING: Test retrieval by loose type.
2022-06-21 19:35:06,987:WARNING: 	 embed_dim: 512
2022-06-21 19:35:06,987:WARNING: 	 image_resolution: 224
2022-06-21 19:35:06,987:WARNING: 	 vision_layers: 12
2022-06-21 19:35:06,987:WARNING: 	 vision_width: 768
2022-06-21 19:35:06,987:WARNING: 	 vision_patch_size: 32
2022-06-21 19:35:06,987:WARNING: 	 context_length: 77
2022-06-21 19:35:06,987:WARNING: 	 vocab_size: 49408
2022-06-21 19:35:06,987:WARNING: 	 transformer_width: 512
2022-06-21 19:35:06,987:WARNING: 	 transformer_heads: 8
2022-06-21 19:35:06,987:WARNING: 	 transformer_layers: 12
2022-06-21 19:35:06,987:WARNING: 		 linear_patch: 3d
2022-06-21 19:35:06,987:WARNING: 	 cut_top_layer: 0
2022-06-21 19:35:14,456:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:35:27,856:INFO: ***** Running test *****
2022-06-21 19:35:27,857:INFO:   Num examples = 27763
2022-06-21 19:35:27,857:INFO:   Batch size = 16
2022-06-21 19:35:27,857:INFO:   Num steps = 1736
2022-06-21 19:35:27,857:INFO: ***** Running val *****
2022-06-21 19:35:27,857:INFO:   Num examples = 4290
2022-06-21 19:35:28,567:INFO: ***** Running training *****
2022-06-21 19:35:28,567:INFO:   Num examples = 48774
2022-06-21 19:35:28,567:INFO:   Batch size = 128
2022-06-21 19:35:28,567:INFO:   Num steps = 3810
2022-06-21 19:39:06,867:INFO: Effective parameters:
2022-06-21 19:39:06,867:INFO:   <<< batch_size: 128
2022-06-21 19:39:06,867:INFO:   <<< batch_size_val: 16
2022-06-21 19:39:06,867:INFO:   <<< cache_dir: 
2022-06-21 19:39:06,867:INFO:   <<< coef_lr: 0.001
2022-06-21 19:39:06,867:INFO:   <<< cross_model: cross-base
2022-06-21 19:39:06,867:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:39:06,867:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:39:06,867:INFO:   <<< datatype: msvd
2022-06-21 19:39:06,867:INFO:   <<< do_eval: False
2022-06-21 19:39:06,867:INFO:   <<< do_lower_case: False
2022-06-21 19:39:06,867:INFO:   <<< do_pretrain: False
2022-06-21 19:39:06,867:INFO:   <<< do_train: True
2022-06-21 19:39:06,868:INFO:   <<< epochs: 5
2022-06-21 19:39:06,868:INFO:   <<< eval_frame_order: 0
2022-06-21 19:39:06,868:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:39:06,868:INFO:   <<< feature_framerate: 1
2022-06-21 19:39:06,868:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:39:06,868:INFO:   <<< fp16: False
2022-06-21 19:39:06,868:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:39:06,868:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:39:06,868:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:39:06,868:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:39:06,868:INFO:   <<< init_model: None
2022-06-21 19:39:06,868:INFO:   <<< linear_patch: 3d
2022-06-21 19:39:06,868:INFO:   <<< local_rank: 0
2022-06-21 19:39:06,868:INFO:   <<< loose_type: True
2022-06-21 19:39:06,868:INFO:   <<< lr: 0.0001
2022-06-21 19:39:06,868:INFO:   <<< lr_decay: 0.9
2022-06-21 19:39:06,868:INFO:   <<< margin: 0.1
2022-06-21 19:39:06,868:INFO:   <<< max_frames: 16
2022-06-21 19:39:06,868:INFO:   <<< max_words: 32
2022-06-21 19:39:06,868:INFO:   <<< n_display: 50
2022-06-21 19:39:06,868:INFO:   <<< n_gpu: 1
2022-06-21 19:39:06,868:INFO:   <<< n_pair: 1
2022-06-21 19:39:06,868:INFO:   <<< negative_weighting: 1
2022-06-21 19:39:06,868:INFO:   <<< num_thread_reader: 2
2022-06-21 19:39:06,868:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:39:06,868:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:39:06,868:INFO:   <<< rank: 0
2022-06-21 19:39:06,868:INFO:   <<< resume_model: None
2022-06-21 19:39:06,868:INFO:   <<< sampled_use_mil: False
2022-06-21 19:39:06,868:INFO:   <<< seed: 42
2022-06-21 19:39:06,869:INFO:   <<< sim_header: meanP
2022-06-21 19:39:06,869:INFO:   <<< slice_framepos: 2
2022-06-21 19:39:06,869:INFO:   <<< task_type: retrieval
2022-06-21 19:39:06,869:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:39:06,869:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:39:06,869:INFO:   <<< train_frame_order: 0
2022-06-21 19:39:06,869:INFO:   <<< use_mil: False
2022-06-21 19:39:06,869:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:39:06,869:INFO:   <<< video_dim: 1024
2022-06-21 19:39:06,869:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:39:06,869:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:39:06,869:INFO:   <<< world_size: 1
2022-06-21 19:39:06,869:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:39:07,602:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:39:07,602:WARNING: Test retrieval by loose type.
2022-06-21 19:39:07,603:WARNING: 	 embed_dim: 512
2022-06-21 19:39:07,603:WARNING: 	 image_resolution: 224
2022-06-21 19:39:07,603:WARNING: 	 vision_layers: 12
2022-06-21 19:39:07,603:WARNING: 	 vision_width: 768
2022-06-21 19:39:07,603:WARNING: 	 vision_patch_size: 32
2022-06-21 19:39:07,603:WARNING: 	 context_length: 77
2022-06-21 19:39:07,603:WARNING: 	 vocab_size: 49408
2022-06-21 19:39:07,603:WARNING: 	 transformer_width: 512
2022-06-21 19:39:07,603:WARNING: 	 transformer_heads: 8
2022-06-21 19:39:07,603:WARNING: 	 transformer_layers: 12
2022-06-21 19:39:07,603:WARNING: 		 linear_patch: 3d
2022-06-21 19:39:07,603:WARNING: 	 cut_top_layer: 0
2022-06-21 19:39:15,209:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:39:28,554:INFO: ***** Running test *****
2022-06-21 19:39:28,554:INFO:   Num examples = 27763
2022-06-21 19:39:28,554:INFO:   Batch size = 16
2022-06-21 19:39:28,554:INFO:   Num steps = 1736
2022-06-21 19:39:28,554:INFO: ***** Running val *****
2022-06-21 19:39:28,554:INFO:   Num examples = 4290
2022-06-21 19:39:29,372:INFO: ***** Running training *****
2022-06-21 19:39:29,372:INFO:   Num examples = 48774
2022-06-21 19:39:29,372:INFO:   Batch size = 128
2022-06-21 19:39:29,372:INFO:   Num steps = 3810
2022-06-21 19:42:32,559:INFO: Effective parameters:
2022-06-21 19:42:32,559:INFO:   <<< batch_size: 128
2022-06-21 19:42:32,559:INFO:   <<< batch_size_val: 16
2022-06-21 19:42:32,559:INFO:   <<< cache_dir: 
2022-06-21 19:42:32,559:INFO:   <<< coef_lr: 0.001
2022-06-21 19:42:32,559:INFO:   <<< cross_model: cross-base
2022-06-21 19:42:32,559:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:42:32,559:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:42:32,559:INFO:   <<< datatype: msvd
2022-06-21 19:42:32,559:INFO:   <<< do_eval: False
2022-06-21 19:42:32,559:INFO:   <<< do_lower_case: False
2022-06-21 19:42:32,560:INFO:   <<< do_pretrain: False
2022-06-21 19:42:32,560:INFO:   <<< do_train: True
2022-06-21 19:42:32,560:INFO:   <<< epochs: 5
2022-06-21 19:42:32,560:INFO:   <<< eval_frame_order: 0
2022-06-21 19:42:32,560:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:42:32,560:INFO:   <<< feature_framerate: 1
2022-06-21 19:42:32,560:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:42:32,560:INFO:   <<< fp16: False
2022-06-21 19:42:32,560:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:42:32,560:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:42:32,560:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:42:32,560:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:42:32,560:INFO:   <<< init_model: None
2022-06-21 19:42:32,560:INFO:   <<< linear_patch: 3d
2022-06-21 19:42:32,560:INFO:   <<< local_rank: 0
2022-06-21 19:42:32,560:INFO:   <<< loose_type: True
2022-06-21 19:42:32,560:INFO:   <<< lr: 0.0001
2022-06-21 19:42:32,560:INFO:   <<< lr_decay: 0.9
2022-06-21 19:42:32,560:INFO:   <<< margin: 0.1
2022-06-21 19:42:32,560:INFO:   <<< max_frames: 16
2022-06-21 19:42:32,560:INFO:   <<< max_words: 32
2022-06-21 19:42:32,560:INFO:   <<< n_display: 50
2022-06-21 19:42:32,560:INFO:   <<< n_gpu: 1
2022-06-21 19:42:32,560:INFO:   <<< n_pair: 1
2022-06-21 19:42:32,560:INFO:   <<< negative_weighting: 1
2022-06-21 19:42:32,560:INFO:   <<< num_thread_reader: 2
2022-06-21 19:42:32,560:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:42:32,560:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:42:32,560:INFO:   <<< rank: 0
2022-06-21 19:42:32,560:INFO:   <<< resume_model: None
2022-06-21 19:42:32,560:INFO:   <<< sampled_use_mil: False
2022-06-21 19:42:32,560:INFO:   <<< seed: 42
2022-06-21 19:42:32,561:INFO:   <<< sim_header: meanP
2022-06-21 19:42:32,561:INFO:   <<< slice_framepos: 2
2022-06-21 19:42:32,561:INFO:   <<< task_type: retrieval
2022-06-21 19:42:32,561:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:42:32,561:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:42:32,561:INFO:   <<< train_frame_order: 0
2022-06-21 19:42:32,561:INFO:   <<< use_mil: False
2022-06-21 19:42:32,561:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:42:32,561:INFO:   <<< video_dim: 1024
2022-06-21 19:42:32,561:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:42:32,561:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:42:32,561:INFO:   <<< world_size: 1
2022-06-21 19:42:32,561:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:42:33,227:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:42:33,227:WARNING: Test retrieval by loose type.
2022-06-21 19:42:33,227:WARNING: 	 embed_dim: 512
2022-06-21 19:42:33,227:WARNING: 	 image_resolution: 224
2022-06-21 19:42:33,227:WARNING: 	 vision_layers: 12
2022-06-21 19:42:33,227:WARNING: 	 vision_width: 768
2022-06-21 19:42:33,227:WARNING: 	 vision_patch_size: 32
2022-06-21 19:42:33,227:WARNING: 	 context_length: 77
2022-06-21 19:42:33,227:WARNING: 	 vocab_size: 49408
2022-06-21 19:42:33,227:WARNING: 	 transformer_width: 512
2022-06-21 19:42:33,227:WARNING: 	 transformer_heads: 8
2022-06-21 19:42:33,227:WARNING: 	 transformer_layers: 12
2022-06-21 19:42:33,228:WARNING: 		 linear_patch: 3d
2022-06-21 19:42:33,228:WARNING: 	 cut_top_layer: 0
2022-06-21 19:42:40,873:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:42:55,613:INFO: ***** Running test *****
2022-06-21 19:42:55,613:INFO:   Num examples = 27763
2022-06-21 19:42:55,613:INFO:   Batch size = 16
2022-06-21 19:42:55,613:INFO:   Num steps = 1736
2022-06-21 19:42:55,613:INFO: ***** Running val *****
2022-06-21 19:42:55,613:INFO:   Num examples = 4290
2022-06-21 19:42:56,543:INFO: ***** Running training *****
2022-06-21 19:42:56,543:INFO:   Num examples = 48774
2022-06-21 19:42:56,543:INFO:   Batch size = 128
2022-06-21 19:42:56,543:INFO:   Num steps = 3810
2022-06-21 19:44:52,750:INFO: Effective parameters:
2022-06-21 19:44:52,750:INFO:   <<< batch_size: 128
2022-06-21 19:44:52,750:INFO:   <<< batch_size_val: 16
2022-06-21 19:44:52,750:INFO:   <<< cache_dir: 
2022-06-21 19:44:52,750:INFO:   <<< coef_lr: 0.001
2022-06-21 19:44:52,750:INFO:   <<< cross_model: cross-base
2022-06-21 19:44:52,750:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:44:52,750:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:44:52,751:INFO:   <<< datatype: msvd
2022-06-21 19:44:52,751:INFO:   <<< do_eval: False
2022-06-21 19:44:52,751:INFO:   <<< do_lower_case: False
2022-06-21 19:44:52,751:INFO:   <<< do_pretrain: False
2022-06-21 19:44:52,751:INFO:   <<< do_train: True
2022-06-21 19:44:52,751:INFO:   <<< epochs: 5
2022-06-21 19:44:52,751:INFO:   <<< eval_frame_order: 0
2022-06-21 19:44:52,751:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:44:52,751:INFO:   <<< feature_framerate: 1
2022-06-21 19:44:52,751:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:44:52,751:INFO:   <<< fp16: False
2022-06-21 19:44:52,751:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:44:52,751:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:44:52,751:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:44:52,751:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:44:52,751:INFO:   <<< init_model: None
2022-06-21 19:44:52,751:INFO:   <<< linear_patch: 3d
2022-06-21 19:44:52,751:INFO:   <<< local_rank: 0
2022-06-21 19:44:52,751:INFO:   <<< loose_type: True
2022-06-21 19:44:52,751:INFO:   <<< lr: 0.0001
2022-06-21 19:44:52,751:INFO:   <<< lr_decay: 0.9
2022-06-21 19:44:52,751:INFO:   <<< margin: 0.1
2022-06-21 19:44:52,751:INFO:   <<< max_frames: 16
2022-06-21 19:44:52,751:INFO:   <<< max_words: 32
2022-06-21 19:44:52,751:INFO:   <<< n_display: 50
2022-06-21 19:44:52,751:INFO:   <<< n_gpu: 1
2022-06-21 19:44:52,751:INFO:   <<< n_pair: 1
2022-06-21 19:44:52,751:INFO:   <<< negative_weighting: 1
2022-06-21 19:44:52,751:INFO:   <<< num_thread_reader: 2
2022-06-21 19:44:52,751:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:44:52,751:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:44:52,751:INFO:   <<< rank: 0
2022-06-21 19:44:52,751:INFO:   <<< resume_model: None
2022-06-21 19:44:52,752:INFO:   <<< sampled_use_mil: False
2022-06-21 19:44:52,752:INFO:   <<< seed: 42
2022-06-21 19:44:52,752:INFO:   <<< sim_header: meanP
2022-06-21 19:44:52,752:INFO:   <<< slice_framepos: 2
2022-06-21 19:44:52,752:INFO:   <<< task_type: retrieval
2022-06-21 19:44:52,752:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:44:52,752:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:44:52,752:INFO:   <<< train_frame_order: 0
2022-06-21 19:44:52,752:INFO:   <<< use_mil: False
2022-06-21 19:44:52,752:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:44:52,752:INFO:   <<< video_dim: 1024
2022-06-21 19:44:52,752:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:44:52,752:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:44:52,752:INFO:   <<< world_size: 1
2022-06-21 19:44:52,752:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:44:53,388:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:44:53,388:WARNING: Test retrieval by loose type.
2022-06-21 19:44:53,389:WARNING: 	 embed_dim: 512
2022-06-21 19:44:53,389:WARNING: 	 image_resolution: 224
2022-06-21 19:44:53,389:WARNING: 	 vision_layers: 12
2022-06-21 19:44:53,389:WARNING: 	 vision_width: 768
2022-06-21 19:44:53,389:WARNING: 	 vision_patch_size: 32
2022-06-21 19:44:53,389:WARNING: 	 context_length: 77
2022-06-21 19:44:53,389:WARNING: 	 vocab_size: 49408
2022-06-21 19:44:53,389:WARNING: 	 transformer_width: 512
2022-06-21 19:44:53,389:WARNING: 	 transformer_heads: 8
2022-06-21 19:44:53,389:WARNING: 	 transformer_layers: 12
2022-06-21 19:44:53,389:WARNING: 		 linear_patch: 3d
2022-06-21 19:44:53,389:WARNING: 	 cut_top_layer: 0
2022-06-21 19:45:00,601:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:45:14,758:INFO: ***** Running test *****
2022-06-21 19:45:14,759:INFO:   Num examples = 27763
2022-06-21 19:45:14,759:INFO:   Batch size = 16
2022-06-21 19:45:14,759:INFO:   Num steps = 1736
2022-06-21 19:45:14,759:INFO: ***** Running val *****
2022-06-21 19:45:14,759:INFO:   Num examples = 4290
2022-06-21 19:45:15,577:INFO: ***** Running training *****
2022-06-21 19:45:15,578:INFO:   Num examples = 48774
2022-06-21 19:45:15,578:INFO:   Batch size = 128
2022-06-21 19:45:15,578:INFO:   Num steps = 3810
2022-06-21 19:48:22,198:INFO: Effective parameters:
2022-06-21 19:48:22,199:INFO:   <<< batch_size: 128
2022-06-21 19:48:22,199:INFO:   <<< batch_size_val: 16
2022-06-21 19:48:22,199:INFO:   <<< cache_dir: 
2022-06-21 19:48:22,199:INFO:   <<< coef_lr: 0.001
2022-06-21 19:48:22,199:INFO:   <<< cross_model: cross-base
2022-06-21 19:48:22,199:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:48:22,199:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:48:22,199:INFO:   <<< datatype: msvd
2022-06-21 19:48:22,199:INFO:   <<< do_eval: False
2022-06-21 19:48:22,199:INFO:   <<< do_lower_case: False
2022-06-21 19:48:22,199:INFO:   <<< do_pretrain: False
2022-06-21 19:48:22,199:INFO:   <<< do_train: True
2022-06-21 19:48:22,199:INFO:   <<< epochs: 5
2022-06-21 19:48:22,199:INFO:   <<< eval_frame_order: 0
2022-06-21 19:48:22,199:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:48:22,199:INFO:   <<< feature_framerate: 1
2022-06-21 19:48:22,199:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:48:22,199:INFO:   <<< fp16: False
2022-06-21 19:48:22,199:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:48:22,199:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:48:22,199:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:48:22,199:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:48:22,199:INFO:   <<< init_model: None
2022-06-21 19:48:22,200:INFO:   <<< linear_patch: 3d
2022-06-21 19:48:22,200:INFO:   <<< local_rank: 0
2022-06-21 19:48:22,200:INFO:   <<< loose_type: True
2022-06-21 19:48:22,200:INFO:   <<< lr: 0.0001
2022-06-21 19:48:22,200:INFO:   <<< lr_decay: 0.9
2022-06-21 19:48:22,200:INFO:   <<< margin: 0.1
2022-06-21 19:48:22,200:INFO:   <<< max_frames: 16
2022-06-21 19:48:22,200:INFO:   <<< max_words: 32
2022-06-21 19:48:22,200:INFO:   <<< n_display: 50
2022-06-21 19:48:22,200:INFO:   <<< n_gpu: 1
2022-06-21 19:48:22,200:INFO:   <<< n_pair: 1
2022-06-21 19:48:22,200:INFO:   <<< negative_weighting: 1
2022-06-21 19:48:22,200:INFO:   <<< num_thread_reader: 2
2022-06-21 19:48:22,200:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:48:22,200:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:48:22,200:INFO:   <<< rank: 0
2022-06-21 19:48:22,200:INFO:   <<< resume_model: None
2022-06-21 19:48:22,200:INFO:   <<< sampled_use_mil: False
2022-06-21 19:48:22,200:INFO:   <<< seed: 42
2022-06-21 19:48:22,200:INFO:   <<< sim_header: meanP
2022-06-21 19:48:22,200:INFO:   <<< slice_framepos: 2
2022-06-21 19:48:22,200:INFO:   <<< task_type: retrieval
2022-06-21 19:48:22,200:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:48:22,200:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:48:22,200:INFO:   <<< train_frame_order: 0
2022-06-21 19:48:22,200:INFO:   <<< use_mil: False
2022-06-21 19:48:22,201:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:48:22,201:INFO:   <<< video_dim: 1024
2022-06-21 19:48:22,201:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:48:22,201:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:48:22,201:INFO:   <<< world_size: 1
2022-06-21 19:48:22,201:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:48:22,909:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:48:22,909:WARNING: Test retrieval by loose type.
2022-06-21 19:48:22,909:WARNING: 	 embed_dim: 512
2022-06-21 19:48:22,909:WARNING: 	 image_resolution: 224
2022-06-21 19:48:22,910:WARNING: 	 vision_layers: 12
2022-06-21 19:48:22,910:WARNING: 	 vision_width: 768
2022-06-21 19:48:22,910:WARNING: 	 vision_patch_size: 32
2022-06-21 19:48:22,910:WARNING: 	 context_length: 77
2022-06-21 19:48:22,910:WARNING: 	 vocab_size: 49408
2022-06-21 19:48:22,910:WARNING: 	 transformer_width: 512
2022-06-21 19:48:22,910:WARNING: 	 transformer_heads: 8
2022-06-21 19:48:22,910:WARNING: 	 transformer_layers: 12
2022-06-21 19:48:22,910:WARNING: 		 linear_patch: 3d
2022-06-21 19:48:22,910:WARNING: 	 cut_top_layer: 0
2022-06-21 19:48:30,433:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:48:44,785:INFO: ***** Running test *****
2022-06-21 19:48:44,785:INFO:   Num examples = 27763
2022-06-21 19:48:44,785:INFO:   Batch size = 16
2022-06-21 19:48:44,785:INFO:   Num steps = 1736
2022-06-21 19:48:44,785:INFO: ***** Running val *****
2022-06-21 19:48:44,785:INFO:   Num examples = 4290
2022-06-21 19:48:45,613:INFO: ***** Running training *****
2022-06-21 19:48:45,613:INFO:   Num examples = 48774
2022-06-21 19:48:45,613:INFO:   Batch size = 128
2022-06-21 19:48:45,613:INFO:   Num steps = 3810
2022-06-21 19:50:06,673:INFO: Effective parameters:
2022-06-21 19:50:06,673:INFO:   <<< batch_size: 128
2022-06-21 19:50:06,673:INFO:   <<< batch_size_val: 16
2022-06-21 19:50:06,674:INFO:   <<< cache_dir: 
2022-06-21 19:50:06,674:INFO:   <<< coef_lr: 0.001
2022-06-21 19:50:06,674:INFO:   <<< cross_model: cross-base
2022-06-21 19:50:06,674:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:50:06,674:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:50:06,674:INFO:   <<< datatype: msvd
2022-06-21 19:50:06,674:INFO:   <<< do_eval: False
2022-06-21 19:50:06,674:INFO:   <<< do_lower_case: False
2022-06-21 19:50:06,674:INFO:   <<< do_pretrain: False
2022-06-21 19:50:06,674:INFO:   <<< do_train: True
2022-06-21 19:50:06,674:INFO:   <<< epochs: 5
2022-06-21 19:50:06,674:INFO:   <<< eval_frame_order: 0
2022-06-21 19:50:06,674:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:50:06,674:INFO:   <<< feature_framerate: 1
2022-06-21 19:50:06,674:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:50:06,674:INFO:   <<< fp16: False
2022-06-21 19:50:06,674:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:50:06,674:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:50:06,674:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:50:06,674:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:50:06,674:INFO:   <<< init_model: None
2022-06-21 19:50:06,674:INFO:   <<< linear_patch: 3d
2022-06-21 19:50:06,675:INFO:   <<< local_rank: 0
2022-06-21 19:50:06,675:INFO:   <<< loose_type: True
2022-06-21 19:50:06,675:INFO:   <<< lr: 0.0001
2022-06-21 19:50:06,675:INFO:   <<< lr_decay: 0.9
2022-06-21 19:50:06,675:INFO:   <<< margin: 0.1
2022-06-21 19:50:06,675:INFO:   <<< max_frames: 16
2022-06-21 19:50:06,675:INFO:   <<< max_words: 32
2022-06-21 19:50:06,675:INFO:   <<< n_display: 50
2022-06-21 19:50:06,675:INFO:   <<< n_gpu: 1
2022-06-21 19:50:06,675:INFO:   <<< n_pair: 1
2022-06-21 19:50:06,675:INFO:   <<< negative_weighting: 1
2022-06-21 19:50:06,675:INFO:   <<< num_thread_reader: 2
2022-06-21 19:50:06,675:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:50:06,675:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:50:06,675:INFO:   <<< rank: 0
2022-06-21 19:50:06,675:INFO:   <<< resume_model: None
2022-06-21 19:50:06,675:INFO:   <<< sampled_use_mil: False
2022-06-21 19:50:06,675:INFO:   <<< seed: 42
2022-06-21 19:50:06,675:INFO:   <<< sim_header: meanP
2022-06-21 19:50:06,675:INFO:   <<< slice_framepos: 2
2022-06-21 19:50:06,675:INFO:   <<< task_type: retrieval
2022-06-21 19:50:06,675:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:50:06,675:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:50:06,675:INFO:   <<< train_frame_order: 0
2022-06-21 19:50:06,676:INFO:   <<< use_mil: False
2022-06-21 19:50:06,676:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:50:06,676:INFO:   <<< video_dim: 1024
2022-06-21 19:50:06,676:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:50:06,676:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:50:06,676:INFO:   <<< world_size: 1
2022-06-21 19:50:06,676:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:50:07,389:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:50:07,389:WARNING: Test retrieval by loose type.
2022-06-21 19:50:07,390:WARNING: 	 embed_dim: 512
2022-06-21 19:50:07,390:WARNING: 	 image_resolution: 224
2022-06-21 19:50:07,390:WARNING: 	 vision_layers: 12
2022-06-21 19:50:07,390:WARNING: 	 vision_width: 768
2022-06-21 19:50:07,390:WARNING: 	 vision_patch_size: 32
2022-06-21 19:50:07,390:WARNING: 	 context_length: 77
2022-06-21 19:50:07,390:WARNING: 	 vocab_size: 49408
2022-06-21 19:50:07,390:WARNING: 	 transformer_width: 512
2022-06-21 19:50:07,390:WARNING: 	 transformer_heads: 8
2022-06-21 19:50:07,390:WARNING: 	 transformer_layers: 12
2022-06-21 19:50:07,390:WARNING: 		 linear_patch: 3d
2022-06-21 19:50:07,390:WARNING: 	 cut_top_layer: 0
2022-06-21 19:50:14,976:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:50:27,812:INFO: ***** Running test *****
2022-06-21 19:50:27,813:INFO:   Num examples = 27763
2022-06-21 19:50:27,813:INFO:   Batch size = 16
2022-06-21 19:50:27,813:INFO:   Num steps = 1736
2022-06-21 19:50:27,813:INFO: ***** Running val *****
2022-06-21 19:50:27,813:INFO:   Num examples = 4290
2022-06-21 19:50:28,625:INFO: ***** Running training *****
2022-06-21 19:50:28,625:INFO:   Num examples = 48774
2022-06-21 19:50:28,625:INFO:   Batch size = 128
2022-06-21 19:50:28,625:INFO:   Num steps = 3810
2022-06-21 19:52:06,546:INFO: Effective parameters:
2022-06-21 19:52:06,546:INFO:   <<< batch_size: 128
2022-06-21 19:52:06,546:INFO:   <<< batch_size_val: 16
2022-06-21 19:52:06,546:INFO:   <<< cache_dir: 
2022-06-21 19:52:06,546:INFO:   <<< coef_lr: 0.001
2022-06-21 19:52:06,546:INFO:   <<< cross_model: cross-base
2022-06-21 19:52:06,547:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:52:06,547:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:52:06,547:INFO:   <<< datatype: msvd
2022-06-21 19:52:06,547:INFO:   <<< do_eval: False
2022-06-21 19:52:06,547:INFO:   <<< do_lower_case: False
2022-06-21 19:52:06,547:INFO:   <<< do_pretrain: False
2022-06-21 19:52:06,547:INFO:   <<< do_train: True
2022-06-21 19:52:06,547:INFO:   <<< epochs: 5
2022-06-21 19:52:06,547:INFO:   <<< eval_frame_order: 0
2022-06-21 19:52:06,547:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:52:06,547:INFO:   <<< feature_framerate: 1
2022-06-21 19:52:06,547:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:52:06,547:INFO:   <<< fp16: False
2022-06-21 19:52:06,547:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:52:06,547:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:52:06,547:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:52:06,547:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:52:06,547:INFO:   <<< init_model: None
2022-06-21 19:52:06,547:INFO:   <<< linear_patch: 3d
2022-06-21 19:52:06,547:INFO:   <<< local_rank: 0
2022-06-21 19:52:06,547:INFO:   <<< loose_type: True
2022-06-21 19:52:06,547:INFO:   <<< lr: 0.0001
2022-06-21 19:52:06,547:INFO:   <<< lr_decay: 0.9
2022-06-21 19:52:06,547:INFO:   <<< margin: 0.1
2022-06-21 19:52:06,547:INFO:   <<< max_frames: 16
2022-06-21 19:52:06,547:INFO:   <<< max_words: 32
2022-06-21 19:52:06,547:INFO:   <<< n_display: 50
2022-06-21 19:52:06,547:INFO:   <<< n_gpu: 1
2022-06-21 19:52:06,547:INFO:   <<< n_pair: 1
2022-06-21 19:52:06,547:INFO:   <<< negative_weighting: 1
2022-06-21 19:52:06,547:INFO:   <<< num_thread_reader: 2
2022-06-21 19:52:06,547:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:52:06,547:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:52:06,548:INFO:   <<< rank: 0
2022-06-21 19:52:06,548:INFO:   <<< resume_model: None
2022-06-21 19:52:06,548:INFO:   <<< sampled_use_mil: False
2022-06-21 19:52:06,548:INFO:   <<< seed: 42
2022-06-21 19:52:06,548:INFO:   <<< sim_header: meanP
2022-06-21 19:52:06,548:INFO:   <<< slice_framepos: 2
2022-06-21 19:52:06,548:INFO:   <<< task_type: retrieval
2022-06-21 19:52:06,548:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:52:06,548:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:52:06,548:INFO:   <<< train_frame_order: 0
2022-06-21 19:52:06,548:INFO:   <<< use_mil: False
2022-06-21 19:52:06,548:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:52:06,548:INFO:   <<< video_dim: 1024
2022-06-21 19:52:06,548:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:52:06,548:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:52:06,548:INFO:   <<< world_size: 1
2022-06-21 19:52:06,548:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:52:07,267:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:52:07,267:WARNING: Test retrieval by loose type.
2022-06-21 19:52:07,268:WARNING: 	 embed_dim: 512
2022-06-21 19:52:07,268:WARNING: 	 image_resolution: 224
2022-06-21 19:52:07,268:WARNING: 	 vision_layers: 12
2022-06-21 19:52:07,268:WARNING: 	 vision_width: 768
2022-06-21 19:52:07,268:WARNING: 	 vision_patch_size: 32
2022-06-21 19:52:07,268:WARNING: 	 context_length: 77
2022-06-21 19:52:07,268:WARNING: 	 vocab_size: 49408
2022-06-21 19:52:07,268:WARNING: 	 transformer_width: 512
2022-06-21 19:52:07,268:WARNING: 	 transformer_heads: 8
2022-06-21 19:52:07,268:WARNING: 	 transformer_layers: 12
2022-06-21 19:52:07,268:WARNING: 		 linear_patch: 3d
2022-06-21 19:52:07,268:WARNING: 	 cut_top_layer: 0
2022-06-21 19:52:14,554:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:52:27,876:INFO: ***** Running test *****
2022-06-21 19:52:27,876:INFO:   Num examples = 27763
2022-06-21 19:52:27,876:INFO:   Batch size = 16
2022-06-21 19:52:27,877:INFO:   Num steps = 1736
2022-06-21 19:52:27,877:INFO: ***** Running val *****
2022-06-21 19:52:27,877:INFO:   Num examples = 4290
2022-06-21 19:52:28,643:INFO: ***** Running training *****
2022-06-21 19:52:28,643:INFO:   Num examples = 48774
2022-06-21 19:52:28,643:INFO:   Batch size = 128
2022-06-21 19:52:28,643:INFO:   Num steps = 3810
2022-06-21 19:53:40,235:INFO: Effective parameters:
2022-06-21 19:53:40,235:INFO:   <<< batch_size: 128
2022-06-21 19:53:40,235:INFO:   <<< batch_size_val: 16
2022-06-21 19:53:40,235:INFO:   <<< cache_dir: 
2022-06-21 19:53:40,235:INFO:   <<< coef_lr: 0.001
2022-06-21 19:53:40,235:INFO:   <<< cross_model: cross-base
2022-06-21 19:53:40,235:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:53:40,235:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:53:40,235:INFO:   <<< datatype: msvd
2022-06-21 19:53:40,235:INFO:   <<< do_eval: False
2022-06-21 19:53:40,235:INFO:   <<< do_lower_case: False
2022-06-21 19:53:40,235:INFO:   <<< do_pretrain: False
2022-06-21 19:53:40,235:INFO:   <<< do_train: True
2022-06-21 19:53:40,236:INFO:   <<< epochs: 5
2022-06-21 19:53:40,236:INFO:   <<< eval_frame_order: 0
2022-06-21 19:53:40,236:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:53:40,236:INFO:   <<< feature_framerate: 1
2022-06-21 19:53:40,236:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:53:40,236:INFO:   <<< fp16: False
2022-06-21 19:53:40,236:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:53:40,236:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:53:40,236:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:53:40,236:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:53:40,236:INFO:   <<< init_model: None
2022-06-21 19:53:40,236:INFO:   <<< linear_patch: 3d
2022-06-21 19:53:40,236:INFO:   <<< local_rank: 0
2022-06-21 19:53:40,236:INFO:   <<< loose_type: True
2022-06-21 19:53:40,236:INFO:   <<< lr: 0.0001
2022-06-21 19:53:40,236:INFO:   <<< lr_decay: 0.9
2022-06-21 19:53:40,236:INFO:   <<< margin: 0.1
2022-06-21 19:53:40,236:INFO:   <<< max_frames: 16
2022-06-21 19:53:40,236:INFO:   <<< max_words: 32
2022-06-21 19:53:40,236:INFO:   <<< n_display: 50
2022-06-21 19:53:40,236:INFO:   <<< n_gpu: 1
2022-06-21 19:53:40,236:INFO:   <<< n_pair: 1
2022-06-21 19:53:40,237:INFO:   <<< negative_weighting: 1
2022-06-21 19:53:40,237:INFO:   <<< num_thread_reader: 2
2022-06-21 19:53:40,237:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:53:40,237:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:53:40,237:INFO:   <<< rank: 0
2022-06-21 19:53:40,237:INFO:   <<< resume_model: None
2022-06-21 19:53:40,237:INFO:   <<< sampled_use_mil: False
2022-06-21 19:53:40,237:INFO:   <<< seed: 42
2022-06-21 19:53:40,237:INFO:   <<< sim_header: meanP
2022-06-21 19:53:40,237:INFO:   <<< slice_framepos: 2
2022-06-21 19:53:40,237:INFO:   <<< task_type: retrieval
2022-06-21 19:53:40,237:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:53:40,237:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:53:40,237:INFO:   <<< train_frame_order: 0
2022-06-21 19:53:40,237:INFO:   <<< use_mil: False
2022-06-21 19:53:40,237:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:53:40,237:INFO:   <<< video_dim: 1024
2022-06-21 19:53:40,237:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:53:40,237:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:53:40,237:INFO:   <<< world_size: 1
2022-06-21 19:53:40,238:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:53:40,950:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:53:40,950:WARNING: Test retrieval by loose type.
2022-06-21 19:53:40,950:WARNING: 	 embed_dim: 512
2022-06-21 19:53:40,951:WARNING: 	 image_resolution: 224
2022-06-21 19:53:40,951:WARNING: 	 vision_layers: 12
2022-06-21 19:53:40,951:WARNING: 	 vision_width: 768
2022-06-21 19:53:40,951:WARNING: 	 vision_patch_size: 32
2022-06-21 19:53:40,951:WARNING: 	 context_length: 77
2022-06-21 19:53:40,951:WARNING: 	 vocab_size: 49408
2022-06-21 19:53:40,951:WARNING: 	 transformer_width: 512
2022-06-21 19:53:40,951:WARNING: 	 transformer_heads: 8
2022-06-21 19:53:40,951:WARNING: 	 transformer_layers: 12
2022-06-21 19:53:40,951:WARNING: 		 linear_patch: 3d
2022-06-21 19:53:40,951:WARNING: 	 cut_top_layer: 0
2022-06-21 19:53:48,187:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:54:01,896:INFO: ***** Running test *****
2022-06-21 19:54:01,896:INFO:   Num examples = 27763
2022-06-21 19:54:01,896:INFO:   Batch size = 16
2022-06-21 19:54:01,896:INFO:   Num steps = 1736
2022-06-21 19:54:01,896:INFO: ***** Running val *****
2022-06-21 19:54:01,896:INFO:   Num examples = 4290
2022-06-21 19:54:02,772:INFO: ***** Running training *****
2022-06-21 19:54:02,772:INFO:   Num examples = 48774
2022-06-21 19:54:02,772:INFO:   Batch size = 128
2022-06-21 19:54:02,772:INFO:   Num steps = 3810
2022-06-21 19:56:15,566:INFO: Effective parameters:
2022-06-21 19:56:15,566:INFO:   <<< batch_size: 128
2022-06-21 19:56:15,566:INFO:   <<< batch_size_val: 16
2022-06-21 19:56:15,566:INFO:   <<< cache_dir: 
2022-06-21 19:56:15,567:INFO:   <<< coef_lr: 0.001
2022-06-21 19:56:15,567:INFO:   <<< cross_model: cross-base
2022-06-21 19:56:15,567:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:56:15,567:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:56:15,567:INFO:   <<< datatype: msvd
2022-06-21 19:56:15,567:INFO:   <<< do_eval: False
2022-06-21 19:56:15,567:INFO:   <<< do_lower_case: False
2022-06-21 19:56:15,567:INFO:   <<< do_pretrain: False
2022-06-21 19:56:15,567:INFO:   <<< do_train: True
2022-06-21 19:56:15,567:INFO:   <<< epochs: 5
2022-06-21 19:56:15,567:INFO:   <<< eval_frame_order: 0
2022-06-21 19:56:15,567:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:56:15,567:INFO:   <<< feature_framerate: 1
2022-06-21 19:56:15,567:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:56:15,567:INFO:   <<< fp16: False
2022-06-21 19:56:15,567:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:56:15,567:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:56:15,567:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:56:15,567:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:56:15,567:INFO:   <<< init_model: None
2022-06-21 19:56:15,567:INFO:   <<< linear_patch: 3d
2022-06-21 19:56:15,567:INFO:   <<< local_rank: 0
2022-06-21 19:56:15,567:INFO:   <<< loose_type: True
2022-06-21 19:56:15,567:INFO:   <<< lr: 0.0001
2022-06-21 19:56:15,568:INFO:   <<< lr_decay: 0.9
2022-06-21 19:56:15,568:INFO:   <<< margin: 0.1
2022-06-21 19:56:15,568:INFO:   <<< max_frames: 16
2022-06-21 19:56:15,568:INFO:   <<< max_words: 32
2022-06-21 19:56:15,568:INFO:   <<< n_display: 50
2022-06-21 19:56:15,568:INFO:   <<< n_gpu: 1
2022-06-21 19:56:15,568:INFO:   <<< n_pair: 1
2022-06-21 19:56:15,568:INFO:   <<< negative_weighting: 1
2022-06-21 19:56:15,568:INFO:   <<< num_thread_reader: 2
2022-06-21 19:56:15,568:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:56:15,568:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:56:15,568:INFO:   <<< rank: 0
2022-06-21 19:56:15,568:INFO:   <<< resume_model: None
2022-06-21 19:56:15,568:INFO:   <<< sampled_use_mil: False
2022-06-21 19:56:15,568:INFO:   <<< seed: 42
2022-06-21 19:56:15,568:INFO:   <<< sim_header: meanP
2022-06-21 19:56:15,568:INFO:   <<< slice_framepos: 2
2022-06-21 19:56:15,568:INFO:   <<< task_type: retrieval
2022-06-21 19:56:15,568:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:56:15,568:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:56:15,568:INFO:   <<< train_frame_order: 0
2022-06-21 19:56:15,568:INFO:   <<< use_mil: False
2022-06-21 19:56:15,568:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:56:15,568:INFO:   <<< video_dim: 1024
2022-06-21 19:56:15,568:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:56:15,569:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:56:15,569:INFO:   <<< world_size: 1
2022-06-21 19:56:15,569:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:56:16,265:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:56:16,265:WARNING: Test retrieval by loose type.
2022-06-21 19:56:16,266:WARNING: 	 embed_dim: 512
2022-06-21 19:56:16,266:WARNING: 	 image_resolution: 224
2022-06-21 19:56:16,266:WARNING: 	 vision_layers: 12
2022-06-21 19:56:16,266:WARNING: 	 vision_width: 768
2022-06-21 19:56:16,266:WARNING: 	 vision_patch_size: 32
2022-06-21 19:56:16,266:WARNING: 	 context_length: 77
2022-06-21 19:56:16,266:WARNING: 	 vocab_size: 49408
2022-06-21 19:56:16,266:WARNING: 	 transformer_width: 512
2022-06-21 19:56:16,266:WARNING: 	 transformer_heads: 8
2022-06-21 19:56:16,266:WARNING: 	 transformer_layers: 12
2022-06-21 19:56:16,266:WARNING: 		 linear_patch: 3d
2022-06-21 19:56:16,266:WARNING: 	 cut_top_layer: 0
2022-06-21 19:56:24,024:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:56:35,793:INFO: ***** Running test *****
2022-06-21 19:56:35,794:INFO:   Num examples = 27763
2022-06-21 19:56:35,794:INFO:   Batch size = 16
2022-06-21 19:56:35,794:INFO:   Num steps = 1736
2022-06-21 19:56:35,794:INFO: ***** Running val *****
2022-06-21 19:56:35,794:INFO:   Num examples = 4290
2022-06-21 19:56:36,618:INFO: ***** Running training *****
2022-06-21 19:56:36,619:INFO:   Num examples = 48774
2022-06-21 19:56:36,619:INFO:   Batch size = 128
2022-06-21 19:56:36,619:INFO:   Num steps = 3810
2022-06-21 19:57:37,570:INFO: Effective parameters:
2022-06-21 19:57:37,570:INFO:   <<< batch_size: 128
2022-06-21 19:57:37,570:INFO:   <<< batch_size_val: 16
2022-06-21 19:57:37,570:INFO:   <<< cache_dir: 
2022-06-21 19:57:37,570:INFO:   <<< coef_lr: 0.001
2022-06-21 19:57:37,570:INFO:   <<< cross_model: cross-base
2022-06-21 19:57:37,570:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:57:37,570:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:57:37,570:INFO:   <<< datatype: msvd
2022-06-21 19:57:37,570:INFO:   <<< do_eval: False
2022-06-21 19:57:37,570:INFO:   <<< do_lower_case: False
2022-06-21 19:57:37,570:INFO:   <<< do_pretrain: False
2022-06-21 19:57:37,570:INFO:   <<< do_train: True
2022-06-21 19:57:37,570:INFO:   <<< epochs: 5
2022-06-21 19:57:37,570:INFO:   <<< eval_frame_order: 0
2022-06-21 19:57:37,570:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:57:37,571:INFO:   <<< feature_framerate: 1
2022-06-21 19:57:37,571:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:57:37,571:INFO:   <<< fp16: False
2022-06-21 19:57:37,571:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:57:37,571:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:57:37,571:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:57:37,571:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:57:37,571:INFO:   <<< init_model: None
2022-06-21 19:57:37,571:INFO:   <<< linear_patch: 3d
2022-06-21 19:57:37,571:INFO:   <<< local_rank: 0
2022-06-21 19:57:37,571:INFO:   <<< loose_type: True
2022-06-21 19:57:37,571:INFO:   <<< lr: 0.0001
2022-06-21 19:57:37,571:INFO:   <<< lr_decay: 0.9
2022-06-21 19:57:37,571:INFO:   <<< margin: 0.1
2022-06-21 19:57:37,571:INFO:   <<< max_frames: 16
2022-06-21 19:57:37,571:INFO:   <<< max_words: 32
2022-06-21 19:57:37,571:INFO:   <<< n_display: 50
2022-06-21 19:57:37,571:INFO:   <<< n_gpu: 1
2022-06-21 19:57:37,571:INFO:   <<< n_pair: 1
2022-06-21 19:57:37,571:INFO:   <<< negative_weighting: 1
2022-06-21 19:57:37,571:INFO:   <<< num_thread_reader: 2
2022-06-21 19:57:37,571:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:57:37,571:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:57:37,571:INFO:   <<< rank: 0
2022-06-21 19:57:37,571:INFO:   <<< resume_model: None
2022-06-21 19:57:37,571:INFO:   <<< sampled_use_mil: False
2022-06-21 19:57:37,571:INFO:   <<< seed: 42
2022-06-21 19:57:37,571:INFO:   <<< sim_header: meanP
2022-06-21 19:57:37,571:INFO:   <<< slice_framepos: 2
2022-06-21 19:57:37,571:INFO:   <<< task_type: retrieval
2022-06-21 19:57:37,571:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:57:37,571:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:57:37,572:INFO:   <<< train_frame_order: 0
2022-06-21 19:57:37,572:INFO:   <<< use_mil: False
2022-06-21 19:57:37,572:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:57:37,572:INFO:   <<< video_dim: 1024
2022-06-21 19:57:37,572:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:57:37,572:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:57:37,572:INFO:   <<< world_size: 1
2022-06-21 19:57:37,572:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:57:38,285:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:57:38,285:WARNING: Test retrieval by loose type.
2022-06-21 19:57:38,285:WARNING: 	 embed_dim: 512
2022-06-21 19:57:38,285:WARNING: 	 image_resolution: 224
2022-06-21 19:57:38,285:WARNING: 	 vision_layers: 12
2022-06-21 19:57:38,285:WARNING: 	 vision_width: 768
2022-06-21 19:57:38,285:WARNING: 	 vision_patch_size: 32
2022-06-21 19:57:38,285:WARNING: 	 context_length: 77
2022-06-21 19:57:38,285:WARNING: 	 vocab_size: 49408
2022-06-21 19:57:38,286:WARNING: 	 transformer_width: 512
2022-06-21 19:57:38,286:WARNING: 	 transformer_heads: 8
2022-06-21 19:57:38,286:WARNING: 	 transformer_layers: 12
2022-06-21 19:57:38,286:WARNING: 		 linear_patch: 3d
2022-06-21 19:57:38,286:WARNING: 	 cut_top_layer: 0
2022-06-21 19:57:45,598:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:57:58,264:INFO: ***** Running test *****
2022-06-21 19:57:58,264:INFO:   Num examples = 27763
2022-06-21 19:57:58,264:INFO:   Batch size = 16
2022-06-21 19:57:58,264:INFO:   Num steps = 1736
2022-06-21 19:57:58,265:INFO: ***** Running val *****
2022-06-21 19:57:58,265:INFO:   Num examples = 4290
2022-06-21 19:57:59,011:INFO: ***** Running training *****
2022-06-21 19:57:59,011:INFO:   Num examples = 48774
2022-06-21 19:57:59,011:INFO:   Batch size = 128
2022-06-21 19:57:59,011:INFO:   Num steps = 3810
2022-06-21 19:59:02,778:INFO: Effective parameters:
2022-06-21 19:59:02,778:INFO:   <<< batch_size: 128
2022-06-21 19:59:02,778:INFO:   <<< batch_size_val: 16
2022-06-21 19:59:02,778:INFO:   <<< cache_dir: 
2022-06-21 19:59:02,778:INFO:   <<< coef_lr: 0.001
2022-06-21 19:59:02,778:INFO:   <<< cross_model: cross-base
2022-06-21 19:59:02,778:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 19:59:02,778:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 19:59:02,778:INFO:   <<< datatype: msvd
2022-06-21 19:59:02,778:INFO:   <<< do_eval: False
2022-06-21 19:59:02,778:INFO:   <<< do_lower_case: False
2022-06-21 19:59:02,778:INFO:   <<< do_pretrain: False
2022-06-21 19:59:02,778:INFO:   <<< do_train: True
2022-06-21 19:59:02,779:INFO:   <<< epochs: 5
2022-06-21 19:59:02,779:INFO:   <<< eval_frame_order: 0
2022-06-21 19:59:02,779:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 19:59:02,779:INFO:   <<< feature_framerate: 1
2022-06-21 19:59:02,779:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 19:59:02,779:INFO:   <<< fp16: False
2022-06-21 19:59:02,779:INFO:   <<< fp16_opt_level: O1
2022-06-21 19:59:02,779:INFO:   <<< freeze_layer_num: 0
2022-06-21 19:59:02,779:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 19:59:02,779:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 19:59:02,779:INFO:   <<< init_model: None
2022-06-21 19:59:02,779:INFO:   <<< linear_patch: 3d
2022-06-21 19:59:02,779:INFO:   <<< local_rank: 0
2022-06-21 19:59:02,779:INFO:   <<< loose_type: True
2022-06-21 19:59:02,779:INFO:   <<< lr: 0.0001
2022-06-21 19:59:02,779:INFO:   <<< lr_decay: 0.9
2022-06-21 19:59:02,779:INFO:   <<< margin: 0.1
2022-06-21 19:59:02,779:INFO:   <<< max_frames: 16
2022-06-21 19:59:02,779:INFO:   <<< max_words: 32
2022-06-21 19:59:02,779:INFO:   <<< n_display: 50
2022-06-21 19:59:02,779:INFO:   <<< n_gpu: 1
2022-06-21 19:59:02,779:INFO:   <<< n_pair: 1
2022-06-21 19:59:02,779:INFO:   <<< negative_weighting: 1
2022-06-21 19:59:02,779:INFO:   <<< num_thread_reader: 2
2022-06-21 19:59:02,779:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 19:59:02,779:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 19:59:02,779:INFO:   <<< rank: 0
2022-06-21 19:59:02,779:INFO:   <<< resume_model: None
2022-06-21 19:59:02,779:INFO:   <<< sampled_use_mil: False
2022-06-21 19:59:02,779:INFO:   <<< seed: 42
2022-06-21 19:59:02,779:INFO:   <<< sim_header: meanP
2022-06-21 19:59:02,779:INFO:   <<< slice_framepos: 2
2022-06-21 19:59:02,780:INFO:   <<< task_type: retrieval
2022-06-21 19:59:02,780:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 19:59:02,780:INFO:   <<< train_csv: data/.train.csv
2022-06-21 19:59:02,780:INFO:   <<< train_frame_order: 0
2022-06-21 19:59:02,780:INFO:   <<< use_mil: False
2022-06-21 19:59:02,780:INFO:   <<< val_csv: data/.val.csv
2022-06-21 19:59:02,780:INFO:   <<< video_dim: 1024
2022-06-21 19:59:02,780:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 19:59:02,780:INFO:   <<< warmup_proportion: 0.1
2022-06-21 19:59:02,780:INFO:   <<< world_size: 1
2022-06-21 19:59:02,780:INFO: device: cuda:0 n_gpu: 2
2022-06-21 19:59:03,462:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 19:59:03,462:WARNING: Test retrieval by loose type.
2022-06-21 19:59:03,462:WARNING: 	 embed_dim: 512
2022-06-21 19:59:03,463:WARNING: 	 image_resolution: 224
2022-06-21 19:59:03,463:WARNING: 	 vision_layers: 12
2022-06-21 19:59:03,463:WARNING: 	 vision_width: 768
2022-06-21 19:59:03,463:WARNING: 	 vision_patch_size: 32
2022-06-21 19:59:03,463:WARNING: 	 context_length: 77
2022-06-21 19:59:03,463:WARNING: 	 vocab_size: 49408
2022-06-21 19:59:03,463:WARNING: 	 transformer_width: 512
2022-06-21 19:59:03,463:WARNING: 	 transformer_heads: 8
2022-06-21 19:59:03,463:WARNING: 	 transformer_layers: 12
2022-06-21 19:59:03,463:WARNING: 		 linear_patch: 3d
2022-06-21 19:59:03,463:WARNING: 	 cut_top_layer: 0
2022-06-21 19:59:10,580:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 19:59:25,621:INFO: ***** Running test *****
2022-06-21 19:59:25,621:INFO:   Num examples = 27763
2022-06-21 19:59:25,621:INFO:   Batch size = 16
2022-06-21 19:59:25,621:INFO:   Num steps = 1736
2022-06-21 19:59:25,621:INFO: ***** Running val *****
2022-06-21 19:59:25,621:INFO:   Num examples = 4290
2022-06-21 19:59:26,615:INFO: ***** Running training *****
2022-06-21 19:59:26,616:INFO:   Num examples = 48774
2022-06-21 19:59:26,616:INFO:   Batch size = 128
2022-06-21 19:59:26,616:INFO:   Num steps = 3810
2022-06-21 20:00:30,741:INFO: Effective parameters:
2022-06-21 20:00:30,741:INFO:   <<< batch_size: 128
2022-06-21 20:00:30,741:INFO:   <<< batch_size_val: 16
2022-06-21 20:00:30,742:INFO:   <<< cache_dir: 
2022-06-21 20:00:30,742:INFO:   <<< coef_lr: 0.001
2022-06-21 20:00:30,742:INFO:   <<< cross_model: cross-base
2022-06-21 20:00:30,742:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:00:30,742:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:00:30,742:INFO:   <<< datatype: msvd
2022-06-21 20:00:30,742:INFO:   <<< do_eval: False
2022-06-21 20:00:30,742:INFO:   <<< do_lower_case: False
2022-06-21 20:00:30,742:INFO:   <<< do_pretrain: False
2022-06-21 20:00:30,742:INFO:   <<< do_train: True
2022-06-21 20:00:30,742:INFO:   <<< epochs: 5
2022-06-21 20:00:30,742:INFO:   <<< eval_frame_order: 0
2022-06-21 20:00:30,742:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:00:30,742:INFO:   <<< feature_framerate: 1
2022-06-21 20:00:30,742:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:00:30,742:INFO:   <<< fp16: False
2022-06-21 20:00:30,742:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:00:30,742:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:00:30,742:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:00:30,742:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:00:30,742:INFO:   <<< init_model: None
2022-06-21 20:00:30,742:INFO:   <<< linear_patch: 3d
2022-06-21 20:00:30,742:INFO:   <<< local_rank: 0
2022-06-21 20:00:30,742:INFO:   <<< loose_type: True
2022-06-21 20:00:30,742:INFO:   <<< lr: 0.0001
2022-06-21 20:00:30,742:INFO:   <<< lr_decay: 0.9
2022-06-21 20:00:30,743:INFO:   <<< margin: 0.1
2022-06-21 20:00:30,743:INFO:   <<< max_frames: 16
2022-06-21 20:00:30,743:INFO:   <<< max_words: 32
2022-06-21 20:00:30,743:INFO:   <<< n_display: 50
2022-06-21 20:00:30,743:INFO:   <<< n_gpu: 1
2022-06-21 20:00:30,743:INFO:   <<< n_pair: 1
2022-06-21 20:00:30,743:INFO:   <<< negative_weighting: 1
2022-06-21 20:00:30,743:INFO:   <<< num_thread_reader: 2
2022-06-21 20:00:30,743:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:00:30,743:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:00:30,743:INFO:   <<< rank: 0
2022-06-21 20:00:30,743:INFO:   <<< resume_model: None
2022-06-21 20:00:30,743:INFO:   <<< sampled_use_mil: False
2022-06-21 20:00:30,743:INFO:   <<< seed: 42
2022-06-21 20:00:30,743:INFO:   <<< sim_header: meanP
2022-06-21 20:00:30,743:INFO:   <<< slice_framepos: 2
2022-06-21 20:00:30,743:INFO:   <<< task_type: retrieval
2022-06-21 20:00:30,743:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:00:30,743:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:00:30,743:INFO:   <<< train_frame_order: 0
2022-06-21 20:00:30,743:INFO:   <<< use_mil: False
2022-06-21 20:00:30,743:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:00:30,743:INFO:   <<< video_dim: 1024
2022-06-21 20:00:30,743:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:00:30,744:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:00:30,744:INFO:   <<< world_size: 1
2022-06-21 20:00:30,744:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:00:31,455:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:00:31,455:WARNING: Test retrieval by loose type.
2022-06-21 20:00:31,455:WARNING: 	 embed_dim: 512
2022-06-21 20:00:31,455:WARNING: 	 image_resolution: 224
2022-06-21 20:00:31,455:WARNING: 	 vision_layers: 12
2022-06-21 20:00:31,455:WARNING: 	 vision_width: 768
2022-06-21 20:00:31,456:WARNING: 	 vision_patch_size: 32
2022-06-21 20:00:31,456:WARNING: 	 context_length: 77
2022-06-21 20:00:31,456:WARNING: 	 vocab_size: 49408
2022-06-21 20:00:31,456:WARNING: 	 transformer_width: 512
2022-06-21 20:00:31,456:WARNING: 	 transformer_heads: 8
2022-06-21 20:00:31,456:WARNING: 	 transformer_layers: 12
2022-06-21 20:00:31,456:WARNING: 		 linear_patch: 3d
2022-06-21 20:00:31,456:WARNING: 	 cut_top_layer: 0
2022-06-21 20:00:39,342:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:00:54,778:INFO: ***** Running test *****
2022-06-21 20:00:54,778:INFO:   Num examples = 27763
2022-06-21 20:00:54,778:INFO:   Batch size = 16
2022-06-21 20:00:54,778:INFO:   Num steps = 1736
2022-06-21 20:00:54,778:INFO: ***** Running val *****
2022-06-21 20:00:54,778:INFO:   Num examples = 4290
2022-06-21 20:00:55,485:INFO: ***** Running training *****
2022-06-21 20:00:55,486:INFO:   Num examples = 48774
2022-06-21 20:00:55,486:INFO:   Batch size = 128
2022-06-21 20:00:55,486:INFO:   Num steps = 3810
2022-06-21 20:02:24,239:INFO: Effective parameters:
2022-06-21 20:02:24,240:INFO:   <<< batch_size: 128
2022-06-21 20:02:24,240:INFO:   <<< batch_size_val: 16
2022-06-21 20:02:24,240:INFO:   <<< cache_dir: 
2022-06-21 20:02:24,240:INFO:   <<< coef_lr: 0.001
2022-06-21 20:02:24,240:INFO:   <<< cross_model: cross-base
2022-06-21 20:02:24,240:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:02:24,240:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:02:24,240:INFO:   <<< datatype: msvd
2022-06-21 20:02:24,240:INFO:   <<< do_eval: False
2022-06-21 20:02:24,240:INFO:   <<< do_lower_case: False
2022-06-21 20:02:24,240:INFO:   <<< do_pretrain: False
2022-06-21 20:02:24,240:INFO:   <<< do_train: True
2022-06-21 20:02:24,240:INFO:   <<< epochs: 5
2022-06-21 20:02:24,240:INFO:   <<< eval_frame_order: 0
2022-06-21 20:02:24,240:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:02:24,240:INFO:   <<< feature_framerate: 1
2022-06-21 20:02:24,240:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:02:24,240:INFO:   <<< fp16: False
2022-06-21 20:02:24,240:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:02:24,240:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:02:24,240:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:02:24,240:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:02:24,241:INFO:   <<< init_model: None
2022-06-21 20:02:24,241:INFO:   <<< linear_patch: 3d
2022-06-21 20:02:24,241:INFO:   <<< local_rank: 0
2022-06-21 20:02:24,241:INFO:   <<< loose_type: True
2022-06-21 20:02:24,241:INFO:   <<< lr: 0.0001
2022-06-21 20:02:24,241:INFO:   <<< lr_decay: 0.9
2022-06-21 20:02:24,241:INFO:   <<< margin: 0.1
2022-06-21 20:02:24,241:INFO:   <<< max_frames: 16
2022-06-21 20:02:24,241:INFO:   <<< max_words: 32
2022-06-21 20:02:24,241:INFO:   <<< n_display: 50
2022-06-21 20:02:24,241:INFO:   <<< n_gpu: 1
2022-06-21 20:02:24,241:INFO:   <<< n_pair: 1
2022-06-21 20:02:24,241:INFO:   <<< negative_weighting: 1
2022-06-21 20:02:24,241:INFO:   <<< num_thread_reader: 2
2022-06-21 20:02:24,241:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:02:24,241:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:02:24,241:INFO:   <<< rank: 0
2022-06-21 20:02:24,241:INFO:   <<< resume_model: None
2022-06-21 20:02:24,241:INFO:   <<< sampled_use_mil: False
2022-06-21 20:02:24,241:INFO:   <<< seed: 42
2022-06-21 20:02:24,241:INFO:   <<< sim_header: meanP
2022-06-21 20:02:24,241:INFO:   <<< slice_framepos: 2
2022-06-21 20:02:24,241:INFO:   <<< task_type: retrieval
2022-06-21 20:02:24,241:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:02:24,241:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:02:24,241:INFO:   <<< train_frame_order: 0
2022-06-21 20:02:24,241:INFO:   <<< use_mil: False
2022-06-21 20:02:24,242:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:02:24,242:INFO:   <<< video_dim: 1024
2022-06-21 20:02:24,242:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:02:24,242:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:02:24,242:INFO:   <<< world_size: 1
2022-06-21 20:02:24,242:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:02:24,961:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:02:24,961:WARNING: Test retrieval by loose type.
2022-06-21 20:02:24,962:WARNING: 	 embed_dim: 512
2022-06-21 20:02:24,962:WARNING: 	 image_resolution: 224
2022-06-21 20:02:24,962:WARNING: 	 vision_layers: 12
2022-06-21 20:02:24,962:WARNING: 	 vision_width: 768
2022-06-21 20:02:24,962:WARNING: 	 vision_patch_size: 32
2022-06-21 20:02:24,962:WARNING: 	 context_length: 77
2022-06-21 20:02:24,962:WARNING: 	 vocab_size: 49408
2022-06-21 20:02:24,962:WARNING: 	 transformer_width: 512
2022-06-21 20:02:24,962:WARNING: 	 transformer_heads: 8
2022-06-21 20:02:24,962:WARNING: 	 transformer_layers: 12
2022-06-21 20:02:24,962:WARNING: 		 linear_patch: 3d
2022-06-21 20:02:24,962:WARNING: 	 cut_top_layer: 0
2022-06-21 20:02:32,287:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:02:45,720:INFO: ***** Running test *****
2022-06-21 20:02:45,721:INFO:   Num examples = 27763
2022-06-21 20:02:45,721:INFO:   Batch size = 16
2022-06-21 20:02:45,721:INFO:   Num steps = 1736
2022-06-21 20:02:45,721:INFO: ***** Running val *****
2022-06-21 20:02:45,721:INFO:   Num examples = 4290
2022-06-21 20:02:46,546:INFO: ***** Running training *****
2022-06-21 20:02:46,547:INFO:   Num examples = 48774
2022-06-21 20:02:46,547:INFO:   Batch size = 128
2022-06-21 20:02:46,547:INFO:   Num steps = 3810
2022-06-21 20:04:40,504:INFO: Effective parameters:
2022-06-21 20:04:40,505:INFO:   <<< batch_size: 128
2022-06-21 20:04:40,505:INFO:   <<< batch_size_val: 16
2022-06-21 20:04:40,505:INFO:   <<< cache_dir: 
2022-06-21 20:04:40,505:INFO:   <<< coef_lr: 0.001
2022-06-21 20:04:40,505:INFO:   <<< cross_model: cross-base
2022-06-21 20:04:40,505:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:04:40,505:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:04:40,505:INFO:   <<< datatype: msvd
2022-06-21 20:04:40,505:INFO:   <<< do_eval: False
2022-06-21 20:04:40,505:INFO:   <<< do_lower_case: False
2022-06-21 20:04:40,505:INFO:   <<< do_pretrain: False
2022-06-21 20:04:40,505:INFO:   <<< do_train: True
2022-06-21 20:04:40,505:INFO:   <<< epochs: 5
2022-06-21 20:04:40,505:INFO:   <<< eval_frame_order: 0
2022-06-21 20:04:40,505:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:04:40,505:INFO:   <<< feature_framerate: 1
2022-06-21 20:04:40,505:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:04:40,505:INFO:   <<< fp16: False
2022-06-21 20:04:40,505:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:04:40,505:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:04:40,505:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:04:40,505:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:04:40,505:INFO:   <<< init_model: None
2022-06-21 20:04:40,505:INFO:   <<< linear_patch: 3d
2022-06-21 20:04:40,505:INFO:   <<< local_rank: 0
2022-06-21 20:04:40,505:INFO:   <<< loose_type: True
2022-06-21 20:04:40,505:INFO:   <<< lr: 0.0001
2022-06-21 20:04:40,505:INFO:   <<< lr_decay: 0.9
2022-06-21 20:04:40,505:INFO:   <<< margin: 0.1
2022-06-21 20:04:40,505:INFO:   <<< max_frames: 16
2022-06-21 20:04:40,506:INFO:   <<< max_words: 32
2022-06-21 20:04:40,506:INFO:   <<< n_display: 50
2022-06-21 20:04:40,506:INFO:   <<< n_gpu: 1
2022-06-21 20:04:40,506:INFO:   <<< n_pair: 1
2022-06-21 20:04:40,506:INFO:   <<< negative_weighting: 1
2022-06-21 20:04:40,506:INFO:   <<< num_thread_reader: 2
2022-06-21 20:04:40,506:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:04:40,506:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:04:40,506:INFO:   <<< rank: 0
2022-06-21 20:04:40,506:INFO:   <<< resume_model: None
2022-06-21 20:04:40,506:INFO:   <<< sampled_use_mil: False
2022-06-21 20:04:40,506:INFO:   <<< seed: 42
2022-06-21 20:04:40,506:INFO:   <<< sim_header: meanP
2022-06-21 20:04:40,506:INFO:   <<< slice_framepos: 2
2022-06-21 20:04:40,506:INFO:   <<< task_type: retrieval
2022-06-21 20:04:40,506:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:04:40,506:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:04:40,506:INFO:   <<< train_frame_order: 0
2022-06-21 20:04:40,506:INFO:   <<< use_mil: False
2022-06-21 20:04:40,506:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:04:40,506:INFO:   <<< video_dim: 1024
2022-06-21 20:04:40,506:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:04:40,506:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:04:40,506:INFO:   <<< world_size: 1
2022-06-21 20:04:40,506:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:04:41,203:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:04:41,204:WARNING: Test retrieval by loose type.
2022-06-21 20:04:41,204:WARNING: 	 embed_dim: 512
2022-06-21 20:04:41,204:WARNING: 	 image_resolution: 224
2022-06-21 20:04:41,204:WARNING: 	 vision_layers: 12
2022-06-21 20:04:41,204:WARNING: 	 vision_width: 768
2022-06-21 20:04:41,204:WARNING: 	 vision_patch_size: 32
2022-06-21 20:04:41,204:WARNING: 	 context_length: 77
2022-06-21 20:04:41,204:WARNING: 	 vocab_size: 49408
2022-06-21 20:04:41,204:WARNING: 	 transformer_width: 512
2022-06-21 20:04:41,205:WARNING: 	 transformer_heads: 8
2022-06-21 20:04:41,205:WARNING: 	 transformer_layers: 12
2022-06-21 20:04:41,205:WARNING: 		 linear_patch: 3d
2022-06-21 20:04:41,205:WARNING: 	 cut_top_layer: 0
2022-06-21 20:04:48,529:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:05:02,933:INFO: ***** Running test *****
2022-06-21 20:05:02,933:INFO:   Num examples = 27763
2022-06-21 20:05:02,933:INFO:   Batch size = 16
2022-06-21 20:05:02,933:INFO:   Num steps = 1736
2022-06-21 20:05:02,933:INFO: ***** Running val *****
2022-06-21 20:05:02,933:INFO:   Num examples = 4290
2022-06-21 20:05:03,782:INFO: ***** Running training *****
2022-06-21 20:05:03,782:INFO:   Num examples = 48774
2022-06-21 20:05:03,782:INFO:   Batch size = 128
2022-06-21 20:05:03,782:INFO:   Num steps = 3810
2022-06-21 20:06:46,248:INFO: Effective parameters:
2022-06-21 20:06:46,248:INFO:   <<< batch_size: 128
2022-06-21 20:06:46,248:INFO:   <<< batch_size_val: 16
2022-06-21 20:06:46,248:INFO:   <<< cache_dir: 
2022-06-21 20:06:46,248:INFO:   <<< coef_lr: 0.001
2022-06-21 20:06:46,248:INFO:   <<< cross_model: cross-base
2022-06-21 20:06:46,248:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:06:46,248:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:06:46,248:INFO:   <<< datatype: msvd
2022-06-21 20:06:46,249:INFO:   <<< do_eval: False
2022-06-21 20:06:46,249:INFO:   <<< do_lower_case: False
2022-06-21 20:06:46,249:INFO:   <<< do_pretrain: False
2022-06-21 20:06:46,249:INFO:   <<< do_train: True
2022-06-21 20:06:46,249:INFO:   <<< epochs: 5
2022-06-21 20:06:46,249:INFO:   <<< eval_frame_order: 0
2022-06-21 20:06:46,249:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:06:46,249:INFO:   <<< feature_framerate: 1
2022-06-21 20:06:46,249:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:06:46,249:INFO:   <<< fp16: False
2022-06-21 20:06:46,249:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:06:46,249:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:06:46,249:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:06:46,249:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:06:46,249:INFO:   <<< init_model: None
2022-06-21 20:06:46,249:INFO:   <<< linear_patch: 3d
2022-06-21 20:06:46,249:INFO:   <<< local_rank: 0
2022-06-21 20:06:46,249:INFO:   <<< loose_type: True
2022-06-21 20:06:46,249:INFO:   <<< lr: 0.0001
2022-06-21 20:06:46,249:INFO:   <<< lr_decay: 0.9
2022-06-21 20:06:46,249:INFO:   <<< margin: 0.1
2022-06-21 20:06:46,249:INFO:   <<< max_frames: 16
2022-06-21 20:06:46,249:INFO:   <<< max_words: 32
2022-06-21 20:06:46,249:INFO:   <<< n_display: 50
2022-06-21 20:06:46,249:INFO:   <<< n_gpu: 1
2022-06-21 20:06:46,249:INFO:   <<< n_pair: 1
2022-06-21 20:06:46,249:INFO:   <<< negative_weighting: 1
2022-06-21 20:06:46,249:INFO:   <<< num_thread_reader: 2
2022-06-21 20:06:46,249:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:06:46,249:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:06:46,249:INFO:   <<< rank: 0
2022-06-21 20:06:46,250:INFO:   <<< resume_model: None
2022-06-21 20:06:46,250:INFO:   <<< sampled_use_mil: False
2022-06-21 20:06:46,250:INFO:   <<< seed: 42
2022-06-21 20:06:46,250:INFO:   <<< sim_header: meanP
2022-06-21 20:06:46,250:INFO:   <<< slice_framepos: 2
2022-06-21 20:06:46,250:INFO:   <<< task_type: retrieval
2022-06-21 20:06:46,250:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:06:46,250:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:06:46,250:INFO:   <<< train_frame_order: 0
2022-06-21 20:06:46,250:INFO:   <<< use_mil: False
2022-06-21 20:06:46,250:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:06:46,250:INFO:   <<< video_dim: 1024
2022-06-21 20:06:46,250:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:06:46,250:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:06:46,250:INFO:   <<< world_size: 1
2022-06-21 20:06:46,250:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:06:46,969:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:06:46,969:WARNING: Test retrieval by loose type.
2022-06-21 20:06:46,970:WARNING: 	 embed_dim: 512
2022-06-21 20:06:46,970:WARNING: 	 image_resolution: 224
2022-06-21 20:06:46,970:WARNING: 	 vision_layers: 12
2022-06-21 20:06:46,971:WARNING: 	 vision_width: 768
2022-06-21 20:06:46,971:WARNING: 	 vision_patch_size: 32
2022-06-21 20:06:46,971:WARNING: 	 context_length: 77
2022-06-21 20:06:46,971:WARNING: 	 vocab_size: 49408
2022-06-21 20:06:46,971:WARNING: 	 transformer_width: 512
2022-06-21 20:06:46,972:WARNING: 	 transformer_heads: 8
2022-06-21 20:06:46,972:WARNING: 	 transformer_layers: 12
2022-06-21 20:06:46,972:WARNING: 		 linear_patch: 3d
2022-06-21 20:06:46,972:WARNING: 	 cut_top_layer: 0
2022-06-21 20:06:54,342:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:07:07,967:INFO: ***** Running test *****
2022-06-21 20:07:07,967:INFO:   Num examples = 27763
2022-06-21 20:07:07,967:INFO:   Batch size = 16
2022-06-21 20:07:07,967:INFO:   Num steps = 1736
2022-06-21 20:07:07,967:INFO: ***** Running val *****
2022-06-21 20:07:07,967:INFO:   Num examples = 4290
2022-06-21 20:07:08,675:INFO: ***** Running training *****
2022-06-21 20:07:08,675:INFO:   Num examples = 48774
2022-06-21 20:07:08,675:INFO:   Batch size = 128
2022-06-21 20:07:08,675:INFO:   Num steps = 3810
2022-06-21 20:08:28,369:INFO: Effective parameters:
2022-06-21 20:08:28,369:INFO:   <<< batch_size: 128
2022-06-21 20:08:28,369:INFO:   <<< batch_size_val: 16
2022-06-21 20:08:28,369:INFO:   <<< cache_dir: 
2022-06-21 20:08:28,369:INFO:   <<< coef_lr: 0.001
2022-06-21 20:08:28,369:INFO:   <<< cross_model: cross-base
2022-06-21 20:08:28,369:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:08:28,369:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:08:28,369:INFO:   <<< datatype: msvd
2022-06-21 20:08:28,369:INFO:   <<< do_eval: False
2022-06-21 20:08:28,369:INFO:   <<< do_lower_case: False
2022-06-21 20:08:28,369:INFO:   <<< do_pretrain: False
2022-06-21 20:08:28,369:INFO:   <<< do_train: True
2022-06-21 20:08:28,369:INFO:   <<< epochs: 5
2022-06-21 20:08:28,369:INFO:   <<< eval_frame_order: 0
2022-06-21 20:08:28,369:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:08:28,369:INFO:   <<< feature_framerate: 1
2022-06-21 20:08:28,369:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:08:28,370:INFO:   <<< fp16: False
2022-06-21 20:08:28,370:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:08:28,370:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:08:28,370:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:08:28,370:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:08:28,370:INFO:   <<< init_model: None
2022-06-21 20:08:28,370:INFO:   <<< linear_patch: 3d
2022-06-21 20:08:28,370:INFO:   <<< local_rank: 0
2022-06-21 20:08:28,370:INFO:   <<< loose_type: True
2022-06-21 20:08:28,370:INFO:   <<< lr: 0.0001
2022-06-21 20:08:28,370:INFO:   <<< lr_decay: 0.9
2022-06-21 20:08:28,370:INFO:   <<< margin: 0.1
2022-06-21 20:08:28,370:INFO:   <<< max_frames: 16
2022-06-21 20:08:28,370:INFO:   <<< max_words: 32
2022-06-21 20:08:28,370:INFO:   <<< n_display: 50
2022-06-21 20:08:28,370:INFO:   <<< n_gpu: 1
2022-06-21 20:08:28,370:INFO:   <<< n_pair: 1
2022-06-21 20:08:28,370:INFO:   <<< negative_weighting: 1
2022-06-21 20:08:28,370:INFO:   <<< num_thread_reader: 2
2022-06-21 20:08:28,370:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:08:28,370:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:08:28,370:INFO:   <<< rank: 0
2022-06-21 20:08:28,370:INFO:   <<< resume_model: None
2022-06-21 20:08:28,370:INFO:   <<< sampled_use_mil: False
2022-06-21 20:08:28,370:INFO:   <<< seed: 42
2022-06-21 20:08:28,370:INFO:   <<< sim_header: meanP
2022-06-21 20:08:28,370:INFO:   <<< slice_framepos: 2
2022-06-21 20:08:28,370:INFO:   <<< task_type: retrieval
2022-06-21 20:08:28,371:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:08:28,371:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:08:28,371:INFO:   <<< train_frame_order: 0
2022-06-21 20:08:28,371:INFO:   <<< use_mil: False
2022-06-21 20:08:28,371:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:08:28,371:INFO:   <<< video_dim: 1024
2022-06-21 20:08:28,371:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:08:28,371:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:08:28,371:INFO:   <<< world_size: 1
2022-06-21 20:08:28,371:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:08:29,072:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:08:29,072:WARNING: Test retrieval by loose type.
2022-06-21 20:08:29,073:WARNING: 	 embed_dim: 512
2022-06-21 20:08:29,073:WARNING: 	 image_resolution: 224
2022-06-21 20:08:29,073:WARNING: 	 vision_layers: 12
2022-06-21 20:08:29,073:WARNING: 	 vision_width: 768
2022-06-21 20:08:29,073:WARNING: 	 vision_patch_size: 32
2022-06-21 20:08:29,073:WARNING: 	 context_length: 77
2022-06-21 20:08:29,073:WARNING: 	 vocab_size: 49408
2022-06-21 20:08:29,073:WARNING: 	 transformer_width: 512
2022-06-21 20:08:29,073:WARNING: 	 transformer_heads: 8
2022-06-21 20:08:29,073:WARNING: 	 transformer_layers: 12
2022-06-21 20:08:29,073:WARNING: 		 linear_patch: 3d
2022-06-21 20:08:29,073:WARNING: 	 cut_top_layer: 0
2022-06-21 20:08:36,442:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:08:50,139:INFO: ***** Running test *****
2022-06-21 20:08:50,139:INFO:   Num examples = 27763
2022-06-21 20:08:50,140:INFO:   Batch size = 16
2022-06-21 20:08:50,140:INFO:   Num steps = 1736
2022-06-21 20:08:50,140:INFO: ***** Running val *****
2022-06-21 20:08:50,140:INFO:   Num examples = 4290
2022-06-21 20:08:50,870:INFO: ***** Running training *****
2022-06-21 20:08:50,870:INFO:   Num examples = 48774
2022-06-21 20:08:50,870:INFO:   Batch size = 128
2022-06-21 20:08:50,871:INFO:   Num steps = 3810
2022-06-21 20:10:22,460:INFO: Effective parameters:
2022-06-21 20:10:22,460:INFO:   <<< batch_size: 128
2022-06-21 20:10:22,460:INFO:   <<< batch_size_val: 16
2022-06-21 20:10:22,460:INFO:   <<< cache_dir: 
2022-06-21 20:10:22,460:INFO:   <<< coef_lr: 0.001
2022-06-21 20:10:22,460:INFO:   <<< cross_model: cross-base
2022-06-21 20:10:22,460:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:10:22,460:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:10:22,460:INFO:   <<< datatype: msvd
2022-06-21 20:10:22,460:INFO:   <<< do_eval: False
2022-06-21 20:10:22,461:INFO:   <<< do_lower_case: False
2022-06-21 20:10:22,461:INFO:   <<< do_pretrain: False
2022-06-21 20:10:22,461:INFO:   <<< do_train: True
2022-06-21 20:10:22,461:INFO:   <<< epochs: 5
2022-06-21 20:10:22,461:INFO:   <<< eval_frame_order: 0
2022-06-21 20:10:22,461:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:10:22,461:INFO:   <<< feature_framerate: 1
2022-06-21 20:10:22,461:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:10:22,461:INFO:   <<< fp16: False
2022-06-21 20:10:22,461:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:10:22,461:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:10:22,461:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:10:22,461:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:10:22,461:INFO:   <<< init_model: None
2022-06-21 20:10:22,461:INFO:   <<< linear_patch: 3d
2022-06-21 20:10:22,461:INFO:   <<< local_rank: 0
2022-06-21 20:10:22,461:INFO:   <<< loose_type: True
2022-06-21 20:10:22,461:INFO:   <<< lr: 0.0001
2022-06-21 20:10:22,461:INFO:   <<< lr_decay: 0.9
2022-06-21 20:10:22,461:INFO:   <<< margin: 0.1
2022-06-21 20:10:22,461:INFO:   <<< max_frames: 16
2022-06-21 20:10:22,461:INFO:   <<< max_words: 32
2022-06-21 20:10:22,461:INFO:   <<< n_display: 50
2022-06-21 20:10:22,461:INFO:   <<< n_gpu: 1
2022-06-21 20:10:22,461:INFO:   <<< n_pair: 1
2022-06-21 20:10:22,461:INFO:   <<< negative_weighting: 1
2022-06-21 20:10:22,461:INFO:   <<< num_thread_reader: 2
2022-06-21 20:10:22,461:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:10:22,461:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:10:22,461:INFO:   <<< rank: 0
2022-06-21 20:10:22,461:INFO:   <<< resume_model: None
2022-06-21 20:10:22,462:INFO:   <<< sampled_use_mil: False
2022-06-21 20:10:22,462:INFO:   <<< seed: 42
2022-06-21 20:10:22,462:INFO:   <<< sim_header: meanP
2022-06-21 20:10:22,462:INFO:   <<< slice_framepos: 2
2022-06-21 20:10:22,462:INFO:   <<< task_type: retrieval
2022-06-21 20:10:22,462:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:10:22,462:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:10:22,462:INFO:   <<< train_frame_order: 0
2022-06-21 20:10:22,462:INFO:   <<< use_mil: False
2022-06-21 20:10:22,462:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:10:22,462:INFO:   <<< video_dim: 1024
2022-06-21 20:10:22,462:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:10:22,462:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:10:22,462:INFO:   <<< world_size: 1
2022-06-21 20:10:22,462:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:10:23,197:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:10:23,197:WARNING: Test retrieval by loose type.
2022-06-21 20:10:23,197:WARNING: 	 embed_dim: 512
2022-06-21 20:10:23,197:WARNING: 	 image_resolution: 224
2022-06-21 20:10:23,197:WARNING: 	 vision_layers: 12
2022-06-21 20:10:23,197:WARNING: 	 vision_width: 768
2022-06-21 20:10:23,197:WARNING: 	 vision_patch_size: 32
2022-06-21 20:10:23,198:WARNING: 	 context_length: 77
2022-06-21 20:10:23,198:WARNING: 	 vocab_size: 49408
2022-06-21 20:10:23,198:WARNING: 	 transformer_width: 512
2022-06-21 20:10:23,198:WARNING: 	 transformer_heads: 8
2022-06-21 20:10:23,198:WARNING: 	 transformer_layers: 12
2022-06-21 20:10:23,198:WARNING: 		 linear_patch: 3d
2022-06-21 20:10:23,198:WARNING: 	 cut_top_layer: 0
2022-06-21 20:10:30,616:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:10:45,299:INFO: ***** Running test *****
2022-06-21 20:10:45,299:INFO:   Num examples = 27763
2022-06-21 20:10:45,299:INFO:   Batch size = 16
2022-06-21 20:10:45,299:INFO:   Num steps = 1736
2022-06-21 20:10:45,299:INFO: ***** Running val *****
2022-06-21 20:10:45,299:INFO:   Num examples = 4290
2022-06-21 20:10:46,000:INFO: ***** Running training *****
2022-06-21 20:10:46,000:INFO:   Num examples = 48774
2022-06-21 20:10:46,000:INFO:   Batch size = 128
2022-06-21 20:10:46,000:INFO:   Num steps = 3810
2022-06-21 20:12:48,290:INFO: Effective parameters:
2022-06-21 20:12:48,291:INFO:   <<< batch_size: 128
2022-06-21 20:12:48,291:INFO:   <<< batch_size_val: 16
2022-06-21 20:12:48,291:INFO:   <<< cache_dir: 
2022-06-21 20:12:48,291:INFO:   <<< coef_lr: 0.001
2022-06-21 20:12:48,291:INFO:   <<< cross_model: cross-base
2022-06-21 20:12:48,291:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:12:48,291:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:12:48,291:INFO:   <<< datatype: msvd
2022-06-21 20:12:48,291:INFO:   <<< do_eval: False
2022-06-21 20:12:48,291:INFO:   <<< do_lower_case: False
2022-06-21 20:12:48,291:INFO:   <<< do_pretrain: False
2022-06-21 20:12:48,291:INFO:   <<< do_train: True
2022-06-21 20:12:48,291:INFO:   <<< epochs: 5
2022-06-21 20:12:48,291:INFO:   <<< eval_frame_order: 0
2022-06-21 20:12:48,291:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:12:48,291:INFO:   <<< feature_framerate: 1
2022-06-21 20:12:48,291:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:12:48,291:INFO:   <<< fp16: False
2022-06-21 20:12:48,291:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:12:48,291:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:12:48,291:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:12:48,291:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:12:48,291:INFO:   <<< init_model: None
2022-06-21 20:12:48,291:INFO:   <<< linear_patch: 3d
2022-06-21 20:12:48,291:INFO:   <<< local_rank: 0
2022-06-21 20:12:48,291:INFO:   <<< loose_type: True
2022-06-21 20:12:48,291:INFO:   <<< lr: 0.0001
2022-06-21 20:12:48,291:INFO:   <<< lr_decay: 0.9
2022-06-21 20:12:48,291:INFO:   <<< margin: 0.1
2022-06-21 20:12:48,291:INFO:   <<< max_frames: 16
2022-06-21 20:12:48,292:INFO:   <<< max_words: 32
2022-06-21 20:12:48,292:INFO:   <<< n_display: 50
2022-06-21 20:12:48,292:INFO:   <<< n_gpu: 1
2022-06-21 20:12:48,292:INFO:   <<< n_pair: 1
2022-06-21 20:12:48,292:INFO:   <<< negative_weighting: 1
2022-06-21 20:12:48,292:INFO:   <<< num_thread_reader: 2
2022-06-21 20:12:48,292:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:12:48,292:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:12:48,292:INFO:   <<< rank: 0
2022-06-21 20:12:48,292:INFO:   <<< resume_model: None
2022-06-21 20:12:48,292:INFO:   <<< sampled_use_mil: False
2022-06-21 20:12:48,292:INFO:   <<< seed: 42
2022-06-21 20:12:48,292:INFO:   <<< sim_header: meanP
2022-06-21 20:12:48,292:INFO:   <<< slice_framepos: 2
2022-06-21 20:12:48,292:INFO:   <<< task_type: retrieval
2022-06-21 20:12:48,292:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:12:48,292:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:12:48,292:INFO:   <<< train_frame_order: 0
2022-06-21 20:12:48,292:INFO:   <<< use_mil: False
2022-06-21 20:12:48,292:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:12:48,292:INFO:   <<< video_dim: 1024
2022-06-21 20:12:48,292:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:12:48,292:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:12:48,292:INFO:   <<< world_size: 1
2022-06-21 20:12:48,292:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:12:49,025:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:12:49,026:WARNING: Test retrieval by loose type.
2022-06-21 20:12:49,026:WARNING: 	 embed_dim: 512
2022-06-21 20:12:49,026:WARNING: 	 image_resolution: 224
2022-06-21 20:12:49,026:WARNING: 	 vision_layers: 12
2022-06-21 20:12:49,026:WARNING: 	 vision_width: 768
2022-06-21 20:12:49,026:WARNING: 	 vision_patch_size: 32
2022-06-21 20:12:49,026:WARNING: 	 context_length: 77
2022-06-21 20:12:49,026:WARNING: 	 vocab_size: 49408
2022-06-21 20:12:49,026:WARNING: 	 transformer_width: 512
2022-06-21 20:12:49,026:WARNING: 	 transformer_heads: 8
2022-06-21 20:12:49,027:WARNING: 	 transformer_layers: 12
2022-06-21 20:12:49,027:WARNING: 		 linear_patch: 3d
2022-06-21 20:12:49,027:WARNING: 	 cut_top_layer: 0
2022-06-21 20:12:56,366:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:13:10,895:INFO: ***** Running test *****
2022-06-21 20:13:10,895:INFO:   Num examples = 27763
2022-06-21 20:13:10,895:INFO:   Batch size = 16
2022-06-21 20:13:10,895:INFO:   Num steps = 1736
2022-06-21 20:13:10,895:INFO: ***** Running val *****
2022-06-21 20:13:10,896:INFO:   Num examples = 4290
2022-06-21 20:13:11,671:INFO: ***** Running training *****
2022-06-21 20:13:11,671:INFO:   Num examples = 48774
2022-06-21 20:13:11,671:INFO:   Batch size = 128
2022-06-21 20:13:11,671:INFO:   Num steps = 3810
2022-06-21 20:18:13,417:INFO: Effective parameters:
2022-06-21 20:18:13,418:INFO:   <<< batch_size: 128
2022-06-21 20:18:13,418:INFO:   <<< batch_size_val: 16
2022-06-21 20:18:13,418:INFO:   <<< cache_dir: 
2022-06-21 20:18:13,418:INFO:   <<< coef_lr: 0.001
2022-06-21 20:18:13,418:INFO:   <<< cross_model: cross-base
2022-06-21 20:18:13,418:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:18:13,418:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:18:13,418:INFO:   <<< datatype: msvd
2022-06-21 20:18:13,418:INFO:   <<< do_eval: False
2022-06-21 20:18:13,418:INFO:   <<< do_lower_case: False
2022-06-21 20:18:13,418:INFO:   <<< do_pretrain: False
2022-06-21 20:18:13,418:INFO:   <<< do_train: True
2022-06-21 20:18:13,418:INFO:   <<< epochs: 5
2022-06-21 20:18:13,418:INFO:   <<< eval_frame_order: 0
2022-06-21 20:18:13,418:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:18:13,418:INFO:   <<< feature_framerate: 1
2022-06-21 20:18:13,418:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:18:13,418:INFO:   <<< fp16: False
2022-06-21 20:18:13,418:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:18:13,418:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:18:13,418:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:18:13,418:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:18:13,418:INFO:   <<< init_model: None
2022-06-21 20:18:13,418:INFO:   <<< linear_patch: 3d
2022-06-21 20:18:13,419:INFO:   <<< local_rank: 0
2022-06-21 20:18:13,419:INFO:   <<< loose_type: True
2022-06-21 20:18:13,419:INFO:   <<< lr: 0.0001
2022-06-21 20:18:13,419:INFO:   <<< lr_decay: 0.9
2022-06-21 20:18:13,419:INFO:   <<< margin: 0.1
2022-06-21 20:18:13,419:INFO:   <<< max_frames: 16
2022-06-21 20:18:13,419:INFO:   <<< max_words: 32
2022-06-21 20:18:13,419:INFO:   <<< n_display: 50
2022-06-21 20:18:13,419:INFO:   <<< n_gpu: 1
2022-06-21 20:18:13,419:INFO:   <<< n_pair: 1
2022-06-21 20:18:13,419:INFO:   <<< negative_weighting: 1
2022-06-21 20:18:13,419:INFO:   <<< num_thread_reader: 2
2022-06-21 20:18:13,419:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:18:13,419:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:18:13,419:INFO:   <<< rank: 0
2022-06-21 20:18:13,419:INFO:   <<< resume_model: None
2022-06-21 20:18:13,419:INFO:   <<< sampled_use_mil: False
2022-06-21 20:18:13,419:INFO:   <<< seed: 42
2022-06-21 20:18:13,419:INFO:   <<< sim_header: meanP
2022-06-21 20:18:13,419:INFO:   <<< slice_framepos: 2
2022-06-21 20:18:13,419:INFO:   <<< task_type: retrieval
2022-06-21 20:18:13,419:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:18:13,419:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:18:13,419:INFO:   <<< train_frame_order: 0
2022-06-21 20:18:13,419:INFO:   <<< use_mil: False
2022-06-21 20:18:13,419:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:18:13,420:INFO:   <<< video_dim: 1024
2022-06-21 20:18:13,420:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:18:13,420:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:18:13,420:INFO:   <<< world_size: 1
2022-06-21 20:18:13,420:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:18:14,134:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:18:14,135:WARNING: Test retrieval by loose type.
2022-06-21 20:18:14,135:WARNING: 	 embed_dim: 512
2022-06-21 20:18:14,135:WARNING: 	 image_resolution: 224
2022-06-21 20:18:14,135:WARNING: 	 vision_layers: 12
2022-06-21 20:18:14,135:WARNING: 	 vision_width: 768
2022-06-21 20:18:14,135:WARNING: 	 vision_patch_size: 32
2022-06-21 20:18:14,135:WARNING: 	 context_length: 77
2022-06-21 20:18:14,135:WARNING: 	 vocab_size: 49408
2022-06-21 20:18:14,135:WARNING: 	 transformer_width: 512
2022-06-21 20:18:14,135:WARNING: 	 transformer_heads: 8
2022-06-21 20:18:14,136:WARNING: 	 transformer_layers: 12
2022-06-21 20:18:14,136:WARNING: 		 linear_patch: 3d
2022-06-21 20:18:14,136:WARNING: 	 cut_top_layer: 0
2022-06-21 20:18:21,852:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:18:33,898:INFO: ***** Running test *****
2022-06-21 20:18:33,899:INFO:   Num examples = 27763
2022-06-21 20:18:33,899:INFO:   Batch size = 16
2022-06-21 20:18:33,899:INFO:   Num steps = 1736
2022-06-21 20:18:33,899:INFO: ***** Running val *****
2022-06-21 20:18:33,899:INFO:   Num examples = 4290
2022-06-21 20:18:34,908:INFO: ***** Running training *****
2022-06-21 20:18:34,908:INFO:   Num examples = 48774
2022-06-21 20:18:34,908:INFO:   Batch size = 128
2022-06-21 20:18:34,908:INFO:   Num steps = 3810
2022-06-21 20:19:30,426:INFO: Effective parameters:
2022-06-21 20:19:30,427:INFO:   <<< batch_size: 128
2022-06-21 20:19:30,427:INFO:   <<< batch_size_val: 16
2022-06-21 20:19:30,427:INFO:   <<< cache_dir: 
2022-06-21 20:19:30,427:INFO:   <<< coef_lr: 0.001
2022-06-21 20:19:30,427:INFO:   <<< cross_model: cross-base
2022-06-21 20:19:30,427:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:19:30,427:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:19:30,427:INFO:   <<< datatype: msvd
2022-06-21 20:19:30,427:INFO:   <<< do_eval: False
2022-06-21 20:19:30,427:INFO:   <<< do_lower_case: False
2022-06-21 20:19:30,427:INFO:   <<< do_pretrain: False
2022-06-21 20:19:30,427:INFO:   <<< do_train: True
2022-06-21 20:19:30,427:INFO:   <<< epochs: 5
2022-06-21 20:19:30,427:INFO:   <<< eval_frame_order: 0
2022-06-21 20:19:30,427:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:19:30,427:INFO:   <<< feature_framerate: 1
2022-06-21 20:19:30,427:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:19:30,427:INFO:   <<< fp16: False
2022-06-21 20:19:30,427:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:19:30,428:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:19:30,428:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:19:30,428:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:19:30,428:INFO:   <<< init_model: None
2022-06-21 20:19:30,428:INFO:   <<< linear_patch: 3d
2022-06-21 20:19:30,428:INFO:   <<< local_rank: 0
2022-06-21 20:19:30,428:INFO:   <<< loose_type: True
2022-06-21 20:19:30,428:INFO:   <<< lr: 0.0001
2022-06-21 20:19:30,428:INFO:   <<< lr_decay: 0.9
2022-06-21 20:19:30,428:INFO:   <<< margin: 0.1
2022-06-21 20:19:30,428:INFO:   <<< max_frames: 16
2022-06-21 20:19:30,428:INFO:   <<< max_words: 32
2022-06-21 20:19:30,428:INFO:   <<< n_display: 50
2022-06-21 20:19:30,428:INFO:   <<< n_gpu: 1
2022-06-21 20:19:30,428:INFO:   <<< n_pair: 1
2022-06-21 20:19:30,428:INFO:   <<< negative_weighting: 1
2022-06-21 20:19:30,428:INFO:   <<< num_thread_reader: 2
2022-06-21 20:19:30,428:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:19:30,428:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:19:30,428:INFO:   <<< rank: 0
2022-06-21 20:19:30,428:INFO:   <<< resume_model: None
2022-06-21 20:19:30,428:INFO:   <<< sampled_use_mil: False
2022-06-21 20:19:30,428:INFO:   <<< seed: 42
2022-06-21 20:19:30,428:INFO:   <<< sim_header: meanP
2022-06-21 20:19:30,428:INFO:   <<< slice_framepos: 2
2022-06-21 20:19:30,428:INFO:   <<< task_type: retrieval
2022-06-21 20:19:30,429:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:19:30,429:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:19:30,429:INFO:   <<< train_frame_order: 0
2022-06-21 20:19:30,429:INFO:   <<< use_mil: False
2022-06-21 20:19:30,429:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:19:30,429:INFO:   <<< video_dim: 1024
2022-06-21 20:19:30,429:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:19:30,429:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:19:30,429:INFO:   <<< world_size: 1
2022-06-21 20:19:30,429:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:19:31,132:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:19:31,133:WARNING: Test retrieval by loose type.
2022-06-21 20:19:31,133:WARNING: 	 embed_dim: 512
2022-06-21 20:19:31,133:WARNING: 	 image_resolution: 224
2022-06-21 20:19:31,133:WARNING: 	 vision_layers: 12
2022-06-21 20:19:31,133:WARNING: 	 vision_width: 768
2022-06-21 20:19:31,133:WARNING: 	 vision_patch_size: 32
2022-06-21 20:19:31,133:WARNING: 	 context_length: 77
2022-06-21 20:19:31,133:WARNING: 	 vocab_size: 49408
2022-06-21 20:19:31,133:WARNING: 	 transformer_width: 512
2022-06-21 20:19:31,133:WARNING: 	 transformer_heads: 8
2022-06-21 20:19:31,133:WARNING: 	 transformer_layers: 12
2022-06-21 20:19:31,133:WARNING: 		 linear_patch: 3d
2022-06-21 20:19:31,133:WARNING: 	 cut_top_layer: 0
2022-06-21 20:19:38,587:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:19:52,895:INFO: ***** Running test *****
2022-06-21 20:19:52,895:INFO:   Num examples = 27763
2022-06-21 20:19:52,896:INFO:   Batch size = 16
2022-06-21 20:19:52,896:INFO:   Num steps = 1736
2022-06-21 20:19:52,896:INFO: ***** Running val *****
2022-06-21 20:19:52,896:INFO:   Num examples = 4290
2022-06-21 20:19:53,789:INFO: ***** Running training *****
2022-06-21 20:19:53,790:INFO:   Num examples = 48774
2022-06-21 20:19:53,790:INFO:   Batch size = 128
2022-06-21 20:19:53,790:INFO:   Num steps = 3810
2022-06-21 20:21:08,483:INFO: Effective parameters:
2022-06-21 20:21:08,483:INFO:   <<< batch_size: 128
2022-06-21 20:21:08,483:INFO:   <<< batch_size_val: 16
2022-06-21 20:21:08,483:INFO:   <<< cache_dir: 
2022-06-21 20:21:08,483:INFO:   <<< coef_lr: 0.001
2022-06-21 20:21:08,483:INFO:   <<< cross_model: cross-base
2022-06-21 20:21:08,483:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:21:08,483:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:21:08,483:INFO:   <<< datatype: msvd
2022-06-21 20:21:08,483:INFO:   <<< do_eval: False
2022-06-21 20:21:08,483:INFO:   <<< do_lower_case: False
2022-06-21 20:21:08,483:INFO:   <<< do_pretrain: False
2022-06-21 20:21:08,483:INFO:   <<< do_train: True
2022-06-21 20:21:08,483:INFO:   <<< epochs: 5
2022-06-21 20:21:08,483:INFO:   <<< eval_frame_order: 0
2022-06-21 20:21:08,484:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:21:08,484:INFO:   <<< feature_framerate: 1
2022-06-21 20:21:08,484:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:21:08,484:INFO:   <<< fp16: False
2022-06-21 20:21:08,484:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:21:08,484:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:21:08,484:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:21:08,484:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:21:08,484:INFO:   <<< init_model: None
2022-06-21 20:21:08,484:INFO:   <<< linear_patch: 3d
2022-06-21 20:21:08,484:INFO:   <<< local_rank: 0
2022-06-21 20:21:08,484:INFO:   <<< loose_type: True
2022-06-21 20:21:08,484:INFO:   <<< lr: 0.0001
2022-06-21 20:21:08,484:INFO:   <<< lr_decay: 0.9
2022-06-21 20:21:08,484:INFO:   <<< margin: 0.1
2022-06-21 20:21:08,484:INFO:   <<< max_frames: 16
2022-06-21 20:21:08,484:INFO:   <<< max_words: 32
2022-06-21 20:21:08,484:INFO:   <<< n_display: 50
2022-06-21 20:21:08,484:INFO:   <<< n_gpu: 1
2022-06-21 20:21:08,484:INFO:   <<< n_pair: 1
2022-06-21 20:21:08,484:INFO:   <<< negative_weighting: 1
2022-06-21 20:21:08,484:INFO:   <<< num_thread_reader: 2
2022-06-21 20:21:08,484:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:21:08,484:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:21:08,484:INFO:   <<< rank: 0
2022-06-21 20:21:08,484:INFO:   <<< resume_model: None
2022-06-21 20:21:08,484:INFO:   <<< sampled_use_mil: False
2022-06-21 20:21:08,484:INFO:   <<< seed: 42
2022-06-21 20:21:08,485:INFO:   <<< sim_header: meanP
2022-06-21 20:21:08,485:INFO:   <<< slice_framepos: 2
2022-06-21 20:21:08,485:INFO:   <<< task_type: retrieval
2022-06-21 20:21:08,485:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:21:08,485:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:21:08,485:INFO:   <<< train_frame_order: 0
2022-06-21 20:21:08,485:INFO:   <<< use_mil: False
2022-06-21 20:21:08,485:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:21:08,485:INFO:   <<< video_dim: 1024
2022-06-21 20:21:08,485:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:21:08,485:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:21:08,485:INFO:   <<< world_size: 1
2022-06-21 20:21:08,485:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:21:09,187:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:21:09,187:WARNING: Test retrieval by loose type.
2022-06-21 20:21:09,188:WARNING: 	 embed_dim: 512
2022-06-21 20:21:09,188:WARNING: 	 image_resolution: 224
2022-06-21 20:21:09,188:WARNING: 	 vision_layers: 12
2022-06-21 20:21:09,189:WARNING: 	 vision_width: 768
2022-06-21 20:21:09,189:WARNING: 	 vision_patch_size: 32
2022-06-21 20:21:09,189:WARNING: 	 context_length: 77
2022-06-21 20:21:09,189:WARNING: 	 vocab_size: 49408
2022-06-21 20:21:09,189:WARNING: 	 transformer_width: 512
2022-06-21 20:21:09,190:WARNING: 	 transformer_heads: 8
2022-06-21 20:21:09,190:WARNING: 	 transformer_layers: 12
2022-06-21 20:21:09,190:WARNING: 		 linear_patch: 3d
2022-06-21 20:21:09,191:WARNING: 	 cut_top_layer: 0
2022-06-21 20:21:16,599:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:21:30,690:INFO: ***** Running test *****
2022-06-21 20:21:30,690:INFO:   Num examples = 27763
2022-06-21 20:21:30,690:INFO:   Batch size = 16
2022-06-21 20:21:30,690:INFO:   Num steps = 1736
2022-06-21 20:21:30,690:INFO: ***** Running val *****
2022-06-21 20:21:30,690:INFO:   Num examples = 4290
2022-06-21 20:21:31,474:INFO: ***** Running training *****
2022-06-21 20:21:31,474:INFO:   Num examples = 48774
2022-06-21 20:21:31,474:INFO:   Batch size = 128
2022-06-21 20:21:31,474:INFO:   Num steps = 3810
2022-06-21 20:23:01,541:INFO: Effective parameters:
2022-06-21 20:23:01,541:INFO:   <<< batch_size: 128
2022-06-21 20:23:01,541:INFO:   <<< batch_size_val: 16
2022-06-21 20:23:01,541:INFO:   <<< cache_dir: 
2022-06-21 20:23:01,541:INFO:   <<< coef_lr: 0.001
2022-06-21 20:23:01,541:INFO:   <<< cross_model: cross-base
2022-06-21 20:23:01,541:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:23:01,541:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:23:01,541:INFO:   <<< datatype: msvd
2022-06-21 20:23:01,541:INFO:   <<< do_eval: False
2022-06-21 20:23:01,541:INFO:   <<< do_lower_case: False
2022-06-21 20:23:01,541:INFO:   <<< do_pretrain: False
2022-06-21 20:23:01,541:INFO:   <<< do_train: True
2022-06-21 20:23:01,541:INFO:   <<< epochs: 5
2022-06-21 20:23:01,541:INFO:   <<< eval_frame_order: 0
2022-06-21 20:23:01,541:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:23:01,541:INFO:   <<< feature_framerate: 1
2022-06-21 20:23:01,541:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:23:01,541:INFO:   <<< fp16: False
2022-06-21 20:23:01,542:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:23:01,542:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:23:01,542:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:23:01,542:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:23:01,542:INFO:   <<< init_model: None
2022-06-21 20:23:01,542:INFO:   <<< linear_patch: 3d
2022-06-21 20:23:01,542:INFO:   <<< local_rank: 0
2022-06-21 20:23:01,542:INFO:   <<< loose_type: True
2022-06-21 20:23:01,542:INFO:   <<< lr: 0.0001
2022-06-21 20:23:01,542:INFO:   <<< lr_decay: 0.9
2022-06-21 20:23:01,542:INFO:   <<< margin: 0.1
2022-06-21 20:23:01,542:INFO:   <<< max_frames: 16
2022-06-21 20:23:01,542:INFO:   <<< max_words: 32
2022-06-21 20:23:01,542:INFO:   <<< n_display: 50
2022-06-21 20:23:01,542:INFO:   <<< n_gpu: 1
2022-06-21 20:23:01,542:INFO:   <<< n_pair: 1
2022-06-21 20:23:01,542:INFO:   <<< negative_weighting: 1
2022-06-21 20:23:01,542:INFO:   <<< num_thread_reader: 2
2022-06-21 20:23:01,542:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:23:01,542:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:23:01,542:INFO:   <<< rank: 0
2022-06-21 20:23:01,542:INFO:   <<< resume_model: None
2022-06-21 20:23:01,542:INFO:   <<< sampled_use_mil: False
2022-06-21 20:23:01,542:INFO:   <<< seed: 42
2022-06-21 20:23:01,542:INFO:   <<< sim_header: meanP
2022-06-21 20:23:01,542:INFO:   <<< slice_framepos: 2
2022-06-21 20:23:01,542:INFO:   <<< task_type: retrieval
2022-06-21 20:23:01,542:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:23:01,542:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:23:01,542:INFO:   <<< train_frame_order: 0
2022-06-21 20:23:01,542:INFO:   <<< use_mil: False
2022-06-21 20:23:01,542:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:23:01,543:INFO:   <<< video_dim: 1024
2022-06-21 20:23:01,543:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:23:01,543:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:23:01,543:INFO:   <<< world_size: 1
2022-06-21 20:23:01,543:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:23:02,272:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:23:02,272:WARNING: Test retrieval by loose type.
2022-06-21 20:23:02,273:WARNING: 	 embed_dim: 512
2022-06-21 20:23:02,273:WARNING: 	 image_resolution: 224
2022-06-21 20:23:02,273:WARNING: 	 vision_layers: 12
2022-06-21 20:23:02,273:WARNING: 	 vision_width: 768
2022-06-21 20:23:02,273:WARNING: 	 vision_patch_size: 32
2022-06-21 20:23:02,273:WARNING: 	 context_length: 77
2022-06-21 20:23:02,273:WARNING: 	 vocab_size: 49408
2022-06-21 20:23:02,273:WARNING: 	 transformer_width: 512
2022-06-21 20:23:02,273:WARNING: 	 transformer_heads: 8
2022-06-21 20:23:02,273:WARNING: 	 transformer_layers: 12
2022-06-21 20:23:02,273:WARNING: 		 linear_patch: 3d
2022-06-21 20:23:02,273:WARNING: 	 cut_top_layer: 0
2022-06-21 20:23:09,508:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:23:22,280:INFO: ***** Running test *****
2022-06-21 20:23:22,281:INFO:   Num examples = 27763
2022-06-21 20:23:22,281:INFO:   Batch size = 16
2022-06-21 20:23:22,281:INFO:   Num steps = 1736
2022-06-21 20:23:22,281:INFO: ***** Running val *****
2022-06-21 20:23:22,281:INFO:   Num examples = 4290
2022-06-21 20:23:23,146:INFO: ***** Running training *****
2022-06-21 20:23:23,147:INFO:   Num examples = 48774
2022-06-21 20:23:23,147:INFO:   Batch size = 128
2022-06-21 20:23:23,147:INFO:   Num steps = 3810
2022-06-21 20:24:27,847:INFO: Effective parameters:
2022-06-21 20:24:27,848:INFO:   <<< batch_size: 128
2022-06-21 20:24:27,848:INFO:   <<< batch_size_val: 16
2022-06-21 20:24:27,848:INFO:   <<< cache_dir: 
2022-06-21 20:24:27,848:INFO:   <<< coef_lr: 0.001
2022-06-21 20:24:27,848:INFO:   <<< cross_model: cross-base
2022-06-21 20:24:27,848:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:24:27,848:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:24:27,848:INFO:   <<< datatype: msvd
2022-06-21 20:24:27,848:INFO:   <<< do_eval: False
2022-06-21 20:24:27,848:INFO:   <<< do_lower_case: False
2022-06-21 20:24:27,848:INFO:   <<< do_pretrain: False
2022-06-21 20:24:27,848:INFO:   <<< do_train: True
2022-06-21 20:24:27,848:INFO:   <<< epochs: 5
2022-06-21 20:24:27,848:INFO:   <<< eval_frame_order: 0
2022-06-21 20:24:27,848:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:24:27,848:INFO:   <<< feature_framerate: 1
2022-06-21 20:24:27,848:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:24:27,848:INFO:   <<< fp16: False
2022-06-21 20:24:27,848:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:24:27,848:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:24:27,848:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:24:27,848:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:24:27,848:INFO:   <<< init_model: None
2022-06-21 20:24:27,848:INFO:   <<< linear_patch: 3d
2022-06-21 20:24:27,849:INFO:   <<< local_rank: 0
2022-06-21 20:24:27,849:INFO:   <<< loose_type: True
2022-06-21 20:24:27,849:INFO:   <<< lr: 0.0001
2022-06-21 20:24:27,849:INFO:   <<< lr_decay: 0.9
2022-06-21 20:24:27,849:INFO:   <<< margin: 0.1
2022-06-21 20:24:27,849:INFO:   <<< max_frames: 16
2022-06-21 20:24:27,849:INFO:   <<< max_words: 32
2022-06-21 20:24:27,849:INFO:   <<< n_display: 50
2022-06-21 20:24:27,849:INFO:   <<< n_gpu: 1
2022-06-21 20:24:27,849:INFO:   <<< n_pair: 1
2022-06-21 20:24:27,849:INFO:   <<< negative_weighting: 1
2022-06-21 20:24:27,849:INFO:   <<< num_thread_reader: 2
2022-06-21 20:24:27,849:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:24:27,849:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:24:27,849:INFO:   <<< rank: 0
2022-06-21 20:24:27,849:INFO:   <<< resume_model: None
2022-06-21 20:24:27,849:INFO:   <<< sampled_use_mil: False
2022-06-21 20:24:27,849:INFO:   <<< seed: 42
2022-06-21 20:24:27,849:INFO:   <<< sim_header: meanP
2022-06-21 20:24:27,849:INFO:   <<< slice_framepos: 2
2022-06-21 20:24:27,849:INFO:   <<< task_type: retrieval
2022-06-21 20:24:27,849:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:24:27,849:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:24:27,849:INFO:   <<< train_frame_order: 0
2022-06-21 20:24:27,849:INFO:   <<< use_mil: False
2022-06-21 20:24:27,849:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:24:27,849:INFO:   <<< video_dim: 1024
2022-06-21 20:24:27,849:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:24:27,849:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:24:27,849:INFO:   <<< world_size: 1
2022-06-21 20:24:27,850:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:24:28,571:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:24:28,571:WARNING: Test retrieval by loose type.
2022-06-21 20:24:28,572:WARNING: 	 embed_dim: 512
2022-06-21 20:24:28,572:WARNING: 	 image_resolution: 224
2022-06-21 20:24:28,572:WARNING: 	 vision_layers: 12
2022-06-21 20:24:28,572:WARNING: 	 vision_width: 768
2022-06-21 20:24:28,572:WARNING: 	 vision_patch_size: 32
2022-06-21 20:24:28,572:WARNING: 	 context_length: 77
2022-06-21 20:24:28,572:WARNING: 	 vocab_size: 49408
2022-06-21 20:24:28,572:WARNING: 	 transformer_width: 512
2022-06-21 20:24:28,572:WARNING: 	 transformer_heads: 8
2022-06-21 20:24:28,572:WARNING: 	 transformer_layers: 12
2022-06-21 20:24:28,572:WARNING: 		 linear_patch: 3d
2022-06-21 20:24:28,572:WARNING: 	 cut_top_layer: 0
2022-06-21 20:24:35,869:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:24:50,704:INFO: ***** Running test *****
2022-06-21 20:24:50,704:INFO:   Num examples = 27763
2022-06-21 20:24:50,704:INFO:   Batch size = 16
2022-06-21 20:24:50,704:INFO:   Num steps = 1736
2022-06-21 20:24:50,704:INFO: ***** Running val *****
2022-06-21 20:24:50,704:INFO:   Num examples = 4290
2022-06-21 20:24:51,592:INFO: ***** Running training *****
2022-06-21 20:24:51,592:INFO:   Num examples = 48774
2022-06-21 20:24:51,592:INFO:   Batch size = 128
2022-06-21 20:24:51,592:INFO:   Num steps = 3810
2022-06-21 20:32:53,211:INFO: Effective parameters:
2022-06-21 20:32:53,212:INFO:   <<< batch_size: 128
2022-06-21 20:32:53,212:INFO:   <<< batch_size_val: 16
2022-06-21 20:32:53,212:INFO:   <<< cache_dir: 
2022-06-21 20:32:53,212:INFO:   <<< coef_lr: 0.001
2022-06-21 20:32:53,212:INFO:   <<< cross_model: cross-base
2022-06-21 20:32:53,212:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:32:53,212:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:32:53,212:INFO:   <<< datatype: msvd
2022-06-21 20:32:53,212:INFO:   <<< do_eval: False
2022-06-21 20:32:53,212:INFO:   <<< do_lower_case: False
2022-06-21 20:32:53,212:INFO:   <<< do_pretrain: False
2022-06-21 20:32:53,212:INFO:   <<< do_train: True
2022-06-21 20:32:53,212:INFO:   <<< epochs: 5
2022-06-21 20:32:53,212:INFO:   <<< eval_frame_order: 0
2022-06-21 20:32:53,212:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:32:53,212:INFO:   <<< feature_framerate: 1
2022-06-21 20:32:53,212:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:32:53,212:INFO:   <<< fp16: False
2022-06-21 20:32:53,212:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:32:53,212:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:32:53,212:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:32:53,212:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:32:53,212:INFO:   <<< init_model: None
2022-06-21 20:32:53,212:INFO:   <<< linear_patch: 3d
2022-06-21 20:32:53,212:INFO:   <<< local_rank: 0
2022-06-21 20:32:53,212:INFO:   <<< loose_type: True
2022-06-21 20:32:53,212:INFO:   <<< lr: 0.0001
2022-06-21 20:32:53,212:INFO:   <<< lr_decay: 0.9
2022-06-21 20:32:53,213:INFO:   <<< margin: 0.1
2022-06-21 20:32:53,213:INFO:   <<< max_frames: 16
2022-06-21 20:32:53,213:INFO:   <<< max_words: 32
2022-06-21 20:32:53,213:INFO:   <<< n_display: 50
2022-06-21 20:32:53,213:INFO:   <<< n_gpu: 1
2022-06-21 20:32:53,213:INFO:   <<< n_pair: 1
2022-06-21 20:32:53,213:INFO:   <<< negative_weighting: 1
2022-06-21 20:32:53,213:INFO:   <<< num_thread_reader: 2
2022-06-21 20:32:53,213:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:32:53,213:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:32:53,213:INFO:   <<< rank: 0
2022-06-21 20:32:53,213:INFO:   <<< resume_model: None
2022-06-21 20:32:53,213:INFO:   <<< sampled_use_mil: False
2022-06-21 20:32:53,213:INFO:   <<< seed: 42
2022-06-21 20:32:53,213:INFO:   <<< sim_header: meanP
2022-06-21 20:32:53,213:INFO:   <<< slice_framepos: 2
2022-06-21 20:32:53,213:INFO:   <<< task_type: retrieval
2022-06-21 20:32:53,213:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:32:53,213:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:32:53,213:INFO:   <<< train_frame_order: 0
2022-06-21 20:32:53,213:INFO:   <<< use_mil: False
2022-06-21 20:32:53,213:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:32:53,213:INFO:   <<< video_dim: 1024
2022-06-21 20:32:53,213:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:32:53,213:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:32:53,213:INFO:   <<< world_size: 1
2022-06-21 20:32:53,213:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:32:53,946:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:32:53,946:WARNING: Test retrieval by loose type.
2022-06-21 20:32:53,947:WARNING: 	 embed_dim: 512
2022-06-21 20:32:53,947:WARNING: 	 image_resolution: 224
2022-06-21 20:32:53,947:WARNING: 	 vision_layers: 12
2022-06-21 20:32:53,947:WARNING: 	 vision_width: 768
2022-06-21 20:32:53,947:WARNING: 	 vision_patch_size: 32
2022-06-21 20:32:53,947:WARNING: 	 context_length: 77
2022-06-21 20:32:53,947:WARNING: 	 vocab_size: 49408
2022-06-21 20:32:53,947:WARNING: 	 transformer_width: 512
2022-06-21 20:32:53,947:WARNING: 	 transformer_heads: 8
2022-06-21 20:32:53,947:WARNING: 	 transformer_layers: 12
2022-06-21 20:32:53,947:WARNING: 		 linear_patch: 3d
2022-06-21 20:32:53,947:WARNING: 	 cut_top_layer: 0
2022-06-21 20:33:01,944:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:33:13,795:INFO: ***** Running test *****
2022-06-21 20:33:13,795:INFO:   Num examples = 27763
2022-06-21 20:33:13,795:INFO:   Batch size = 16
2022-06-21 20:33:13,795:INFO:   Num steps = 1736
2022-06-21 20:33:13,795:INFO: ***** Running val *****
2022-06-21 20:33:13,795:INFO:   Num examples = 4290
2022-06-21 20:33:14,599:INFO: ***** Running training *****
2022-06-21 20:33:14,600:INFO:   Num examples = 48774
2022-06-21 20:33:14,600:INFO:   Batch size = 128
2022-06-21 20:33:14,600:INFO:   Num steps = 3810
2022-06-21 20:36:40,730:INFO: Effective parameters:
2022-06-21 20:36:40,730:INFO:   <<< batch_size: 128
2022-06-21 20:36:40,730:INFO:   <<< batch_size_val: 16
2022-06-21 20:36:40,730:INFO:   <<< cache_dir: 
2022-06-21 20:36:40,730:INFO:   <<< coef_lr: 0.001
2022-06-21 20:36:40,731:INFO:   <<< cross_model: cross-base
2022-06-21 20:36:40,731:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:36:40,731:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:36:40,731:INFO:   <<< datatype: msvd
2022-06-21 20:36:40,731:INFO:   <<< do_eval: False
2022-06-21 20:36:40,731:INFO:   <<< do_lower_case: False
2022-06-21 20:36:40,731:INFO:   <<< do_pretrain: False
2022-06-21 20:36:40,731:INFO:   <<< do_train: True
2022-06-21 20:36:40,731:INFO:   <<< epochs: 5
2022-06-21 20:36:40,731:INFO:   <<< eval_frame_order: 0
2022-06-21 20:36:40,731:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:36:40,731:INFO:   <<< feature_framerate: 1
2022-06-21 20:36:40,731:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:36:40,731:INFO:   <<< fp16: False
2022-06-21 20:36:40,731:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:36:40,731:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:36:40,731:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:36:40,731:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:36:40,731:INFO:   <<< init_model: None
2022-06-21 20:36:40,731:INFO:   <<< linear_patch: 3d
2022-06-21 20:36:40,731:INFO:   <<< local_rank: 0
2022-06-21 20:36:40,731:INFO:   <<< loose_type: True
2022-06-21 20:36:40,731:INFO:   <<< lr: 0.0001
2022-06-21 20:36:40,731:INFO:   <<< lr_decay: 0.9
2022-06-21 20:36:40,731:INFO:   <<< margin: 0.1
2022-06-21 20:36:40,731:INFO:   <<< max_frames: 16
2022-06-21 20:36:40,731:INFO:   <<< max_words: 32
2022-06-21 20:36:40,731:INFO:   <<< n_display: 50
2022-06-21 20:36:40,731:INFO:   <<< n_gpu: 1
2022-06-21 20:36:40,732:INFO:   <<< n_pair: 1
2022-06-21 20:36:40,732:INFO:   <<< negative_weighting: 1
2022-06-21 20:36:40,732:INFO:   <<< num_thread_reader: 2
2022-06-21 20:36:40,732:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:36:40,732:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:36:40,732:INFO:   <<< rank: 0
2022-06-21 20:36:40,732:INFO:   <<< resume_model: None
2022-06-21 20:36:40,732:INFO:   <<< sampled_use_mil: False
2022-06-21 20:36:40,732:INFO:   <<< seed: 42
2022-06-21 20:36:40,732:INFO:   <<< sim_header: meanP
2022-06-21 20:36:40,732:INFO:   <<< slice_framepos: 2
2022-06-21 20:36:40,732:INFO:   <<< task_type: retrieval
2022-06-21 20:36:40,732:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:36:40,732:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:36:40,732:INFO:   <<< train_frame_order: 0
2022-06-21 20:36:40,732:INFO:   <<< use_mil: False
2022-06-21 20:36:40,732:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:36:40,732:INFO:   <<< video_dim: 1024
2022-06-21 20:36:40,732:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:36:40,732:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:36:40,732:INFO:   <<< world_size: 1
2022-06-21 20:36:40,732:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:36:41,442:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:36:41,442:WARNING: Test retrieval by loose type.
2022-06-21 20:36:41,443:WARNING: 	 embed_dim: 512
2022-06-21 20:36:41,443:WARNING: 	 image_resolution: 224
2022-06-21 20:36:41,443:WARNING: 	 vision_layers: 12
2022-06-21 20:36:41,443:WARNING: 	 vision_width: 768
2022-06-21 20:36:41,443:WARNING: 	 vision_patch_size: 32
2022-06-21 20:36:41,443:WARNING: 	 context_length: 77
2022-06-21 20:36:41,443:WARNING: 	 vocab_size: 49408
2022-06-21 20:36:41,443:WARNING: 	 transformer_width: 512
2022-06-21 20:36:41,443:WARNING: 	 transformer_heads: 8
2022-06-21 20:36:41,443:WARNING: 	 transformer_layers: 12
2022-06-21 20:36:41,443:WARNING: 		 linear_patch: 3d
2022-06-21 20:36:41,443:WARNING: 	 cut_top_layer: 0
2022-06-21 20:36:49,288:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:37:01,858:INFO: ***** Running test *****
2022-06-21 20:37:01,859:INFO:   Num examples = 27763
2022-06-21 20:37:01,859:INFO:   Batch size = 16
2022-06-21 20:37:01,859:INFO:   Num steps = 1736
2022-06-21 20:37:01,859:INFO: ***** Running val *****
2022-06-21 20:37:01,859:INFO:   Num examples = 4290
2022-06-21 20:37:02,605:INFO: ***** Running training *****
2022-06-21 20:37:02,605:INFO:   Num examples = 48774
2022-06-21 20:37:02,605:INFO:   Batch size = 128
2022-06-21 20:37:02,605:INFO:   Num steps = 3810
2022-06-21 20:41:27,417:INFO: Effective parameters:
2022-06-21 20:41:27,417:INFO:   <<< batch_size: 128
2022-06-21 20:41:27,417:INFO:   <<< batch_size_val: 16
2022-06-21 20:41:27,417:INFO:   <<< cache_dir: 
2022-06-21 20:41:27,417:INFO:   <<< coef_lr: 0.001
2022-06-21 20:41:27,417:INFO:   <<< cross_model: cross-base
2022-06-21 20:41:27,417:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 20:41:27,417:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 20:41:27,417:INFO:   <<< datatype: msvd
2022-06-21 20:41:27,417:INFO:   <<< do_eval: False
2022-06-21 20:41:27,417:INFO:   <<< do_lower_case: False
2022-06-21 20:41:27,417:INFO:   <<< do_pretrain: False
2022-06-21 20:41:27,417:INFO:   <<< do_train: True
2022-06-21 20:41:27,418:INFO:   <<< epochs: 5
2022-06-21 20:41:27,418:INFO:   <<< eval_frame_order: 0
2022-06-21 20:41:27,418:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 20:41:27,418:INFO:   <<< feature_framerate: 1
2022-06-21 20:41:27,418:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 20:41:27,418:INFO:   <<< fp16: False
2022-06-21 20:41:27,418:INFO:   <<< fp16_opt_level: O1
2022-06-21 20:41:27,418:INFO:   <<< freeze_layer_num: 0
2022-06-21 20:41:27,418:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 20:41:27,418:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 20:41:27,418:INFO:   <<< init_model: None
2022-06-21 20:41:27,418:INFO:   <<< linear_patch: 3d
2022-06-21 20:41:27,418:INFO:   <<< local_rank: 0
2022-06-21 20:41:27,418:INFO:   <<< loose_type: True
2022-06-21 20:41:27,418:INFO:   <<< lr: 0.0001
2022-06-21 20:41:27,418:INFO:   <<< lr_decay: 0.9
2022-06-21 20:41:27,418:INFO:   <<< margin: 0.1
2022-06-21 20:41:27,418:INFO:   <<< max_frames: 16
2022-06-21 20:41:27,418:INFO:   <<< max_words: 32
2022-06-21 20:41:27,418:INFO:   <<< n_display: 50
2022-06-21 20:41:27,418:INFO:   <<< n_gpu: 1
2022-06-21 20:41:27,418:INFO:   <<< n_pair: 1
2022-06-21 20:41:27,418:INFO:   <<< negative_weighting: 1
2022-06-21 20:41:27,418:INFO:   <<< num_thread_reader: 2
2022-06-21 20:41:27,418:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 20:41:27,418:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 20:41:27,418:INFO:   <<< rank: 0
2022-06-21 20:41:27,418:INFO:   <<< resume_model: None
2022-06-21 20:41:27,418:INFO:   <<< sampled_use_mil: False
2022-06-21 20:41:27,418:INFO:   <<< seed: 42
2022-06-21 20:41:27,418:INFO:   <<< sim_header: meanP
2022-06-21 20:41:27,419:INFO:   <<< slice_framepos: 2
2022-06-21 20:41:27,419:INFO:   <<< task_type: retrieval
2022-06-21 20:41:27,419:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 20:41:27,419:INFO:   <<< train_csv: data/.train.csv
2022-06-21 20:41:27,419:INFO:   <<< train_frame_order: 0
2022-06-21 20:41:27,419:INFO:   <<< use_mil: False
2022-06-21 20:41:27,419:INFO:   <<< val_csv: data/.val.csv
2022-06-21 20:41:27,419:INFO:   <<< video_dim: 1024
2022-06-21 20:41:27,419:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 20:41:27,419:INFO:   <<< warmup_proportion: 0.1
2022-06-21 20:41:27,419:INFO:   <<< world_size: 1
2022-06-21 20:41:27,419:INFO: device: cuda:0 n_gpu: 2
2022-06-21 20:41:28,130:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 20:41:28,131:WARNING: Test retrieval by loose type.
2022-06-21 20:41:28,131:WARNING: 	 embed_dim: 512
2022-06-21 20:41:28,131:WARNING: 	 image_resolution: 224
2022-06-21 20:41:28,131:WARNING: 	 vision_layers: 12
2022-06-21 20:41:28,131:WARNING: 	 vision_width: 768
2022-06-21 20:41:28,131:WARNING: 	 vision_patch_size: 32
2022-06-21 20:41:28,131:WARNING: 	 context_length: 77
2022-06-21 20:41:28,132:WARNING: 	 vocab_size: 49408
2022-06-21 20:41:28,132:WARNING: 	 transformer_width: 512
2022-06-21 20:41:28,132:WARNING: 	 transformer_heads: 8
2022-06-21 20:41:28,132:WARNING: 	 transformer_layers: 12
2022-06-21 20:41:28,132:WARNING: 		 linear_patch: 3d
2022-06-21 20:41:28,132:WARNING: 	 cut_top_layer: 0
2022-06-21 20:41:35,511:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 20:41:49,922:INFO: ***** Running test *****
2022-06-21 20:41:49,923:INFO:   Num examples = 27763
2022-06-21 20:41:49,923:INFO:   Batch size = 16
2022-06-21 20:41:49,923:INFO:   Num steps = 1736
2022-06-21 20:41:49,923:INFO: ***** Running val *****
2022-06-21 20:41:49,923:INFO:   Num examples = 4290
2022-06-21 20:41:50,843:INFO: ***** Running training *****
2022-06-21 20:41:50,843:INFO:   Num examples = 48774
2022-06-21 20:41:50,844:INFO:   Batch size = 128
2022-06-21 20:41:50,844:INFO:   Num steps = 3810
2022-06-21 20:57:14,345:INFO: Epoch: 1/5, Step: 50/762, Lr: 0.000000013, Loss: 2.973226, Time/step: 18.470021
2022-06-21 21:12:41,127:INFO: Epoch: 1/5, Step: 100/762, Lr: 0.000000026, Loss: 2.524416, Time/step: 18.535613
2022-06-21 21:28:06,073:INFO: Epoch: 1/5, Step: 150/762, Lr: 0.000000039, Loss: 2.509278, Time/step: 18.498923
2022-06-21 21:41:39,875:INFO: Effective parameters:
2022-06-21 21:41:39,875:INFO:   <<< batch_size: 128
2022-06-21 21:41:39,875:INFO:   <<< batch_size_val: 16
2022-06-21 21:41:39,875:INFO:   <<< cache_dir: 
2022-06-21 21:41:39,875:INFO:   <<< coef_lr: 0.001
2022-06-21 21:41:39,875:INFO:   <<< cross_model: cross-base
2022-06-21 21:41:39,875:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 21:41:39,875:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 21:41:39,875:INFO:   <<< datatype: msvd
2022-06-21 21:41:39,875:INFO:   <<< do_eval: False
2022-06-21 21:41:39,875:INFO:   <<< do_lower_case: False
2022-06-21 21:41:39,875:INFO:   <<< do_pretrain: False
2022-06-21 21:41:39,875:INFO:   <<< do_train: True
2022-06-21 21:41:39,876:INFO:   <<< epochs: 5
2022-06-21 21:41:39,876:INFO:   <<< eval_frame_order: 0
2022-06-21 21:41:39,876:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 21:41:39,876:INFO:   <<< feature_framerate: 1
2022-06-21 21:41:39,876:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 21:41:39,876:INFO:   <<< fp16: False
2022-06-21 21:41:39,876:INFO:   <<< fp16_opt_level: O1
2022-06-21 21:41:39,876:INFO:   <<< freeze_layer_num: 0
2022-06-21 21:41:39,876:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 21:41:39,876:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 21:41:39,876:INFO:   <<< init_model: None
2022-06-21 21:41:39,876:INFO:   <<< linear_patch: 3d
2022-06-21 21:41:39,876:INFO:   <<< local_rank: 0
2022-06-21 21:41:39,876:INFO:   <<< loose_type: True
2022-06-21 21:41:39,876:INFO:   <<< lr: 0.0001
2022-06-21 21:41:39,876:INFO:   <<< lr_decay: 0.9
2022-06-21 21:41:39,876:INFO:   <<< margin: 0.1
2022-06-21 21:41:39,876:INFO:   <<< max_frames: 16
2022-06-21 21:41:39,876:INFO:   <<< max_words: 32
2022-06-21 21:41:39,876:INFO:   <<< n_display: 50
2022-06-21 21:41:39,876:INFO:   <<< n_gpu: 1
2022-06-21 21:41:39,876:INFO:   <<< n_pair: 1
2022-06-21 21:41:39,876:INFO:   <<< negative_weighting: 1
2022-06-21 21:41:39,876:INFO:   <<< num_thread_reader: 2
2022-06-21 21:41:39,876:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 21:41:39,876:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 21:41:39,876:INFO:   <<< rank: 0
2022-06-21 21:41:39,876:INFO:   <<< resume_model: None
2022-06-21 21:41:39,876:INFO:   <<< sampled_use_mil: False
2022-06-21 21:41:39,876:INFO:   <<< seed: 42
2022-06-21 21:41:39,876:INFO:   <<< sim_header: meanP
2022-06-21 21:41:39,877:INFO:   <<< slice_framepos: 2
2022-06-21 21:41:39,877:INFO:   <<< task_type: retrieval
2022-06-21 21:41:39,877:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 21:41:39,877:INFO:   <<< train_csv: data/.train.csv
2022-06-21 21:41:39,877:INFO:   <<< train_frame_order: 0
2022-06-21 21:41:39,877:INFO:   <<< use_mil: False
2022-06-21 21:41:39,877:INFO:   <<< val_csv: data/.val.csv
2022-06-21 21:41:39,877:INFO:   <<< video_dim: 1024
2022-06-21 21:41:39,877:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 21:41:39,877:INFO:   <<< warmup_proportion: 0.1
2022-06-21 21:41:39,877:INFO:   <<< world_size: 1
2022-06-21 21:41:39,877:INFO: device: cuda:0 n_gpu: 2
2022-06-21 21:41:40,597:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 21:41:40,597:WARNING: Test retrieval by loose type.
2022-06-21 21:41:40,597:WARNING: 	 embed_dim: 512
2022-06-21 21:41:40,597:WARNING: 	 image_resolution: 224
2022-06-21 21:41:40,597:WARNING: 	 vision_layers: 12
2022-06-21 21:41:40,597:WARNING: 	 vision_width: 768
2022-06-21 21:41:40,598:WARNING: 	 vision_patch_size: 32
2022-06-21 21:41:40,598:WARNING: 	 context_length: 77
2022-06-21 21:41:40,598:WARNING: 	 vocab_size: 49408
2022-06-21 21:41:40,598:WARNING: 	 transformer_width: 512
2022-06-21 21:41:40,598:WARNING: 	 transformer_heads: 8
2022-06-21 21:41:40,598:WARNING: 	 transformer_layers: 12
2022-06-21 21:41:40,598:WARNING: 		 linear_patch: 3d
2022-06-21 21:41:40,598:WARNING: 	 cut_top_layer: 0
2022-06-21 21:41:48,014:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 21:42:00,252:INFO: ***** Running test *****
2022-06-21 21:42:00,252:INFO:   Num examples = 27763
2022-06-21 21:42:00,252:INFO:   Batch size = 16
2022-06-21 21:42:00,252:INFO:   Num steps = 1736
2022-06-21 21:42:00,252:INFO: ***** Running val *****
2022-06-21 21:42:00,252:INFO:   Num examples = 4290
2022-06-21 21:42:01,275:INFO: ***** Running training *****
2022-06-21 21:42:01,275:INFO:   Num examples = 48774
2022-06-21 21:42:01,275:INFO:   Batch size = 128
2022-06-21 21:42:01,275:INFO:   Num steps = 3810
2022-06-21 21:43:04,174:INFO: Effective parameters:
2022-06-21 21:43:04,174:INFO:   <<< batch_size: 128
2022-06-21 21:43:04,174:INFO:   <<< batch_size_val: 16
2022-06-21 21:43:04,174:INFO:   <<< cache_dir: 
2022-06-21 21:43:04,175:INFO:   <<< coef_lr: 0.001
2022-06-21 21:43:04,175:INFO:   <<< cross_model: cross-base
2022-06-21 21:43:04,175:INFO:   <<< cross_num_hidden_layers: 4
2022-06-21 21:43:04,175:INFO:   <<< data_path: /home/key2317/CLIP2TAE/msvd_data
2022-06-21 21:43:04,175:INFO:   <<< datatype: msvd
2022-06-21 21:43:04,175:INFO:   <<< do_eval: False
2022-06-21 21:43:04,175:INFO:   <<< do_lower_case: False
2022-06-21 21:43:04,175:INFO:   <<< do_pretrain: False
2022-06-21 21:43:04,175:INFO:   <<< do_train: True
2022-06-21 21:43:04,175:INFO:   <<< epochs: 5
2022-06-21 21:43:04,175:INFO:   <<< eval_frame_order: 0
2022-06-21 21:43:04,175:INFO:   <<< expand_msrvtt_sentences: False
2022-06-21 21:43:04,175:INFO:   <<< feature_framerate: 1
2022-06-21 21:43:04,175:INFO:   <<< features_path: /home/key2317/CLIP2TAE/msvd_data/MSVD_Videos
2022-06-21 21:43:04,175:INFO:   <<< fp16: False
2022-06-21 21:43:04,175:INFO:   <<< fp16_opt_level: O1
2022-06-21 21:43:04,175:INFO:   <<< freeze_layer_num: 0
2022-06-21 21:43:04,175:INFO:   <<< gradient_accumulation_steps: 1
2022-06-21 21:43:04,175:INFO:   <<< hard_negative_rate: 0.5
2022-06-21 21:43:04,175:INFO:   <<< init_model: None
2022-06-21 21:43:04,175:INFO:   <<< linear_patch: 3d
2022-06-21 21:43:04,175:INFO:   <<< local_rank: 0
2022-06-21 21:43:04,175:INFO:   <<< loose_type: True
2022-06-21 21:43:04,175:INFO:   <<< lr: 0.0001
2022-06-21 21:43:04,175:INFO:   <<< lr_decay: 0.9
2022-06-21 21:43:04,175:INFO:   <<< margin: 0.1
2022-06-21 21:43:04,175:INFO:   <<< max_frames: 16
2022-06-21 21:43:04,175:INFO:   <<< max_words: 32
2022-06-21 21:43:04,175:INFO:   <<< n_display: 50
2022-06-21 21:43:04,176:INFO:   <<< n_gpu: 1
2022-06-21 21:43:04,176:INFO:   <<< n_pair: 1
2022-06-21 21:43:04,176:INFO:   <<< negative_weighting: 1
2022-06-21 21:43:04,176:INFO:   <<< num_thread_reader: 2
2022-06-21 21:43:04,176:INFO:   <<< output_dir: ckpts/ckpt_msvd_retrieval_looseType
2022-06-21 21:43:04,176:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-06-21 21:43:04,176:INFO:   <<< rank: 0
2022-06-21 21:43:04,176:INFO:   <<< resume_model: None
2022-06-21 21:43:04,176:INFO:   <<< sampled_use_mil: False
2022-06-21 21:43:04,176:INFO:   <<< seed: 42
2022-06-21 21:43:04,176:INFO:   <<< sim_header: meanP
2022-06-21 21:43:04,176:INFO:   <<< slice_framepos: 2
2022-06-21 21:43:04,176:INFO:   <<< task_type: retrieval
2022-06-21 21:43:04,176:INFO:   <<< text_num_hidden_layers: 12
2022-06-21 21:43:04,176:INFO:   <<< train_csv: data/.train.csv
2022-06-21 21:43:04,176:INFO:   <<< train_frame_order: 0
2022-06-21 21:43:04,176:INFO:   <<< use_mil: False
2022-06-21 21:43:04,176:INFO:   <<< val_csv: data/.val.csv
2022-06-21 21:43:04,176:INFO:   <<< video_dim: 1024
2022-06-21 21:43:04,176:INFO:   <<< visual_num_hidden_layers: 12
2022-06-21 21:43:04,176:INFO:   <<< warmup_proportion: 0.1
2022-06-21 21:43:04,176:INFO:   <<< world_size: 1
2022-06-21 21:43:04,176:INFO: device: cuda:0 n_gpu: 2
2022-06-21 21:43:04,941:WARNING: Stage-One:True, Stage-Two:False
2022-06-21 21:43:04,941:WARNING: Test retrieval by loose type.
2022-06-21 21:43:04,941:WARNING: 	 embed_dim: 512
2022-06-21 21:43:04,941:WARNING: 	 image_resolution: 224
2022-06-21 21:43:04,941:WARNING: 	 vision_layers: 12
2022-06-21 21:43:04,941:WARNING: 	 vision_width: 768
2022-06-21 21:43:04,942:WARNING: 	 vision_patch_size: 32
2022-06-21 21:43:04,942:WARNING: 	 context_length: 77
2022-06-21 21:43:04,942:WARNING: 	 vocab_size: 49408
2022-06-21 21:43:04,942:WARNING: 	 transformer_width: 512
2022-06-21 21:43:04,942:WARNING: 	 transformer_heads: 8
2022-06-21 21:43:04,942:WARNING: 	 transformer_layers: 12
2022-06-21 21:43:04,942:WARNING: 		 linear_patch: 3d
2022-06-21 21:43:04,942:WARNING: 	 cut_top_layer: 0
2022-06-21 21:43:12,373:ERROR: Weights from pretrained model cause errors in CLIP4Clip: 
   size mismatch for clip.visual.positional_embedding: copying a param with shape torch.Size([50, 768]) from checkpoint, the shape in current model is torch.Size([26, 768]).
2022-06-21 21:43:27,073:INFO: ***** Running test *****
2022-06-21 21:43:27,073:INFO:   Num examples = 27763
2022-06-21 21:43:27,073:INFO:   Batch size = 16
2022-06-21 21:43:27,073:INFO:   Num steps = 1736
2022-06-21 21:43:27,073:INFO: ***** Running val *****
2022-06-21 21:43:27,073:INFO:   Num examples = 4290
2022-06-21 21:43:28,098:INFO: ***** Running training *****
2022-06-21 21:43:28,098:INFO:   Num examples = 48774
2022-06-21 21:43:28,098:INFO:   Batch size = 128
2022-06-21 21:43:28,098:INFO:   Num steps = 3810
